{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'rnnlm' from 'rnnlm.pyc'>"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json, os, re, shutil, sys, time\n",
    "import collections, itertools\n",
    "import unittest\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# NLTK for NLP utils and corpora\n",
    "import nltk\n",
    "\n",
    "# NumPy and TensorFlow\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "assert(tf.__version__.startswith(\"1.\"))\n",
    "\n",
    "# utils.pretty_print_matrix uses Pandas. Configure float format here.\n",
    "import pandas as pd\n",
    "pd.set_option('float_format', lambda f: \"{0:.04f}\".format(f))\n",
    "\n",
    "# RNNLM Model\n",
    "import rnnlm\n",
    "reload(rnnlm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "class Vocabulary(object):\n",
    "\n",
    "  UNK_TOKEN = \"<unk>\"\n",
    "\n",
    "  def __init__(self, tokens, size=None):\n",
    "    self.unigram_counts = collections.Counter(tokens)\n",
    "    # leave space for \"<s>\", \"</s>\", and \"<unk>\"\n",
    "    top_counts = self.unigram_counts.most_common(None if size is None else (size - 1))\n",
    "    vocab = ([self.UNK_TOKEN] +\n",
    "             [w for w,c in top_counts])\n",
    "\n",
    "    # Assign an id to each word, by frequency\n",
    "    self.id_to_word = dict(enumerate(vocab))\n",
    "    self.word_to_id = {v:k for k,v in self.id_to_word.iteritems()}\n",
    "    self.size = len(self.id_to_word)\n",
    "    if size is not None:\n",
    "        assert(self.size <= size)\n",
    "\n",
    "    # For convenience\n",
    "    self.wordset = set(self.word_to_id.iterkeys())\n",
    "\n",
    "    # Store special IDs\n",
    "    self.UNK_ID = self.word_to_id[self.UNK_TOKEN]\n",
    "\n",
    "  def words_to_ids(self, words):\n",
    "    return [self.word_to_id.get(w, self.UNK_ID) for w in words]\n",
    "\n",
    "  def ids_to_words(self, ids):\n",
    "    return [self.id_to_word[i] for i in ids]\n",
    "\n",
    "  def ordered_words(self):\n",
    "    \"\"\"Return a list of words, ordered by id.\"\"\"\n",
    "    return self.ids_to_words(range(self.size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import re\n",
    "\n",
    "def canonicalize_digits(word):\n",
    "    if any([c.isalpha() for c in word]): return word\n",
    "    word = re.sub(\"\\d\", \"DG\", word)\n",
    "    if word.startswith(\"DG\"):\n",
    "        word = word.replace(\",\", \"\") # remove thousands separator\n",
    "    return word\n",
    "\n",
    "def canonicalize_word(word):\n",
    "    word = word.lower()\n",
    "    return canonicalize_digits(word) # try to canonicalize numbers\n",
    "\n",
    "def canonicalize_words(words):\n",
    "    current = []\n",
    "    for word in words.split(\" \"):   \n",
    "        if word and word[-1] in (\".\", ',', '?', ';', '!'):\n",
    "            punk = word[-1]\n",
    "            current.append(punk)\n",
    "            word = word[0:-1]\n",
    "\n",
    "        word = canonicalize_word(word)\n",
    "        current.append(word)\n",
    "    return current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pretty_timedelta(fmt=\"%d:%02d:%02d\", since=None, until=None):\n",
    "    \"\"\"Pretty-print a timedelta, using the given format string.\"\"\"\n",
    "    since = since or time.time()\n",
    "    until = until or time.time()\n",
    "    delta_s = until - since\n",
    "    hours, remainder = divmod(delta_s, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    return fmt % (hours, minutes, seconds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_train_data():\n",
    "    train_data_dir = 'train_data'\n",
    "    y = []\n",
    "    X = []\n",
    "    all_tokens = []\n",
    "    author_to_id = {}\n",
    "    for author_id, author in enumerate(listdir(train_data_dir)):\n",
    "        author_to_id[author] = author_id\n",
    "        author_path = \"%s/%s\" % (train_data_dir, author)\n",
    "        print author, author_id\n",
    "\n",
    "        for file_name in listdir(author_path):\n",
    "            full_path = \"%s/%s\" % (author_path, file_name)\n",
    "            y.append(author_id)            \n",
    "            with open(full_path, \"r\") as f:\n",
    "                current = canonicalize_words(f.read())\n",
    "                all_tokens += current\n",
    "                X.append(np.array(current))\n",
    "                \n",
    "    vocab = Vocabulary(all_tokens)\n",
    "\n",
    "    # replace words with ids\n",
    "    for i, x in enumerate(X):\n",
    "        X[i] = np.array(vocab.words_to_ids(x))\n",
    "\n",
    "    return vocab, np.array(X), np.array(y), author_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thomas_paine 0\n",
      "thomas_jefferson 1\n",
      "john_adams 2\n",
      "james_madison 3\n",
      "alexander_hamilton 4\n",
      "james_monroe 5\n",
      "john_jay 6\n",
      "george_washington 7\n",
      "benjamin_franklin 8\n",
      "vocab.size 145546\n",
      "{'thomas_jefferson': 1, 'john_adams': 2, 'alexander_hamilton': 4, 'benjamin_franklin': 8, 'george_washington': 7, 'thomas_paine': 0, 'james_madison': 3, 'james_monroe': 5, 'john_jay': 6}\n"
     ]
    }
   ],
   "source": [
    "vocab, X_train, y_train, author_to_id = load_train_data()\n",
    "num_classes = len(np.unique(y_train))\n",
    "print \"vocab.size\", vocab.size\n",
    "print author_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\n",
      "[[ 184    2 3790 ...,  365    5  497]]\n"
     ]
    }
   ],
   "source": [
    "def load_eval_data(vocab):\n",
    "    eval_data_dir = \"unknown_data\"\n",
    "    eval_X = {}\n",
    "    eval_y = {}\n",
    "    for file_name in listdir(eval_data_dir):\n",
    "        full_path = \"%s/%s\" % (eval_data_dir, file_name)\n",
    "        with open(full_path, \"r\") as f:\n",
    "            current = vocab.words_to_ids(canonicalize_words(f.read()))\n",
    "\n",
    "        expanded_X = np.array(current)\n",
    "        id = file_name.split(\"_\")[2].split(\".\")[0]\n",
    "        eval_X[id] = np.array([expanded_X])\n",
    "        # working with the assumption that James Madison wrote all the disputed papers\n",
    "        eval_y[id] = np.array([author_to_id['james_madison']])\n",
    "\n",
    "    return eval_X, eval_y\n",
    "\n",
    "eval_X, eval_y = load_eval_data(vocab)\n",
    "print eval_y['18']\n",
    "print eval_X['18']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 1 1 1 1 1 1 1 1 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 5 6 6 6 6 6 7 7 8]\n",
      "[array([   214,      3, 110275, ...,      3,    107, 117020])\n",
      " array([42483,   344, 22831, ...,     1,   135, 14900])\n",
      " array([   279, 116136,   3396, ...,   6758,      3,  21317])\n",
      " array([   47,   192,     3, ...,   591,   516, 38425])\n",
      " array([   13,    58,    19, ...,  2333,   120, 96859])\n",
      " array([61541,     1,   135, ...,   432,     6, 38425])\n",
      " array([   13,   789,    27, ...,     5,  3499, 45432])\n",
      " array([   11,    12,     8, ...,     5, 51014,  1028])\n",
      " array([ 56122,    132,   1821, ...,     14,    613, 118907])\n",
      " array([   13,   156,     8, ...,   169, 15270, 57131])\n",
      " array([  1028,      4,    712, ...,      3,      2, 125230])\n",
      " array([   13,   696,     4, ...,   527,     6, 27168])\n",
      " array([   13,    31,    18, ..., 77518,     5,  7580])\n",
      " array([   2,  132,  346, ...,    5,  231, 3420])\n",
      " array([  11,   31, 1149, ...,    5,  313, 3420])\n",
      " array([  2, 418, 271, ...,   3,   5, 690])\n",
      " array([ 157, 1149,    9, ...,    5,  278, 3420])\n",
      " array([ 157, 8665,    2, ...,    5,  346, 3420])\n",
      " array([   2,  418, 1129, ...,    5,  704, 3420])\n",
      " array([     7,    482,      3, ...,      3,    220, 124105])\n",
      " array([    13,    102,     21, ..., 114169,      5,  21061])\n",
      " array([   44,  1750,    22, ...,   182,   143, 51870])\n",
      " array([ 184,    2, 1018, ...,    5, 1707, 3420])\n",
      " array([7819,    2,  116, ...,    5,   43, 3420])\n",
      " array([  42,   19,  397, ...,    5,  715, 3420])\n",
      " array([   2,  137,  303, ...,  746, 3012, 3420])\n",
      " array([   7, 7549,    2, ...,  103,    5, 3294])\n",
      " array([  11,   12,   21, ...,    5, 1664, 3420])\n",
      " array([   8, 3018, 1129, ...,    5, 1879, 3420])\n",
      " array([  35,    2,  484, ...,   12,    5, 2446])\n",
      " array([ 613,    3,    2, ..., 6827,  516, 4965])\n",
      " array([ 22727,    714,      3, ...,      3, 121423,  66101])\n",
      " array([   2, 2076, 1129, ...,    5,   54, 3420])\n",
      " array([ 57471,    132,     31, ...,     20,     32, 141555])\n",
      " array([ 28329,    248,     17, ...,     18,      9, 122739])\n",
      " array([     1,   6717,    977, ...,   9650,      4, 121872])\n",
      " array([  11,   40,  249, ...,    5, 2906, 3420])\n",
      " array([   2,  208,   12, ...,    5,  627, 3420])\n",
      " array([19151, 34633,  3800, ...,   432,     4, 21317])\n",
      " array([ 171,   36, 3623, ...,  103,    5,  137])\n",
      " array([  1886,      4,  42536, ...,    301,      3, 123882])\n",
      " array([   11,    12,   758, ...,  1356,     5, 14355])\n",
      " array([   2,  671, 4074, ...,   24,    5,  276])\n",
      " array([  42,   19,  397, ...,  229,    5, 7919])\n",
      " array([ 394,    4, 6621, ...,  239,    5,  186])\n",
      " array([   2,  208,    3, ...,    5, 3472, 3420])\n",
      " array([   2,  510,    3, ...,    5, 2022, 3420])\n",
      " array([  1264,      1,    186, ..., 116951,   1886,  23764])\n",
      " array([306,  72,  95, ..., 394,   5, 346])\n",
      " array([    5,    50, 84966, ...,     3,  4962, 74944])\n",
      " array([  1320,      1,    135, ...,     39,     37, 135205])\n",
      " array([   2, 2502,    3, ...,    5,  278, 3420])\n",
      " array([   8, 1810,    3, ...,    3,    5, 5378])\n",
      " array([    1,    42,     2, ...,    53,     3, 25775])\n",
      " array([42, 19,  1, ..., 24,  5, 75])\n",
      " array([  11,   39,   37, ...,  229,    5, 7919])\n",
      " array([   2, 1189,  185, ...,    5, 2839, 3420])\n",
      " array([   2,  402,    3, ...,    5, 1528, 3420])\n",
      " array([   2, 6091,    3, ..., 1917,    5,  135])\n",
      " array([  816,     3,     2, ...,    48,    53, 93581])\n",
      " array([  11,   31,    8, ...,    5, 3458, 3420])\n",
      " array([   361,      6, 111267, ...,   1238,      6,  74759])\n",
      " array([ 822,   13,  102, ...,    5,  442, 3420])\n",
      " array([    5,    50, 95938, ...,  4231,     8, 53971])\n",
      " array([  5751,      3,      2, ..., 125721, 118755, 123349])\n",
      " array([ 1273,     1,   186, ...,    28, 13288, 23764])\n",
      " array([  270,    21,    78, ...,    99,  1405, 46169])\n",
      " array([ 127,   42,  619, ...,    5,  205, 3420])\n",
      " array([  4,   2, 185, ...,  24,   5, 169])\n",
      " array([ 73759, 138934,    215, ...,     12,     21,  63520])\n",
      " array([  11,   39,   37, ...,  779,    5, 8489])\n",
      " array([  388,     4,     2, ..., 29405, 38987,     2])\n",
      " array([  2, 468, 230, ..., 977,   5, 239])\n",
      " array([ 2058,     6,  1551, ...,    18,    28, 96168])\n",
      " array([  13, 2520,  199, ...,    5,  378, 3420])\n",
      " array([   8, 1591,  278, ..., 8490,    5,   13])\n",
      " array([   40,    11,  1360, ...,    25,    10, 76328])\n",
      " array([     2,    752,    135, ..., 123599,  14851,  23764])\n",
      " array([4817,   11,  138, ...,   24,    5,  116])\n",
      " array([     2,   3559, 119806, ...,     29,      8,  45279])\n",
      " array([   2,  621,    4, ...,    6,    5, 9790])\n",
      " array([   2,   97,    3, ...,    5, 3763, 3420])\n",
      " array([  11,   39,   37, ...,    5,   11, 3420])\n",
      " array([  42,  619,   95, ..., 1719,    5, 3416])\n",
      " array([    2,   208,    12, ...,     7, 29356,  3420])\n",
      " array([ 73127,      4,     47, ...,      7,     41, 142475])\n",
      " array([    2,   237,   132, ...,   317,     5, 39598])\n",
      " array([    2,  1074,     3, ...,     5, 18185,  3420])\n",
      " array([  36,    1,  621, ...,    5,  395, 3420])\n",
      " array([  145,   150,  4585, ...,     3,     2, 91446])\n",
      " array([  2, 137,   3, ..., 963,   5, 135])\n",
      " array([    7, 10615,     3, ...,     5,    57,  3420])\n",
      " array([ 157,    7,    2, ...,    5,  443, 3420])\n",
      " array([    2,   494,     3, ...,  8388,  4446, 61230])\n",
      " array([     5,     73, 115293, ...,    976,     12,  83049])\n",
      " array([81572,     1,   186, ...,   537,     3, 79784])\n",
      " array([1886,    4, 5115, ...,    5, 1029, 4031])\n",
      " array([    7,     2,   168, ...,    18,     2, 16539])\n",
      " array([  14, 1284,   20, ...,    5,  107, 3420])\n",
      " array([  59,   12,   36, ...,  229,    5, 7919])\n",
      " array([     5,     50, 105165, ...,      6,   4386,  44155])\n",
      " array([   9,   59,   40, ..., 2045,    5, 1375])\n",
      " array([   2,  921,    3, ...,  604,    5, 1338])\n",
      " array([    15,  16399,    135, ...,   9309,      8, 118249])\n",
      " array([   4,  438,   20, ...,    5,  663, 3420])\n",
      " array([    50, 109235,      2, ...,   3443, 106208,  61818])\n",
      " array([  7, 956,   4, ...,   8,   5, 456])\n",
      " array([    2,   123,     3, ...,  3389,     2, 78497])\n",
      " array([   59,    30,  2043, ...,     3,  9325, 42863])\n",
      " array([119574,      1,    135, ...,     36,   3365,  55076])\n",
      " array([1740,    7,  324, ...,    2,    5,  123])\n",
      " array([   2,   56, 2100, ...,    5, 7148, 3420])\n",
      " array([     2,    533,      3, ...,  90744,      5, 113690])\n",
      " array([    4,     2,  1565, ...,     2,    54, 97797])\n",
      " array([  13,  619,   95, ...,   93,    5, 1317])\n",
      " array([    7,     2,   168, ...,     6,     5, 15136])\n",
      " array([   35,    50,   484, ...,     3,     5, 15139])\n",
      " array([ 3942,     1, 16424, ...,     5,   148,  3420])\n",
      " array([    98,      2,    123, ...,     46, 121152,   3420])\n",
      " array([  11,   12,   21, ...,  105,  139, 3420])\n",
      " array([  46,  132,  346, ...,    5,  202, 3420])\n",
      " array([  11,   12,    8, ...,    5, 5378, 3420])\n",
      " array([    13,   2354,     20, ...,      5, 104911,    712])\n",
      " array([  672,     1,    15, ...,     1,     3, 47280])\n",
      " array([    1, 72603,    35, ..., 66877,     5, 53167])]\n"
     ]
    }
   ],
   "source": [
    "print y_train\n",
    "print X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def batch_generator(publications, authors, batch_size, max_time):\n",
    "    \"\"\"Convert ids to data-matrix form.\"\"\"\n",
    "    all_w = []\n",
    "    all_y = []\n",
    "    for i, ids in enumerate(publications):\n",
    "        # Clip to multiple of max_time for convenience\n",
    "        clip_len = ((len(ids)-1) / batch_size) * batch_size\n",
    "        \n",
    "        input_w = ids[:clip_len]     # current word\n",
    "        target_y = ids[1:clip_len+1]  # next word\n",
    "        # Reshape so we can select columns\n",
    "        input_w = input_w.reshape([batch_size,-1])\n",
    "\n",
    "        for j in xrange(0, input_w.shape[1], max_time):\n",
    "            this_w = input_w[:,j:j+max_time]\n",
    "            all_w.append(this_w)\n",
    "            all_y.append(np.full_like(this_w, authors[i]))\n",
    "\n",
    "    # Yield batches in random order     \n",
    "    data = range(0, len(all_y)-1)\n",
    "    random.shuffle(data)   \n",
    "\n",
    "    for k in data:\n",
    "        yield all_w[k], all_y[k]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 4 4 4 4]\n",
      " [4 4 4 4 4]\n",
      " [4 4 4 4 4]\n",
      " [4 4 4 4 4]\n",
      " [4 4 4 4 4]\n",
      " [4 4 4 4 4]\n",
      " [4 4 4 4 4]\n",
      " [4 4 4 4 4]\n",
      " [4 4 4 4 4]\n",
      " [4 4 4 4 4]]\n",
      "[[   515     38    994      3     55]\n",
      " [     6      1  14093     30      7]\n",
      " [  8629 117527      2   4224      3]\n",
      " [     1    386     30      2    917]\n",
      " [    11   3161      8     56   4136]\n",
      " [    12     36    375      3     44]\n",
      " [    10   2192     82     21     78]\n",
      " [  1258     14     33     30    371]\n",
      " [     2      5   4866      2   1561]\n",
      " [    36   2364  49771    413      4]]\n"
     ]
    }
   ],
   "source": [
    "for i, (w, y) in enumerate(batch_generator(X_train, y_train, 10, 5)):\n",
    "    print y\n",
    "    print w \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_epoch(lm, session, batch_iterator,\n",
    "              train=False, verbose=False,\n",
    "              tick_s=10, learning_rate=0.1):\n",
    "    start_time = time.time()\n",
    "    tick_time = start_time  # for showing status\n",
    "    total_cost = 0.0  # total cost, summed over all words\n",
    "    total_batches = 0\n",
    "    total_words = 0\n",
    "\n",
    "    if train:\n",
    "        train_op = lm.train_step_\n",
    "        use_dropout = True\n",
    "    else:\n",
    "        train_op = tf.no_op()\n",
    "        use_dropout = False  # no dropout at test time\n",
    "\n",
    "    for i, (w, y) in enumerate(batch_iterator):\n",
    "        cost = 0.0\n",
    "        # At first batch in epoch, get a clean intitial state.\n",
    "        if i == 0:\n",
    "            h = session.run(lm.initial_h_, {lm.input_w_: w})\n",
    "            \n",
    "        feed_dict = {lm.input_w_: w,\n",
    "                     lm.target_y_: y,\n",
    "                     lm.initial_h_: h,\n",
    "                     lm.learning_rate_: learning_rate,\n",
    "                     lm.use_dropout_: use_dropout}\n",
    "        \n",
    "        _, h, cost = session.run([train_op, lm.final_h_, lm.loss_], feed_dict)  \n",
    "\n",
    "        total_cost += cost\n",
    "        total_batches = i + 1\n",
    "        total_words += w.size  # w.size = batch_size * max_time\n",
    "\n",
    "        ##\n",
    "        # Print average loss-so-far for epoch\n",
    "        # If using train_loss_, this may be an underestimate.\n",
    "        if verbose and (time.time() - tick_time >= tick_s):\n",
    "            avg_cost = total_cost / total_batches\n",
    "            avg_wps = total_words / (time.time() - start_time)\n",
    "            print \"[batch %d]: seen %d words at %d wps, loss = %.3f\" % (\n",
    "                i, total_words, avg_wps, avg_cost)\n",
    "            tick_time = time.time()  # reset time ticker\n",
    "\n",
    "    return total_cost / total_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score_dataset(lm, session, ids, authors, max_time, name=\"Data\"):\n",
    "    # For scoring, we can use larger batches to speed things up.\n",
    "    bi = batch_generator(ids, authors, batch_size=100, max_time=max_time)\n",
    "    cost = run_epoch(lm, session, bi, \n",
    "                     learning_rate=1.0, train=False, \n",
    "                     verbose=False, tick_s=3600)\n",
    "    print \"%s: avg. loss: %.03f  (perplexity: %.02f)\" % (name, cost, np.exp(cost))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_paper(lm, session, batch_iterator):\n",
    "    for i, (w, y) in enumerate(batch_iterator):        \n",
    "        feed_dict = {lm.input_w_: w,\n",
    "                     lm.target_y_: y}\n",
    "        \n",
    "        cost, truths, logits, predictions = session.run([lm.loss_, lm.target_y_last_, lm.logits_last_, lm.predictions_], feed_dict)  \n",
    "        print \"predictions:\", predictions.reshape(-1)\n",
    "        print \"truths:\", truths.reshape(-1)\n",
    "        print \"logits:\", logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "max_time = 15\n",
    "batch_size = 40\n",
    "learning_rate = 0.1\n",
    "num_epochs = 1\n",
    "\n",
    "# Model parameters\n",
    "model_params = dict(V=vocab.size, \n",
    "                    H=100, \n",
    "                    num_classes=num_classes,\n",
    "                    num_layers=1)\n",
    "\n",
    "TF_SAVEDIR = \"tf_saved\"\n",
    "checkpoint_filename = os.path.join(TF_SAVEDIR, \"rnnlm\")\n",
    "trained_filename = os.path.join(TF_SAVEDIR, \"rnnlm_trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] Starting epoch 1\n",
      "[batch 4557]: seen 2710000 words at 27097 wps, loss = 1.421\n",
      "[epoch 1] Completed in 0:02:13\n",
      "[epoch 1] Federalist Paper 18: avg. loss: 1.509  (perplexity: 4.52)\n",
      "\n",
      "predictions: [3 1 1 1 1 4 1 1 1 1 3 4 1 1 1 1 4 1 1 1 1 3 4 1 1 3 4 4 4 1 1 1 3 1 1 1 1\n",
      " 3 1 1]\n",
      "truths: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3]\n",
      "logits: [[[ 0.26530796  2.0033524  -2.41954088  2.5579915   2.43984413 -0.15790242\n",
      "   -3.57718945 -2.23421764 -2.04049754]]\n",
      "\n",
      " [[ 0.47454411  2.08166647 -2.94268799  1.39814627  1.63085508 -1.05434155\n",
      "   -2.54554152 -2.04491615 -0.38368887]]\n",
      "\n",
      " [[ 0.0630518   1.71351516 -2.10049605  1.52507532  1.64475787 -0.77790803\n",
      "   -2.48289609 -1.78943956 -0.84769511]]\n",
      "\n",
      " [[ 0.68611884  1.74850583 -2.42345905  0.53609884  1.43320549 -1.48981047\n",
      "   -2.60026455 -2.51207399  0.37313688]]\n",
      "\n",
      " [[ 0.10888016  1.8271066  -2.46813869  1.56725764  1.72297144 -1.26517963\n",
      "   -3.30124712 -2.24677014 -0.98890853]]\n",
      "\n",
      " [[ 0.67121893  1.96537244 -3.02723002  2.03199267  2.10165358 -0.40961722\n",
      "   -1.74654555 -1.46743643 -1.00586629]]\n",
      "\n",
      " [[ 0.15517694  2.17541838 -2.56508684  1.58496451  1.68905616 -1.60721684\n",
      "   -2.87681723 -2.53605771 -0.64566219]]\n",
      "\n",
      " [[ 0.08407465  1.75008297 -2.19714403  1.56929708  1.71350467 -0.75353855\n",
      "   -2.54073906 -2.01289034 -1.06731915]]\n",
      "\n",
      " [[ 0.36408192  2.35429454 -2.31427002  1.85553443  2.16471171 -0.90365916\n",
      "   -2.5824821  -2.19666553 -0.71032125]]\n",
      "\n",
      " [[ 0.38577294  1.9769305  -2.84549856  1.36137998  1.95474887 -0.99759442\n",
      "   -2.54298925 -2.06928945 -0.77593464]]\n",
      "\n",
      " [[-0.20046948  1.47681904 -2.45334125  1.57164669  1.54158223 -0.96601653\n",
      "   -2.51738238 -1.79598331 -1.33094239]]\n",
      "\n",
      " [[ 0.16238716  1.86858082 -2.69531465  1.68976688  1.93417513 -0.71779883\n",
      "   -1.94971323 -1.56619453 -1.01597452]]\n",
      "\n",
      " [[ 0.45214176  2.49032116 -3.6147933   1.23966312  1.68563437 -1.55793917\n",
      "   -3.09845114 -2.52061105 -0.74773037]]\n",
      "\n",
      " [[ 0.63555992  2.84818864 -3.22006679  1.28765678  1.55750453 -1.82784688\n",
      "   -2.50704122 -2.71893644  0.42650706]]\n",
      "\n",
      " [[ 0.12039745  2.29527926 -2.37352896  2.0355804   1.90350974 -1.06852841\n",
      "   -3.17683506 -2.18889713 -0.6236698 ]]\n",
      "\n",
      " [[ 0.52081001  2.24197197 -2.68721771  2.23769808  2.1278913  -0.65154159\n",
      "   -2.66678739 -1.93815732 -0.59945583]]\n",
      "\n",
      " [[ 0.14292195  1.76985931 -1.92399764  1.75019312  1.77591479 -0.70775187\n",
      "   -2.77384853 -1.58272529 -0.83339113]]\n",
      "\n",
      " [[-0.08773914  2.11015081 -2.47432828  2.0314393   1.93073332 -0.88055122\n",
      "   -3.05599332 -2.18938184 -1.35057223]]\n",
      "\n",
      " [[ 0.02959894  1.69462276 -2.60163546  1.4145366   1.5639782  -1.14874876\n",
      "   -2.68603206 -1.99308681 -0.91696733]]\n",
      "\n",
      " [[ 0.62592548  2.36847544 -2.96777678  0.89792848  1.4628638  -1.93702722\n",
      "   -2.32009077 -2.86892104  0.40530747]]\n",
      "\n",
      " [[ 0.43080807  2.23430467 -2.51356411  1.24536061  1.5691644  -1.2118988\n",
      "   -2.78336859 -2.25786519 -0.12119609]]\n",
      "\n",
      " [[ 0.15424758  1.81942153 -2.64928436  2.1253562   2.09482026 -0.80248016\n",
      "   -2.58086801 -1.63130426 -1.29205608]]\n",
      "\n",
      " [[ 0.04028435  1.75512147 -2.1800642   1.75449705  1.75537872 -0.64049351\n",
      "   -2.62151289 -1.63513005 -1.04128289]]\n",
      "\n",
      " [[ 0.42499012  2.41451645 -2.86234093  1.61085665  1.80391979 -1.27431989\n",
      "   -2.59715319 -2.62258792 -0.36598563]]\n",
      "\n",
      " [[ 0.38336664  2.08092523 -2.79923511  1.41284227  1.6595999  -1.04711199\n",
      "   -2.46703649 -2.08776736 -0.32128227]]\n",
      "\n",
      " [[-0.01252045  1.75299788 -2.20346689  2.58415532  2.3363533  -0.50015759\n",
      "   -3.02784824 -1.38790441 -2.1029911 ]]\n",
      "\n",
      " [[ 0.15793389  1.87573802 -2.32097864  1.7315892   1.92329192 -0.78325558\n",
      "   -2.47899199 -1.66954541 -0.98847759]]\n",
      "\n",
      " [[ 0.32051212  1.9199115  -2.60894871  1.7503283   1.99887109 -0.61723822\n",
      "   -2.44345093 -1.56947947 -0.84347749]]\n",
      "\n",
      " [[ 0.30109802  1.97564483 -2.5102067   1.97909713  2.05550957 -0.70242506\n",
      "   -2.74907088 -1.95069671 -1.22472763]]\n",
      "\n",
      " [[ 0.24328235  1.83806694 -2.34646225  1.45760655  1.54827905 -0.83338785\n",
      "   -2.36808872 -1.67277646 -1.20980918]]\n",
      "\n",
      " [[ 0.31814876  1.97071087 -2.31719065  1.05499077  1.2768836  -1.28487074\n",
      "   -2.34945774 -2.66844249 -0.13372254]]\n",
      "\n",
      " [[ 0.35588509  2.39519453 -2.02794981  1.80637527  1.79441643 -1.04566503\n",
      "   -2.66352558 -1.87758017  0.38893068]]\n",
      "\n",
      " [[ 0.32447413  1.78614044 -2.40239716  1.98197615  1.85392618 -0.39224702\n",
      "   -2.3658185  -1.31882179 -1.04849625]]\n",
      "\n",
      " [[ 0.27900022  2.24283767 -2.43097591  1.1291281   1.40589345 -1.43837404\n",
      "   -2.85829687 -2.13560629  0.13821256]]\n",
      "\n",
      " [[ 0.06744745  2.08157969 -2.83218098  0.58382523  1.07406843 -2.05309629\n",
      "   -2.28649139 -2.58264899  0.018498  ]]\n",
      "\n",
      " [[ 0.2606369   2.03744912 -2.30634403  1.73272312  1.8823005  -0.79333848\n",
      "   -2.81443024 -1.89570522 -0.87412095]]\n",
      "\n",
      " [[ 0.28238547  1.86361825 -2.59907532  1.19472849  1.42816186 -1.26362801\n",
      "   -2.40120173 -2.30171609 -0.62545896]]\n",
      "\n",
      " [[-0.04545832  1.6314708  -2.98432589  1.98775351  1.84810758 -0.47084975\n",
      "   -2.8177762  -1.58770823 -1.61832118]]\n",
      "\n",
      " [[ 0.28277397  2.0793457  -2.52190161  1.76033449  1.90760076 -0.81793672\n",
      "   -2.59607768 -1.74476814 -0.57791024]]\n",
      "\n",
      " [[ 0.24663869  1.78475785 -2.21143246  1.54074991  1.70041287 -0.65389556\n",
      "   -2.45361328 -1.75355065 -0.82301158]]]\n",
      "predictions: [1 4 4 1 1 1 1 4 3 1 1 1 1 1 3 1 1 1 1 1 4 1 4 4 1 1 1 4 1 1 4 1 1 4 1 1 1\n",
      " 1 1 1]\n",
      "truths: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3]\n",
      "logits: [[[  1.71937972e-01   1.84828448e+00  -2.57472992e+00   1.50072944e+00\n",
      "     1.68416119e+00  -1.24694920e+00  -2.44652796e+00  -1.95072198e+00\n",
      "    -6.82235599e-01]]\n",
      "\n",
      " [[  1.49902135e-01   1.74280941e+00  -2.31136346e+00   1.78187919e+00\n",
      "     1.98853302e+00  -6.07984781e-01  -2.52918482e+00  -1.57597256e+00\n",
      "    -1.26515555e+00]]\n",
      "\n",
      " [[  1.51583135e-01   1.75173199e+00  -2.15821218e+00   1.71822858e+00\n",
      "     1.86966813e+00  -5.63965976e-01  -2.65806198e+00  -1.67549360e+00\n",
      "    -1.14600468e+00]]\n",
      "\n",
      " [[  2.61044860e-01   2.02006030e+00  -2.75263977e+00   1.48588312e+00\n",
      "     1.79588151e+00  -9.88602519e-01  -2.00952911e+00  -2.06446409e+00\n",
      "    -7.87788570e-01]]\n",
      "\n",
      " [[  1.58694029e-01   1.75807166e+00  -2.31867337e+00   1.26593959e+00\n",
      "     1.55180609e+00  -1.06153822e+00  -2.66484976e+00  -2.06008625e+00\n",
      "    -7.87928939e-01]]\n",
      "\n",
      " [[  7.27850080e-01   2.46919513e+00  -2.43818665e+00   1.91619885e+00\n",
      "     1.99736440e+00  -9.38281059e-01  -2.10722589e+00  -1.47764552e+00\n",
      "     2.30569899e-01]]\n",
      "\n",
      " [[  4.57542241e-01   2.28294706e+00  -2.79267550e+00   1.20004010e+00\n",
      "     1.54265809e+00  -1.23275888e+00  -2.77351451e+00  -2.26245475e+00\n",
      "    -1.58785969e-01]]\n",
      "\n",
      " [[  1.57172114e-01   1.70384264e+00  -2.46715879e+00   1.92516530e+00\n",
      "     1.93037987e+00  -6.00151062e-01  -2.92442989e+00  -1.71316457e+00\n",
      "    -1.38612199e+00]]\n",
      "\n",
      " [[  1.77337319e-01   1.58349264e+00  -2.51740170e+00   1.94967675e+00\n",
      "     1.89461625e+00  -2.09582388e-01  -2.84488392e+00  -1.78276420e+00\n",
      "    -1.97424293e+00]]\n",
      "\n",
      " [[ -2.88578808e-01   1.83066726e+00  -2.71272397e+00   1.31132877e+00\n",
      "     1.44185472e+00  -1.71212912e+00  -2.65606403e+00  -1.92117286e+00\n",
      "    -5.10098338e-01]]\n",
      "\n",
      " [[  2.69262016e-01   2.00837851e+00  -2.55175900e+00   7.13635325e-01\n",
      "     1.14470267e+00  -1.45196211e+00  -2.62583303e+00  -2.50390887e+00\n",
      "    -1.16382569e-01]]\n",
      "\n",
      " [[  5.91736734e-01   2.87348771e+00  -3.75503874e+00   9.33607340e-01\n",
      "     1.52765381e+00  -2.26829004e+00  -3.38779116e+00  -2.88063812e+00\n",
      "     4.36159194e-01]]\n",
      "\n",
      " [[  4.21138585e-01   2.43120098e+00  -3.39654112e+00   1.09896338e+00\n",
      "     1.65147841e+00  -1.48723698e+00  -2.45728874e+00  -2.63811898e+00\n",
      "     1.13523364e-01]]\n",
      "\n",
      " [[  2.80759305e-01   2.10971260e+00  -2.54680538e+00   1.70435154e+00\n",
      "     1.75500846e+00  -1.09380734e+00  -3.16181254e+00  -2.16812992e+00\n",
      "    -3.05372715e-01]]\n",
      "\n",
      " [[  3.56987715e-02   1.84571505e+00  -2.38343191e+00   1.93473446e+00\n",
      "     1.86513245e+00  -6.42757952e-01  -2.61567497e+00  -1.68350244e+00\n",
      "    -1.12151194e+00]]\n",
      "\n",
      " [[  1.74591094e-01   2.16136336e+00  -2.42326641e+00   1.23164332e+00\n",
      "     1.45361578e+00  -1.49168491e+00  -3.02782416e+00  -2.27981663e+00\n",
      "    -2.43002176e-03]]\n",
      "\n",
      " [[  3.58139336e-01   2.15203238e+00  -2.46198416e+00   7.73513198e-01\n",
      "     1.32604957e+00  -1.34171581e+00  -2.75399733e+00  -2.47951555e+00\n",
      "     1.11747742e-01]]\n",
      "\n",
      " [[  1.88559532e-01   1.89021540e+00  -2.30414486e+00   1.25500500e+00\n",
      "     1.53715813e+00  -1.15303743e+00  -2.78782225e+00  -2.10885906e+00\n",
      "    -5.93484759e-01]]\n",
      "\n",
      " [[  2.84216881e-01   1.99648011e+00  -2.83523226e+00   1.48486686e+00\n",
      "     1.60047007e+00  -1.22798586e+00  -2.51244164e+00  -2.15844011e+00\n",
      "    -6.35334194e-01]]\n",
      "\n",
      " [[  4.43604231e-01   2.13447142e+00  -2.44033766e+00   1.63902104e+00\n",
      "     1.84409487e+00  -9.55235481e-01  -2.90586615e+00  -1.97698140e+00\n",
      "    -6.06400847e-01]]\n",
      "\n",
      " [[  3.32260191e-01   1.91891384e+00  -2.64966774e+00   1.98724031e+00\n",
      "     2.15766168e+00  -4.32685763e-01  -2.29774880e+00  -1.37181628e+00\n",
      "    -1.00971437e+00]]\n",
      "\n",
      " [[  3.90140593e-01   1.93454635e+00  -2.63443184e+00   9.65244293e-01\n",
      "     1.40159667e+00  -1.11560690e+00  -2.35494661e+00  -2.24471998e+00\n",
      "    -6.23322546e-01]]\n",
      "\n",
      " [[  2.83204019e-01   1.96890366e+00  -2.37597513e+00   2.02955103e+00\n",
      "     2.07139611e+00  -6.18111432e-01  -3.16905642e+00  -2.07370996e+00\n",
      "    -1.13866389e+00]]\n",
      "\n",
      " [[  1.41135067e-01   1.77871537e+00  -2.32665253e+00   1.99837053e+00\n",
      "     2.15694809e+00  -4.15144145e-01  -2.53740668e+00  -1.38925743e+00\n",
      "    -1.46476054e+00]]\n",
      "\n",
      " [[  2.05443561e-01   2.03829432e+00  -2.35811901e+00   1.61115193e+00\n",
      "     1.77338433e+00  -9.07501519e-01  -2.54615116e+00  -1.90450191e+00\n",
      "    -6.36899114e-01]]\n",
      "\n",
      " [[  3.50658119e-01   2.06898332e+00  -2.95816231e+00   9.22189951e-01\n",
      "     1.38268697e+00  -1.35685921e+00  -2.82484150e+00  -2.45002699e+00\n",
      "    -4.90631759e-01]]\n",
      "\n",
      " [[  4.68146503e-01   2.51717639e+00  -2.68412232e+00   1.90806842e+00\n",
      "     1.93843603e+00  -1.00808263e+00  -2.58373785e+00  -2.31932020e+00\n",
      "     3.30100656e-02]]\n",
      "\n",
      " [[  1.80919528e-01   1.85476410e+00  -2.51025677e+00   2.09117413e+00\n",
      "     2.19988394e+00  -2.23374248e-01  -2.13395333e+00  -1.49945652e+00\n",
      "    -1.50073099e+00]]\n",
      "\n",
      " [[  2.04206437e-01   2.10613728e+00  -2.52622128e+00   1.89284408e+00\n",
      "     2.08726311e+00  -9.11857605e-01  -2.29245758e+00  -1.78319979e+00\n",
      "    -1.17801189e+00]]\n",
      "\n",
      " [[  4.98624682e-01   2.31328702e+00  -2.69523716e+00   1.19633424e+00\n",
      "     1.55536091e+00  -1.37767434e+00  -2.24825692e+00  -2.29427576e+00\n",
      "     5.41508794e-02]]\n",
      "\n",
      " [[  2.32859612e-01   1.77913141e+00  -2.28449607e+00   1.84440494e+00\n",
      "     1.90996933e+00  -5.11219740e-01  -2.68671799e+00  -1.67945433e+00\n",
      "    -1.19567251e+00]]\n",
      "\n",
      " [[  3.07938963e-01   2.46207929e+00  -2.71954250e+00   1.26058447e+00\n",
      "     1.53823566e+00  -1.79956031e+00  -2.74196529e+00  -2.71362662e+00\n",
      "    -9.30113792e-02]]\n",
      "\n",
      " [[ -3.23597938e-02   1.72435391e+00  -2.64071608e+00   1.36642766e+00\n",
      "     1.52896225e+00  -9.18336987e-01  -2.20166469e+00  -2.13789272e+00\n",
      "    -1.27151060e+00]]\n",
      "\n",
      " [[  1.54345214e-01   1.62923443e+00  -2.49161959e+00   1.56782162e+00\n",
      "     1.76503158e+00  -7.46622980e-01  -2.34615374e+00  -2.12902117e+00\n",
      "    -1.33882225e+00]]\n",
      "\n",
      " [[  3.08941543e-01   2.15259838e+00  -2.32633948e+00   1.46988869e+00\n",
      "     1.67395699e+00  -1.35400128e+00  -3.09606218e+00  -2.38307762e+00\n",
      "    -5.66276431e-01]]\n",
      "\n",
      " [[  5.51449120e-01   2.48923111e+00  -2.88430882e+00   9.84858394e-01\n",
      "     1.38464081e+00  -1.78517389e+00  -2.84864116e+00  -2.58519530e+00\n",
      "     1.23741090e-01]]\n",
      "\n",
      " [[  2.81545967e-01   2.55186105e+00  -2.94724441e+00   1.76442301e+00\n",
      "     1.66470265e+00  -1.44318748e+00  -2.98444819e+00  -2.61109042e+00\n",
      "     5.90103865e-03]]\n",
      "\n",
      " [[  4.02373254e-01   2.09330845e+00  -2.59002447e+00   1.19604647e+00\n",
      "     1.46848273e+00  -1.11739278e+00  -2.79402637e+00  -2.18740082e+00\n",
      "    -5.79212248e-01]]\n",
      "\n",
      " [[  2.82281786e-01   1.88605666e+00  -2.30504131e+00   1.53674006e+00\n",
      "     1.71010864e+00  -9.66403484e-01  -2.44325018e+00  -1.93751526e+00\n",
      "    -8.03318739e-01]]\n",
      "\n",
      " [[  8.18045676e-01   2.56845880e+00  -2.89779949e+00   9.06935334e-01\n",
      "     1.40389705e+00  -1.42054009e+00  -2.37933540e+00  -2.36948967e+00\n",
      "     4.85749662e-01]]]\n",
      "predictions: [4 1 3 1 1 1 1 1 1 4 4 1 1 4 1 1 4 4 3 1 1 4 1 4 4 1 1 1 4 4 1 4 1 1 1 1 1\n",
      " 1 1 4]\n",
      "truths: [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3]\n",
      "logits: [[[ 0.38556141  1.8282603  -2.53034401  1.61095524  1.83608139 -0.68311477\n",
      "   -2.23376107 -1.55480587 -0.6980505 ]]\n",
      "\n",
      " [[ 0.1967428   2.00695777 -2.26564765  1.65949833  1.80537796 -0.92595834\n",
      "   -2.66403294 -1.90241742 -0.64533097]]\n",
      "\n",
      " [[ 0.01253816  1.80031085 -2.27734971  2.00614715  1.95591867 -0.41755664\n",
      "   -2.50580263 -1.52580571 -1.31543851]]\n",
      "\n",
      " [[ 0.08412749  1.99789023 -2.64356542  1.38957679  1.68435621 -1.33013701\n",
      "   -2.7989409  -2.54961705 -0.31483841]]\n",
      "\n",
      " [[ 0.10066047  2.25083494 -2.56880808  2.24324441  2.05646229 -0.85507703\n",
      "   -2.85153937 -1.92925763 -0.87894469]]\n",
      "\n",
      " [[ 0.30311918  2.07826519 -2.45362234  1.43277562  1.4577955  -1.1570456\n",
      "   -2.83010912 -1.96756744 -0.57150275]]\n",
      "\n",
      " [[ 0.19267985  1.88558865 -2.45747519  1.55647826  1.74376535 -0.75626683\n",
      "   -2.42193365 -1.96480727 -1.07333517]]\n",
      "\n",
      " [[ 0.3376956   2.07362628 -2.72070789  1.56812012  1.67505193 -0.87882882\n",
      "   -2.52194405 -2.25413775 -0.52932787]]\n",
      "\n",
      " [[ 1.13680363  2.96781707 -2.84058046  1.25466847  1.73082197 -1.61453271\n",
      "   -2.13486433 -2.20422602  1.22424603]]\n",
      "\n",
      " [[-0.08127227  1.58038437 -2.34676027  1.65965736  1.82293069 -0.7370491\n",
      "   -2.57157993 -1.75637245 -1.58095908]]\n",
      "\n",
      " [[ 0.02254958  1.82659769 -2.66778469  2.09363484  2.17504406 -0.77028185\n",
      "   -2.50407648 -1.57977009 -1.84959292]]\n",
      "\n",
      " [[ 0.42103177  2.13638639 -2.67404127  1.61508274  1.84856713 -0.78937429\n",
      "   -2.5555048  -1.83859897 -0.40375391]]\n",
      "\n",
      " [[ 0.83139902  2.9459281  -2.5472908   1.14229357  1.84093261 -1.77057886\n",
      "   -2.9663353  -2.4012742   0.80347675]]\n",
      "\n",
      " [[ 0.13243747  1.77282989 -2.56988573  2.01409888  2.10884881 -0.39960033\n",
      "   -2.08617902 -1.6151588  -1.40334475]]\n",
      "\n",
      " [[ 0.52047867  2.22695017 -2.55484295  1.20730555  1.58926737 -1.28837323\n",
      "   -2.7027154  -2.17721987 -0.05180314]]\n",
      "\n",
      " [[ 0.21825176  1.86311758 -2.49870539  1.60635734  1.73917222 -0.67594564\n",
      "   -2.91449976 -1.95656753 -1.07907176]]\n",
      "\n",
      " [[-0.03281936  1.53284276 -2.50041533  1.73308027  1.75780785 -0.64431399\n",
      "   -2.12898326 -1.30983424 -1.67926836]]\n",
      "\n",
      " [[ 0.32470608  1.78021562 -2.65366578  1.76465499  1.99226975 -0.60747677\n",
      "   -2.34138894 -1.52787173 -1.00326633]]\n",
      "\n",
      " [[-0.02717444  1.92946637 -2.51737595  2.15691185  2.06018138 -0.78587031\n",
      "   -2.81742859 -1.40762997 -0.97344798]]\n",
      "\n",
      " [[ 0.41074049  2.1668644  -2.68991947  1.39743423  1.70233977 -1.04389966\n",
      "   -2.67246008 -2.11980844 -0.27748802]]\n",
      "\n",
      " [[ 0.01966406  2.04339981 -2.40089035  1.66657722  1.88420653 -0.92211819\n",
      "   -3.28822613 -2.08619499 -0.83549696]]\n",
      "\n",
      " [[ 0.09557605  1.60596776 -2.64341879  1.8330462   1.84602988 -0.56926793\n",
      "   -2.40812349 -1.66476107 -1.28575826]]\n",
      "\n",
      " [[ 0.25814557  2.2614634  -3.0364213   1.3650558   1.54675508 -1.28581214\n",
      "   -2.96470189 -2.65586019 -0.30037451]]\n",
      "\n",
      " [[ 0.27994362  2.01560736 -2.59244347  2.16668105  2.17606521 -1.22024143\n",
      "   -2.56574106 -1.7273221  -0.7772069 ]]\n",
      "\n",
      " [[-0.0820176   1.45900714 -2.64017749  1.58363152  1.70868564 -0.67514026\n",
      "   -2.88016415 -2.22334146 -1.50497293]]\n",
      "\n",
      " [[ 0.02985285  2.11462522 -2.32960939  1.31011093  1.58436346 -1.35808539\n",
      "   -2.52278662 -2.03199911 -0.59300768]]\n",
      "\n",
      " [[ 0.63729262  2.38616109 -2.59381008  1.12183571  1.6482538  -1.42477727\n",
      "   -2.65024281 -2.2226181   0.06183523]]\n",
      "\n",
      " [[ 0.33882588  1.99390817 -2.73107576  1.9007628   1.94575751 -0.6485061\n",
      "   -1.93980122 -2.05501938 -0.83797169]]\n",
      "\n",
      " [[ 0.05719124  1.68480563 -2.37733412  1.7783078   1.78303039 -0.49819317\n",
      "   -3.04593515 -1.70151806 -1.46536422]]\n",
      "\n",
      " [[ 0.01307409  1.5080688  -2.42072439  1.63058162  1.76679051 -1.03945804\n",
      "   -2.13830781 -2.33025169 -1.30412316]]\n",
      "\n",
      " [[ 0.07471573  1.76466191 -2.68781853  1.18424451  1.13454604 -1.21193612\n",
      "   -2.6336112  -2.55243182 -0.37310252]]\n",
      "\n",
      " [[ 0.14813754  2.00565791 -3.41075706  2.39693904  2.41476178 -0.28582278\n",
      "   -2.71229053 -1.77599883 -1.94137478]]\n",
      "\n",
      " [[ 0.59010738  2.58214664 -2.99317455  1.01390946  1.4589678  -1.95115483\n",
      "   -2.97712159 -2.81813383  0.23018318]]\n",
      "\n",
      " [[ 0.26137316  2.33720708 -2.77873564  2.13163471  2.15833116 -1.03596163\n",
      "   -2.70244813 -2.46428847 -1.2024157 ]]\n",
      "\n",
      " [[ 0.75023013  2.22146344 -2.64935088  0.88503349  1.40670156 -1.75244856\n",
      "   -2.32609797 -2.30564332  0.33147901]]\n",
      "\n",
      " [[ 0.30416673  2.03162861 -2.38953209  1.29192781  1.50218046 -1.07945979\n",
      "   -2.98401904 -2.4492662  -0.37983769]]\n",
      "\n",
      " [[ 0.18997386  2.43339992 -2.78891563  1.91457379  1.70321941 -1.29333258\n",
      "   -2.86485362 -2.20246792 -0.15296507]]\n",
      "\n",
      " [[ 0.53690279  2.27157879 -2.80179787  1.58911669  1.9813298  -1.2560513\n",
      "   -2.44834733 -1.90496635 -0.91327393]]\n",
      "\n",
      " [[ 0.59042132  2.2041657  -2.46036577  1.23526299  1.51691043 -1.18253946\n",
      "   -2.18748355 -2.02646613  0.0906232 ]]\n",
      "\n",
      " [[ 0.30813828  2.00305653 -2.29943228  2.06782961  2.18692493 -0.76092327\n",
      "   -2.90674019 -1.7613138  -1.2826345 ]]]\n"
     ]
    }
   ],
   "source": [
    "reload(rnnlm)\n",
    "# Will print status every this many seconds\n",
    "print_interval = 5\n",
    "\n",
    "# Clear old log directory\n",
    "shutil.rmtree(\"tf_summaries\", ignore_errors=True)\n",
    "\n",
    "lm = rnnlm.RNNLM(**model_params)\n",
    "lm.BuildCoreGraph()\n",
    "lm.BuildTrainGraph()\n",
    "lm.BuildClassifierGraph()\n",
    "\n",
    "# Explicitly add global initializer and variable saver to LM graph\n",
    "with lm.graph.as_default():\n",
    "    initializer = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "# Clear old log directory\n",
    "shutil.rmtree(TF_SAVEDIR, ignore_errors=True)\n",
    "if not os.path.isdir(TF_SAVEDIR):\n",
    "    os.makedirs(TF_SAVEDIR)\n",
    "\n",
    "with tf.Session(graph=lm.graph) as session:\n",
    "    # Seed RNG for repeatability\n",
    "    tf.set_random_seed(42)\n",
    "\n",
    "    session.run(initializer)\n",
    "\n",
    "    for epoch in xrange(1,num_epochs+1):\n",
    "        t0_epoch = time.time()\n",
    "        bi = batch_generator(X_train, y_train, batch_size, max_time)\n",
    "        print \"[epoch %d] Starting epoch %d\" % (epoch, epoch)\n",
    "        # Run a training epoch.\n",
    "\n",
    "        run_epoch(lm, session, bi, train=True, verbose=True, tick_s=100, learning_rate=learning_rate)\n",
    "    \n",
    "        print \"[epoch %d] Completed in %s\" % (epoch, pretty_timedelta(since=t0_epoch))\n",
    "    \n",
    "        # Save a checkpoint\n",
    "        saver.save(session, checkpoint_filename, global_step=epoch)\n",
    "    \n",
    "        ##\n",
    "        # score_dataset will run a forward pass over the entire dataset\n",
    "        # and report perplexity scores. This can be slow (around 1/2 to \n",
    "        # 1/4 as long as a full epoch), so you may want to comment it out\n",
    "        # to speed up training on a slow machine. Be sure to run it at the \n",
    "        # end to evaluate your score.\n",
    "        print (\"[epoch %d]\" % epoch),\n",
    "        score_dataset(lm, session, eval_X['18'], eval_y['18'], max_time, name=\"Federalist Paper 18\")\n",
    "        #score_dataset(lm, session, test_ids, name=\"Test set\")\n",
    "        print \"\"\n",
    "\n",
    "    bi = batch_generator(eval_X['18'], eval_y['18'], batch_size, max_time)\n",
    "    predict_paper(lm, session, bi)\n",
    "    # Save final model\n",
    "    saver.save(session, trained_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "7\n",
      "{'thomas_jefferson': 1, 'john_adams': 2, 'alexander_hamilton': 4, 'george_washington': 7, 'thomas_paine': 0, 'james_madison': 3, 'james_monroe': 5, 'john_jay': 6}\n"
     ]
    }
   ],
   "source": [
    "print author_to_id['james_madison']\n",
    "print author_to_id['george_washington']\n",
    "print author_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

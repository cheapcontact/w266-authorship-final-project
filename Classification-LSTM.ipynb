{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json, os, re, shutil, sys, time\n",
    "import collections, itertools\n",
    "import unittest\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# NLTK for NLP utils and corpora\n",
    "import nltk\n",
    "\n",
    "# NumPy and TensorFlow\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "assert(tf.__version__.startswith(\"1.\"))\n",
    "\n",
    "# utils.pretty_print_matrix uses Pandas. Configure float format here.\n",
    "import pandas as pd\n",
    "pd.set_option('float_format', lambda f: \"{0:.04f}\".format(f))\n",
    "\n",
    "# RNNLM Model\n",
    "import rnnlm\n",
    "reload(rnnlm)\n",
    "\n",
    "# Other imports\n",
    "from datetime import datetime\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vocabulary class holds the vocabulary and the mapping between words and ids for the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "'''Vocabulary class, nearly identical to that used in a4'''\n",
    "class Vocabulary(object):\n",
    "\n",
    "  UNK_TOKEN = \"<unk>\"\n",
    "\n",
    "  def __init__(self, tokens, size=None):\n",
    "    self.unigram_counts = collections.Counter(tokens)\n",
    "    # leave space for \"<unk>\"\n",
    "    top_counts = self.unigram_counts.most_common(None if size is None else (size - 1))\n",
    "    vocab = ([self.UNK_TOKEN] +\n",
    "             [w for w,c in top_counts])\n",
    "\n",
    "    # Assign an id to each word, by frequency\n",
    "    self.id_to_word = dict(enumerate(vocab))\n",
    "    self.word_to_id = {v:k for k,v in self.id_to_word.iteritems()}\n",
    "    self.size = len(self.id_to_word)\n",
    "    if size is not None:\n",
    "        assert(self.size <= size)\n",
    "\n",
    "    # For convenience\n",
    "    self.wordset = set(self.word_to_id.iterkeys())\n",
    "\n",
    "    # Store special IDs\n",
    "    self.UNK_ID = self.word_to_id[self.UNK_TOKEN]\n",
    "\n",
    "  def words_to_ids(self, words):\n",
    "    return [self.word_to_id.get(w, self.UNK_ID) for w in words]\n",
    "\n",
    "  def ids_to_words(self, ids):\n",
    "    return [self.id_to_word[i] for i in ids]\n",
    "\n",
    "  def ordered_words(self):\n",
    "    \"\"\"Return a list of words, ordered by id.\"\"\"\n",
    "    return self.ids_to_words(range(self.size))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These functions are used to massage the cleaned data into indivdual words. Punctuation at the end of a word is split into its own distince word. Also accomplishes some minor data cleaning, removing nonsense characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import re\n",
    "\n",
    "def canonicalize_digits(word):\n",
    "    if any([c.isalpha() for c in word]): return word\n",
    "    word = re.sub(\"\\d\", \"DG\", word)\n",
    "    if word.startswith(\"DG\"):\n",
    "        word = word.replace(\",\", \"\") # remove thousands separator\n",
    "    return word\n",
    "\n",
    "def canonicalize_word(word):\n",
    "    word = word.lower()\n",
    "    return canonicalize_digits(word) # try to canonicalize numbers\n",
    "\n",
    "def replace_all(text, dic):\n",
    "    for i, j in dic.iteritems():\n",
    "        text = text.replace(i, j)\n",
    "    return text\n",
    "\n",
    "def canonicalize_words(words):\n",
    "    current = []\n",
    "    rep_dict = {'\\n':' '\n",
    "                ,'\\xc2':' '\n",
    "                ,'\\xa0':' '\n",
    "                ,'\\xc2':' '\n",
    "                ,'\\xc3':' '\n",
    "                ,'\\xa9':' '\n",
    "                ,'\\xef':' '\n",
    "                ,'\\xbb':' '\n",
    "                ,'\\xbf':' '\n",
    "                ,'\\xa6':' '\n",
    "                ,'\\xb9':' '\n",
    "                ,'\\xa3':' '\n",
    "                ,'\\xbd':' '\n",
    "                ,'\\xb4':' '\n",
    "                ,'\\xcb':' '\n",
    "                ,'\\x9a':' '\n",
    "                ,'\\x86':' '\n",
    "                ,'\\xcf':' '\n",
    "                ,'\\x84':' '\n",
    "                ,'\\xce':' '\n",
    "                ,'\\x87':' '\n",
    "                ,'\\xe2':' '\n",
    "                ,'\\x80':' '\n",
    "                ,'\\x94':' '\n",
    "               }\n",
    "    for word in replace_all(words, rep_dict).split(' '):   \n",
    "        if word:\n",
    "            if word[-1] in ('.', ',', '?', ';', '!'):\n",
    "                punk = word[-1]\n",
    "                current.append(punk)\n",
    "                word = word[0:-1]\n",
    "\n",
    "            word = canonicalize_word(word)\n",
    "            current.append(word)\n",
    "    return current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pretty_timedelta(fmt=\"%d:%02d:%02d\", since=None, until=None):\n",
    "    \"\"\"Pretty-print a timedelta, using the given format string.\"\"\"\n",
    "    since = since or time.time()\n",
    "    until = until or time.time()\n",
    "    delta_s = until - since\n",
    "    hours, remainder = divmod(delta_s, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    return fmt % (hours, minutes, seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load_train_data reads in everything in train_data directory from which it generates the vocab (of type Vocabulary defined above), the author_to_id map (which maps author names to ids) and two arrays, one contains the text of each file (as a list of word ids) under \"train_data\". The other holds the author id for each of the texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_train_data(train_data_dir):\n",
    "    y = []\n",
    "    X = []\n",
    "    all_tokens = []\n",
    "    author_to_id = {}\n",
    "    for author_id, author in enumerate(listdir(train_data_dir)):\n",
    "        author_to_id[author] = author_id\n",
    "        author_path = \"%s/%s\" % (train_data_dir, author)\n",
    "        print author, author_id\n",
    "\n",
    "        for file_name in listdir(author_path):\n",
    "            full_path = \"%s/%s\" % (author_path, file_name)\n",
    "            y.append(author_id)            \n",
    "            with open(full_path, \"r\") as f:\n",
    "                current = canonicalize_words(f.read())\n",
    "                all_tokens += current\n",
    "                X.append(np.array(current))\n",
    "                \n",
    "    vocab = Vocabulary(all_tokens)\n",
    "\n",
    "    # replace words with ids\n",
    "    for i, x in enumerate(X):\n",
    "        # X[i] = np.array(x) # This line can be used to make sure your words are useful \n",
    "        X[i] = np.array(vocab.words_to_ids(x))\n",
    "\n",
    "    return vocab, np.array(X), np.array(y), author_to_id\n",
    "\n",
    "\n",
    "def id_to_author(author_to_id, id):\n",
    "    for author, author_id in author_to_id.iteritems():\n",
    "        if id == author_id:\n",
    "            return author"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we load the training data, note resulting number of classes (authors) and display some useful information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "james_madison 0\n",
      "alexander_hamilton 1\n",
      "john_jay 2\n",
      "vocab.size 3560\n",
      "{'james_madison': 0, 'john_jay': 2, 'alexander_hamilton': 1}\n"
     ]
    }
   ],
   "source": [
    "train_data_dir = './train_data_small'\n",
    "vocab, X_train, y_train, author_to_id = load_train_data(train_data_dir)\n",
    "num_classes = len(np.unique(y_train))\n",
    "print \"vocab.size\", vocab.size\n",
    "print author_to_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the eval data in the same format as the training data. But each federalist paper here ends up in its own dictionary entry so that they can be scored/classified/attributed separately. Each is assumed to be written by James Madison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[[294   1 175 ...,  93   6 383]]\n",
      "Who wrote Federalist paper 5 (John Jay should be answer): john_jay\n"
     ]
    }
   ],
   "source": [
    "def load_eval_data(vocab, eval_data_dir):\n",
    "    eval_X = {}\n",
    "    eval_y = {}\n",
    "    \n",
    "    for author_id, author in enumerate(listdir(eval_data_dir)):\n",
    "        author_path = \"%s/%s\" % (eval_data_dir, author)\n",
    "\n",
    "        for file_name in listdir(author_path):\n",
    "            full_path = \"%s/%s\" % (author_path, file_name)\n",
    "            \n",
    "            with open(full_path, \"r\") as f:\n",
    "                current = vocab.words_to_ids(canonicalize_words(f.read()))\n",
    "                \n",
    "            expanded_X = np.array(current)\n",
    "            id = file_name.split(\"_\")[2].split(\".\")[0]\n",
    "            eval_X[id] = np.array([expanded_X])\n",
    "            eval_y[id] = np.array([author_to_id[author]])\n",
    "                \n",
    "    return eval_X, eval_y\n",
    "\n",
    "eval_X, eval_y = load_eval_data(vocab, \"unknown_data\")\n",
    "print eval_y['18']\n",
    "print eval_X['18']\n",
    "\n",
    "test_X, test_y = load_eval_data(vocab, \"test_data\")\n",
    "print \"Who wrote Federalist paper 5 (John Jay should be answer): %s\" % id_to_author(author_to_id, test_y['5'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cut up the publications based on batch_size, and max_time. To reduce how much code had to be changed from a4 this expands the author id for each document to be an author id for each word in the document. So if you had publication[1] = [1 2 3] and authors[1] = 1, this would output (assuming a batch of 1 and max time of 3) w = [1 2 3] and y = [1 1 1]. In the end we'll ignore all the loss for everything except the last word, but all the matrix functions and multiplications could work as is if I kept expanded the author to be associated with each word (since that is what the sequence math was doing, each word had a corresponding target word). Note: this also randomly shuffles the batches so that an given author's data is mixed through out the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['hello', 'I', 'am'], ['mr', '.', 'anderson'], ['what', 'is', 'your']]"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def slice_up_words(words, window_size=10, step_size=1):\n",
    "    clip_len = ((len(words)-1) / window_size) * window_size\n",
    "    words = words[:clip_len]\n",
    "    slices = []\n",
    "    num_words = len(words)\n",
    "    for index in range(0, num_words, step_size):\n",
    "        slices.append(words[index:index+window_size])\n",
    "    return slices\n",
    "        \n",
    "slice_up_words([\"hello\", \"I\", \"am\", \"mr\", \".\", \"anderson\", \"what\", \"is\", \"your\", \"name\", \"?\"], 3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "# maybe worth seeding here. or in the batch_generator function\n",
    "\n",
    "def shape_data_for_batching(publications, authors, max_time):\n",
    "    \"\"\"Convert ids to data-matrix form.\"\"\"\n",
    "    all_w = None\n",
    "    all_y = []\n",
    "    for i, ids in enumerate(publications):\n",
    "        ids = np.array(slice_up_words(ids, max_time, max_time))\n",
    "        y = np.full_like(ids, authors[i])\n",
    "        \n",
    "        if all_w is not None:\n",
    "            all_w = np.append(all_w, ids, 0)\n",
    "            all_y = np.append(all_y, y, 0)\n",
    "            \n",
    "        else:\n",
    "            all_w = ids\n",
    "            all_y = y\n",
    "\n",
    "    # Yield batches in random order     \n",
    "    index = range(0, len(all_y)-1)\n",
    "    random.shuffle(index)   \n",
    "\n",
    "    all_w = [all_w[i] for i in index]\n",
    "    all_y = [all_y[i] for i in index]\n",
    "\n",
    "    return all_w, all_y\n",
    "\n",
    "def batch_generator(X_shaped, y_shaped, batch_size):\n",
    "    clip_len = ((len(X_shaped)-1) / batch_size) * batch_size\n",
    "    X_shaped = X_shaped[:clip_len]\n",
    "    y_shaped = y_shaped[:clip_len]  \n",
    "    for j in xrange(0, len(X_shaped), batch_size):\n",
    "        this_x = X_shaped[j:j+batch_size]\n",
    "        this_y = y_shaped[j:j+batch_size]\n",
    "        yield np.array(this_x), np.array(this_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sanity Check\n",
    "X_shaped, y_shaped = shape_data_for_batching(X_train, y_train, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 2 2 2 2]\n",
      " [2 2 2 2 2]\n",
      " [0 0 0 0 0]\n",
      " [1 1 1 1 1]\n",
      " [2 2 2 2 2]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [0 0 0 0 0]\n",
      " [1 1 1 1 1]\n",
      " [2 2 2 2 2]]\n",
      "[[   3  602    5    2  471]\n",
      " [ 970    7    1   68    3]\n",
      " [1360  317    7   18  120]\n",
      " [2179    3    9  174    2]\n",
      " [  15    9  131   75 3180]\n",
      " [2758 3526   65 2767    5]\n",
      " [   1  262  292   66    6]\n",
      " [   2  531  273    4    1]\n",
      " [   5   22    1  237    3]\n",
      " [  17   90    2   32 1465]]\n"
     ]
    }
   ],
   "source": [
    "for i, (w, y) in enumerate(batch_generator(X_shaped, y_shaped, 10)):\n",
    "    print y\n",
    "    print w \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Runs the epoch. Mostly the same as a4, but there is no test phase (instead there is no a separate prediction phase) that didn't makes as much sense to me to have in this function, so it has its own function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_epoch(lm, session, batch_iterator,\n",
    "              train=False, verbose=False,\n",
    "              tick_s=10, learning_rate=0.1):\n",
    "    start_time = time.time()\n",
    "    tick_time = start_time  # for showing status\n",
    "    total_cost = 0.0  # total cost, summed over all words\n",
    "    total_batches = 0\n",
    "    total_words = 0\n",
    "\n",
    "    if train:\n",
    "        train_op = lm.train_step_\n",
    "        use_dropout = True\n",
    "    else:\n",
    "        train_op = tf.no_op()\n",
    "        use_dropout = False  # no dropout at test time\n",
    "\n",
    "    for i, (w, y) in enumerate(batch_iterator):\n",
    "        cost = 0.0\n",
    "        # At first batch in epoch, get a clean intitial state.\n",
    "        if i == 0:\n",
    "            h = session.run(lm.initial_h_, {lm.input_w_: w})\n",
    "            \n",
    "        feed_dict = {lm.input_w_: w,\n",
    "                     lm.target_y_: y,\n",
    "                     lm.initial_h_: h,\n",
    "                     lm.learning_rate_: learning_rate,\n",
    "                     lm.use_dropout_: use_dropout}\n",
    "        \n",
    "        _, h, cost = session.run([train_op, lm.final_h_, lm.loss_], feed_dict)  \n",
    "\n",
    "        total_cost += cost\n",
    "        total_batches = i + 1\n",
    "        total_words += w.size  # w.size = batch_size * max_time\n",
    "\n",
    "        ##\n",
    "        # Print average loss-so-far for epoch\n",
    "        # If using train_loss_, this may be an underestimate.\n",
    "        if verbose and (time.time() - tick_time >= tick_s):\n",
    "            avg_cost = total_cost / total_batches\n",
    "            avg_wps = total_words / (time.time() - start_time)\n",
    "            print \"[batch %d]: seen %d words at %d wps, loss = %.3f\" % (\n",
    "                i, total_words, avg_wps, avg_cost)\n",
    "            tick_time = time.time()  # reset time ticker\n",
    "\n",
    "    return total_cost / total_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score_dataset(lm, session, ids, authors, max_time, name=\"Data\"):\n",
    "    # For scoring, we can use larger batches to speed things up. Same as a4\n",
    "    bi = batch_generator(ids, authors, batch_size=100, max_time=max_time)\n",
    "    cost = run_epoch(lm, session, bi, \n",
    "                     learning_rate=1.0, train=False, \n",
    "                     verbose=False, tick_s=3600)\n",
    "    print \"%s: avg. loss: %.03f  (perplexity: %.02f)\" % (name, cost, np.exp(cost))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions used to predict a batch iterators data. Used post training to test the unknown federalist papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Summary:\n",
      "alexander_hamilton: 0.50\n",
      "john_jay: 0.50\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: 0.5, 2: 0.5}"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def get_prediction_results(predictions, author_to_id, print_results=True):\n",
    "    '''\n",
    "    Takes the predictions for a set of text batches and calculates the percentage\n",
    "    of patches predicted for each author.\n",
    "    '''\n",
    "    counts = defaultdict(float)\n",
    "    for p in predictions:\n",
    "        counts[p] += 1\n",
    "\n",
    "    # getting prediction percentages to return for later viewing\n",
    "    predictions_num = len(predictions)\n",
    "    results_dict = {author_id:float(count)/predictions_num for author_id, count in counts.iteritems()}\n",
    "    \n",
    "    if print_results:\n",
    "        # prints results if indicated\n",
    "        print \"Prediction Summary:\"\n",
    "        for author_id, prediction in results_dict.iteritems():\n",
    "            print \"%s: %.2f\" % (id_to_author(author_to_id, author_id), prediction)\n",
    "        print \"\"\n",
    "\n",
    "    return results_dict\n",
    "    \n",
    "def predict_paper(lm, session, batch_iterator, authors, paper_name, print_results=True):\n",
    "    '''\n",
    "    Splits given paper into batches and predicts the author for each batch.\n",
    "    Passes these predictions to get_prediction_results() to tally the batches for each author\n",
    "    and arrive at a final prediction percentage.\n",
    "    '''\n",
    "    total_predictions = np.array([])\n",
    "    if print_results:\n",
    "        print \"Predicting for %s\" % paper_name\n",
    "    for i, (w, y) in enumerate(batch_iterator):        \n",
    "        if i == 0 and print_results:\n",
    "            print \"Truth:\", id_to_author(authors, y[0][0])\n",
    "            \n",
    "        feed_dict = {lm.input_w_: w,\n",
    "                     lm.target_y_: y}\n",
    "        \n",
    "        cost, truths, logits, predictions = session.run([lm.loss_, lm.target_y_last_, lm.logits_last_, lm.predictions_], feed_dict)  \n",
    "        total_predictions = np.append(total_predictions, predictions.reshape(-1))\n",
    "\n",
    "    # gets final predictions, by author, for the given paper\n",
    "    results_dict = get_prediction_results(total_predictions, authors, print_results=print_results)\n",
    "    return results_dict\n",
    "\n",
    "def test_papers(lm, session, papers, labels, authors, batch_size, print_results=True):\n",
    "    '''\n",
    "    Predicts authorship for given papers.\n",
    "    Returns a dictionary of dictionaries containing the predictions by author for each paper.\n",
    "    '''\n",
    "    full_results = dict()\n",
    "    for key in papers:\n",
    "        prediction_bi = batch_generator(papers[key], labels[key], batch_size)\n",
    "        paper_results = predict_paper(lm, session, prediction_bi, authors, \"Federalist Paper %s\" % key, print_results=print_results)\n",
    "        full_results[key] = paper_results\n",
    "    \n",
    "    return full_results\n",
    "\n",
    "def create_predictions_dataframe(epoch_predictions):\n",
    "    '''\n",
    "    Input: List of predictions for each epoch, where an epochs predictions is a dictionary of dictionaries containing\n",
    "    the predictions for each paper by author.\n",
    "    Output: Pandas dataframe of results for each author by paper, with a flag indicating the epoch.\n",
    "    '''\n",
    "    df_list = []\n",
    "    for epoch in range(len(epoch_predictions)):\n",
    "        epoch_num = epoch + 1 # we indexed our epochs from 1, but this list is 0-indexed of course\n",
    "        df = pd.DataFrame(epoch_predictions[epoch])\n",
    "        df['epoch'] = epoch_num\n",
    "        df_list.append(df)\n",
    "\n",
    "    return pd.concat(df_list)\n",
    "\n",
    "def save_results(save_dir):\n",
    "    '''\n",
    "    Saves results dataframe to csv, pickles the author_to_id dictionary, and creates\n",
    "    a text file with relevant settings that this model was trained with.\n",
    "    This function is lazy and calls the objects from out of scope rather than passing, but\n",
    "    it will do for now.\n",
    "    '''\n",
    "    # Creating directory\n",
    "    shutil.rmtree(RESULTS_SAVE_DIR, ignore_errors=True)\n",
    "    if not os.path.isdir(RESULTS_SAVE_DIR):\n",
    "        os.makedirs(RESULTS_SAVE_DIR)\n",
    "    df.to_csv(save_dir + '/results.csv')\n",
    "    pickle.dump(author_to_id, open(save_dir + '/author_to_id.p', 'wb'))\n",
    "    save_parms = {'max_time':max_time, 'batch_size':batch_size, 'learning_rate':learning_rate,\n",
    "                  'num_epochs':num_epochs, 'train_data_dir':train_data_dir}\n",
    "    with open(save_dir + '/parms.txt', 'w') as f:\n",
    "        for parm, val in save_parms.iteritems():\n",
    "            f.write(parm + ' : ' + str(val) + '\\n')\n",
    "    \n",
    "get_prediction_results([1, 2, 1, 2], author_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "max_time = 15\n",
    "batch_size = 50\n",
    "learning_rate = 0.08\n",
    "num_epochs = 300\n",
    "\n",
    "save_predictions = True # flag to determine if we save the predictions on unkown papers in each epoch\n",
    "\n",
    "# Model parameters\n",
    "model_params = dict(V=vocab.size, \n",
    "                    H=100, \n",
    "                    num_classes=num_classes,\n",
    "                    num_layers=1)\n",
    "\n",
    "TF_SAVEDIR = \"tf_saved\"\n",
    "checkpoint_filename = os.path.join(TF_SAVEDIR, \"rnnlm\")\n",
    "trained_filename = os.path.join(TF_SAVEDIR, \"rnnlm_trained\")\n",
    "\n",
    "\n",
    "X_train_shaped, y_train_shaped = shape_data_for_batching(X_train, y_train, max_time)\n",
    "\n",
    "X_test_shaped = {}\n",
    "y_test_shaped = {}\n",
    "for key in test_X:\n",
    "    X_test_shaped[key], y_test_shaped[key] = shape_data_for_batching(test_X[key], test_y[key], max_time)\n",
    "\n",
    "X_eval_shaped = {}\n",
    "y_eval_shaped = {}\n",
    "for key in eval_X:\n",
    "    X_eval_shaped[key], y_eval_shaped[key] = shape_data_for_batching(eval_X[key], eval_y[key], max_time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nearly the same as a4, but instead of scoring the data we look at prediction results after each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] Starting epoch 1\n",
      "[epoch 1] Completed in 0:00:00\n",
      "[epoch 1] [epoch 2] Starting epoch 2\n",
      "[epoch 2] Completed in 0:00:00\n",
      "[epoch 2] [epoch 3] Starting epoch 3\n",
      "[epoch 3] Completed in 0:00:00\n",
      "[epoch 3] [epoch 4] Starting epoch 4\n",
      "[epoch 4] Completed in 0:00:00\n",
      "[epoch 4] [epoch 5] Starting epoch 5\n",
      "[epoch 5] Completed in 0:00:00\n",
      "[epoch 5] [epoch 6] Starting epoch 6\n",
      "[epoch 6] Completed in 0:00:00\n",
      "[epoch 6] [epoch 7] Starting epoch 7\n",
      "[epoch 7] Completed in 0:00:00\n",
      "[epoch 7] [epoch 8] Starting epoch 8\n",
      "[epoch 8] Completed in 0:00:00\n",
      "[epoch 8] [epoch 9] Starting epoch 9\n",
      "[epoch 9] Completed in 0:00:00\n",
      "[epoch 9] [epoch 10] Starting epoch 10\n",
      "[epoch 10] Completed in 0:00:00\n",
      "[epoch 10] [epoch 11] Starting epoch 11\n",
      "[epoch 11] Completed in 0:00:00\n",
      "[epoch 11] [epoch 12] Starting epoch 12\n",
      "[epoch 12] Completed in 0:00:00\n",
      "[epoch 12] [epoch 13] Starting epoch 13\n",
      "[epoch 13] Completed in 0:00:00\n",
      "[epoch 13] [epoch 14] Starting epoch 14\n",
      "[epoch 14] Completed in 0:00:00\n",
      "[epoch 14] [epoch 15] Starting epoch 15\n",
      "[epoch 15] Completed in 0:00:00\n",
      "[epoch 15] [epoch 16] Starting epoch 16\n",
      "[epoch 16] Completed in 0:00:00\n",
      "[epoch 16] [epoch 17] Starting epoch 17\n",
      "[epoch 17] Completed in 0:00:00\n",
      "[epoch 17] [epoch 18] Starting epoch 18\n",
      "[epoch 18] Completed in 0:00:00\n",
      "[epoch 18] [epoch 19] Starting epoch 19\n",
      "[epoch 19] Completed in 0:00:00\n",
      "[epoch 19] [epoch 20] Starting epoch 20\n",
      "[epoch 20] Completed in 0:00:00\n",
      "[epoch 20] [epoch 21] Starting epoch 21\n",
      "[epoch 21] Completed in 0:00:00\n",
      "[epoch 21] [epoch 22] Starting epoch 22\n",
      "[epoch 22] Completed in 0:00:00\n",
      "[epoch 22] [epoch 23] Starting epoch 23\n",
      "[epoch 23] Completed in 0:00:00\n",
      "[epoch 23] [epoch 24] Starting epoch 24\n",
      "[epoch 24] Completed in 0:00:00\n",
      "[epoch 24] [epoch 25] Starting epoch 25\n",
      "[epoch 25] Completed in 0:00:00\n",
      "[epoch 25] [epoch 26] Starting epoch 26\n",
      "[epoch 26] Completed in 0:00:00\n",
      "[epoch 26] [epoch 27] Starting epoch 27\n",
      "[epoch 27] Completed in 0:00:00\n",
      "[epoch 27] [epoch 28] Starting epoch 28\n",
      "[epoch 28] Completed in 0:00:00\n",
      "[epoch 28] [epoch 29] Starting epoch 29\n",
      "[epoch 29] Completed in 0:00:00\n",
      "[epoch 29] [epoch 30] Starting epoch 30\n",
      "[epoch 30] Completed in 0:00:00\n",
      "[epoch 30] [epoch 31] Starting epoch 31\n",
      "[epoch 31] Completed in 0:00:00\n",
      "[epoch 31] [epoch 32] Starting epoch 32\n",
      "[epoch 32] Completed in 0:00:00\n",
      "[epoch 32] [epoch 33] Starting epoch 33\n",
      "[epoch 33] Completed in 0:00:00\n",
      "[epoch 33] [epoch 34] Starting epoch 34\n",
      "[epoch 34] Completed in 0:00:00\n",
      "[epoch 34] [epoch 35] Starting epoch 35\n",
      "[epoch 35] Completed in 0:00:00\n",
      "[epoch 35] [epoch 36] Starting epoch 36\n",
      "[epoch 36] Completed in 0:00:00\n",
      "[epoch 36] [epoch 37] Starting epoch 37\n",
      "[epoch 37] Completed in 0:00:00\n",
      "[epoch 37] [epoch 38] Starting epoch 38\n",
      "[epoch 38] Completed in 0:00:00\n",
      "[epoch 38] [epoch 39] Starting epoch 39\n",
      "[epoch 39] Completed in 0:00:00\n",
      "[epoch 39] [epoch 40] Starting epoch 40\n",
      "[epoch 40] Completed in 0:00:00\n",
      "[epoch 40] [epoch 41] Starting epoch 41\n",
      "[epoch 41] Completed in 0:00:00\n",
      "[epoch 41] [epoch 42] Starting epoch 42\n",
      "[epoch 42] Completed in 0:00:00\n",
      "[epoch 42] [epoch 43] Starting epoch 43\n",
      "[epoch 43] Completed in 0:00:00\n",
      "[epoch 43] [epoch 44] Starting epoch 44\n",
      "[epoch 44] Completed in 0:00:00\n",
      "[epoch 44] [epoch 45] Starting epoch 45\n",
      "[epoch 45] Completed in 0:00:00\n",
      "[epoch 45] [epoch 46] Starting epoch 46\n",
      "[epoch 46] Completed in 0:00:00\n",
      "[epoch 46] [epoch 47] Starting epoch 47\n",
      "[epoch 47] Completed in 0:00:00\n",
      "[epoch 47] [epoch 48] Starting epoch 48\n",
      "[epoch 48] Completed in 0:00:00\n",
      "[epoch 48] [epoch 49] Starting epoch 49\n",
      "[epoch 49] Completed in 0:00:00\n",
      "[epoch 49] [epoch 50] Starting epoch 50\n",
      "[epoch 50] Completed in 0:00:00\n",
      "[epoch 50] [epoch 51] Starting epoch 51\n",
      "[epoch 51] Completed in 0:00:00\n",
      "[epoch 51] [epoch 52] Starting epoch 52\n",
      "[epoch 52] Completed in 0:00:00\n",
      "[epoch 52] [epoch 53] Starting epoch 53\n",
      "[epoch 53] Completed in 0:00:00\n",
      "[epoch 53] [epoch 54] Starting epoch 54\n",
      "[epoch 54] Completed in 0:00:00\n",
      "[epoch 54] [epoch 55] Starting epoch 55\n",
      "[epoch 55] Completed in 0:00:00\n",
      "[epoch 55] [epoch 56] Starting epoch 56\n",
      "[epoch 56] Completed in 0:00:00\n",
      "[epoch 56] [epoch 57] Starting epoch 57\n",
      "[epoch 57] Completed in 0:00:00\n",
      "[epoch 57] [epoch 58] Starting epoch 58\n",
      "[epoch 58] Completed in 0:00:00\n",
      "[epoch 58] [epoch 59] Starting epoch 59\n",
      "[epoch 59] Completed in 0:00:00\n",
      "[epoch 59] [epoch 60] Starting epoch 60\n",
      "[epoch 60] Completed in 0:00:00\n",
      "[epoch 60] [epoch 61] Starting epoch 61\n",
      "[epoch 61] Completed in 0:00:00\n",
      "[epoch 61] [epoch 62] Starting epoch 62\n",
      "[epoch 62] Completed in 0:00:00\n",
      "[epoch 62] [epoch 63] Starting epoch 63\n",
      "[epoch 63] Completed in 0:00:00\n",
      "[epoch 63] [epoch 64] Starting epoch 64\n",
      "[epoch 64] Completed in 0:00:00\n",
      "[epoch 64] [epoch 65] Starting epoch 65\n",
      "[epoch 65] Completed in 0:00:00\n",
      "[epoch 65] [epoch 66] Starting epoch 66\n",
      "[epoch 66] Completed in 0:00:00\n",
      "[epoch 66] [epoch 67] Starting epoch 67\n",
      "[epoch 67] Completed in 0:00:00\n",
      "[epoch 67] [epoch 68] Starting epoch 68\n",
      "[epoch 68] Completed in 0:00:00\n",
      "[epoch 68] [epoch 69] Starting epoch 69\n",
      "[epoch 69] Completed in 0:00:00\n",
      "[epoch 69] [epoch 70] Starting epoch 70\n",
      "[epoch 70] Completed in 0:00:00\n",
      "[epoch 70] [epoch 71] Starting epoch 71\n",
      "[epoch 71] Completed in 0:00:00\n",
      "[epoch 71] [epoch 72] Starting epoch 72\n",
      "[epoch 72] Completed in 0:00:00\n",
      "[epoch 72] [epoch 73] Starting epoch 73\n",
      "[epoch 73] Completed in 0:00:00\n",
      "[epoch 73] [epoch 74] Starting epoch 74\n",
      "[epoch 74] Completed in 0:00:00\n",
      "[epoch 74] [epoch 75] Starting epoch 75\n",
      "[epoch 75] Completed in 0:00:00\n",
      "[epoch 75] [epoch 76] Starting epoch 76\n",
      "[epoch 76] Completed in 0:00:00\n",
      "[epoch 76] [epoch 77] Starting epoch 77\n",
      "[epoch 77] Completed in 0:00:00\n",
      "[epoch 77] [epoch 78] Starting epoch 78\n",
      "[epoch 78] Completed in 0:00:00\n",
      "[epoch 78] [epoch 79] Starting epoch 79\n",
      "[epoch 79] Completed in 0:00:00\n",
      "[epoch 79] [epoch 80] Starting epoch 80\n",
      "[epoch 80] Completed in 0:00:00\n",
      "[epoch 80] [epoch 81] Starting epoch 81\n",
      "[epoch 81] Completed in 0:00:00\n",
      "[epoch 81] [epoch 82] Starting epoch 82\n",
      "[epoch 82] Completed in 0:00:00\n",
      "[epoch 82] [epoch 83] Starting epoch 83\n",
      "[epoch 83] Completed in 0:00:00\n",
      "[epoch 83] [epoch 84] Starting epoch 84\n",
      "[epoch 84] Completed in 0:00:00\n",
      "[epoch 84] [epoch 85] Starting epoch 85\n",
      "[epoch 85] Completed in 0:00:00\n",
      "[epoch 85] [epoch 86] Starting epoch 86\n",
      "[epoch 86] Completed in 0:00:00\n",
      "[epoch 86] [epoch 87] Starting epoch 87\n",
      "[epoch 87] Completed in 0:00:00\n",
      "[epoch 87] [epoch 88] Starting epoch 88\n",
      "[epoch 88] Completed in 0:00:00\n",
      "[epoch 88] [epoch 89] Starting epoch 89\n",
      "[epoch 89] Completed in 0:00:00\n",
      "[epoch 89] [epoch 90] Starting epoch 90\n",
      "[epoch 90] Completed in 0:00:00\n",
      "[epoch 90] [epoch 91] Starting epoch 91\n",
      "[epoch 91] Completed in 0:00:00\n",
      "[epoch 91] [epoch 92] Starting epoch 92\n",
      "[epoch 92] Completed in 0:00:00\n",
      "[epoch 92] [epoch 93] Starting epoch 93\n",
      "[epoch 93] Completed in 0:00:00\n",
      "[epoch 93] [epoch 94] Starting epoch 94\n",
      "[epoch 94] Completed in 0:00:00\n",
      "[epoch 94] [epoch 95] Starting epoch 95\n",
      "[epoch 95] Completed in 0:00:00\n",
      "[epoch 95] [epoch 96] Starting epoch 96\n",
      "[epoch 96] Completed in 0:00:00\n",
      "[epoch 96] [epoch 97] Starting epoch 97\n",
      "[epoch 97] Completed in 0:00:00\n",
      "[epoch 97] [epoch 98] Starting epoch 98\n",
      "[epoch 98] Completed in 0:00:00\n",
      "[epoch 98] [epoch 99] Starting epoch 99\n",
      "[epoch 99] Completed in 0:00:00\n",
      "[epoch 99] [epoch 100] Starting epoch 100\n",
      "[epoch 100] Completed in 0:00:00\n",
      "[epoch 100] [epoch 101] Starting epoch 101\n",
      "[epoch 101] Completed in 0:00:00\n",
      "[epoch 101] [epoch 102] Starting epoch 102\n",
      "[epoch 102] Completed in 0:00:00\n",
      "[epoch 102] [epoch 103] Starting epoch 103\n",
      "[epoch 103] Completed in 0:00:00\n",
      "[epoch 103] [epoch 104] Starting epoch 104\n",
      "[epoch 104] Completed in 0:00:00\n",
      "[epoch 104] [epoch 105] Starting epoch 105\n",
      "[epoch 105] Completed in 0:00:00\n",
      "[epoch 105] [epoch 106] Starting epoch 106\n",
      "[epoch 106] Completed in 0:00:00\n",
      "[epoch 106] [epoch 107] Starting epoch 107\n",
      "[epoch 107] Completed in 0:00:00\n",
      "[epoch 107] [epoch 108] Starting epoch 108\n",
      "[epoch 108] Completed in 0:00:00\n",
      "[epoch 108] [epoch 109] Starting epoch 109\n",
      "[epoch 109] Completed in 0:00:00\n",
      "[epoch 109] [epoch 110] Starting epoch 110\n",
      "[epoch 110] Completed in 0:00:00\n",
      "[epoch 110] [epoch 111] Starting epoch 111\n",
      "[epoch 111] Completed in 0:00:00\n",
      "[epoch 111] [epoch 112] Starting epoch 112\n",
      "[epoch 112] Completed in 0:00:00\n",
      "[epoch 112] [epoch 113] Starting epoch 113\n",
      "[epoch 113] Completed in 0:00:00\n",
      "[epoch 113] [epoch 114] Starting epoch 114\n",
      "[epoch 114] Completed in 0:00:00\n",
      "[epoch 114] [epoch 115] Starting epoch 115\n",
      "[epoch 115] Completed in 0:00:00\n",
      "[epoch 115] [epoch 116] Starting epoch 116\n",
      "[epoch 116] Completed in 0:00:00\n",
      "[epoch 116] [epoch 117] Starting epoch 117\n",
      "[epoch 117] Completed in 0:00:00\n",
      "[epoch 117] [epoch 118] Starting epoch 118\n",
      "[epoch 118] Completed in 0:00:00\n",
      "[epoch 118] [epoch 119] Starting epoch 119\n",
      "[epoch 119] Completed in 0:00:00\n",
      "[epoch 119] [epoch 120] Starting epoch 120\n",
      "[epoch 120] Completed in 0:00:00\n",
      "[epoch 120] [epoch 121] Starting epoch 121\n",
      "[epoch 121] Completed in 0:00:00\n",
      "[epoch 121] [epoch 122] Starting epoch 122\n",
      "[epoch 122] Completed in 0:00:00\n",
      "[epoch 122] [epoch 123] Starting epoch 123\n",
      "[epoch 123] Completed in 0:00:00\n",
      "[epoch 123] [epoch 124] Starting epoch 124\n",
      "[epoch 124] Completed in 0:00:00\n",
      "[epoch 124] [epoch 125] Starting epoch 125\n",
      "[epoch 125] Completed in 0:00:00\n",
      "[epoch 125] [epoch 126] Starting epoch 126\n",
      "[epoch 126] Completed in 0:00:00\n",
      "[epoch 126] [epoch 127] Starting epoch 127\n",
      "[epoch 127] Completed in 0:00:00\n",
      "[epoch 127] [epoch 128] Starting epoch 128\n",
      "[epoch 128] Completed in 0:00:00\n",
      "[epoch 128] [epoch 129] Starting epoch 129\n",
      "[epoch 129] Completed in 0:00:00\n",
      "[epoch 129] [epoch 130] Starting epoch 130\n",
      "[epoch 130] Completed in 0:00:00\n",
      "[epoch 130] [epoch 131] Starting epoch 131\n",
      "[epoch 131] Completed in 0:00:00\n",
      "[epoch 131] [epoch 132] Starting epoch 132\n",
      "[epoch 132] Completed in 0:00:00\n",
      "[epoch 132] [epoch 133] Starting epoch 133\n",
      "[epoch 133] Completed in 0:00:00\n",
      "[epoch 133] [epoch 134] Starting epoch 134\n",
      "[epoch 134] Completed in 0:00:00\n",
      "[epoch 134] [epoch 135] Starting epoch 135\n",
      "[epoch 135] Completed in 0:00:00\n",
      "[epoch 135] [epoch 136] Starting epoch 136\n",
      "[epoch 136] Completed in 0:00:00\n",
      "[epoch 136] [epoch 137] Starting epoch 137\n",
      "[epoch 137] Completed in 0:00:00\n",
      "[epoch 137] [epoch 138] Starting epoch 138\n",
      "[epoch 138] Completed in 0:00:00\n",
      "[epoch 138] [epoch 139] Starting epoch 139\n",
      "[epoch 139] Completed in 0:00:00\n",
      "[epoch 139] [epoch 140] Starting epoch 140\n",
      "[epoch 140] Completed in 0:00:00\n",
      "[epoch 140] [epoch 141] Starting epoch 141\n",
      "[epoch 141] Completed in 0:00:00\n",
      "[epoch 141] [epoch 142] Starting epoch 142\n",
      "[epoch 142] Completed in 0:00:00\n",
      "[epoch 142] [epoch 143] Starting epoch 143\n",
      "[epoch 143] Completed in 0:00:00\n",
      "[epoch 143] [epoch 144] Starting epoch 144\n",
      "[epoch 144] Completed in 0:00:00\n",
      "[epoch 144] [epoch 145] Starting epoch 145\n",
      "[epoch 145] Completed in 0:00:00\n",
      "[epoch 145] [epoch 146] Starting epoch 146\n",
      "[epoch 146] Completed in 0:00:00\n",
      "[epoch 146] [epoch 147] Starting epoch 147\n",
      "[epoch 147] Completed in 0:00:00\n",
      "[epoch 147] [epoch 148] Starting epoch 148\n",
      "[epoch 148] Completed in 0:00:00\n",
      "[epoch 148] [epoch 149] Starting epoch 149\n",
      "[epoch 149] Completed in 0:00:00\n",
      "[epoch 149] [epoch 150] Starting epoch 150\n",
      "[epoch 150] Completed in 0:00:00\n",
      "[epoch 150] [epoch 151] Starting epoch 151\n",
      "[epoch 151] Completed in 0:00:00\n",
      "[epoch 151] [epoch 152] Starting epoch 152\n",
      "[epoch 152] Completed in 0:00:00\n",
      "[epoch 152] [epoch 153] Starting epoch 153\n",
      "[epoch 153] Completed in 0:00:00\n",
      "[epoch 153] [epoch 154] Starting epoch 154\n",
      "[epoch 154] Completed in 0:00:00\n",
      "[epoch 154] [epoch 155] Starting epoch 155\n",
      "[epoch 155] Completed in 0:00:00\n",
      "[epoch 155] [epoch 156] Starting epoch 156\n",
      "[epoch 156] Completed in 0:00:00\n",
      "[epoch 156] [epoch 157] Starting epoch 157\n",
      "[epoch 157] Completed in 0:00:00\n",
      "[epoch 157] [epoch 158] Starting epoch 158\n",
      "[epoch 158] Completed in 0:00:00\n",
      "[epoch 158] [epoch 159] Starting epoch 159\n",
      "[epoch 159] Completed in 0:00:00\n",
      "[epoch 159] [epoch 160] Starting epoch 160\n",
      "[epoch 160] Completed in 0:00:00\n",
      "[epoch 160] [epoch 161] Starting epoch 161\n",
      "[epoch 161] Completed in 0:00:00\n",
      "[epoch 161] [epoch 162] Starting epoch 162\n",
      "[epoch 162] Completed in 0:00:00\n",
      "[epoch 162] [epoch 163] Starting epoch 163\n",
      "[epoch 163] Completed in 0:00:00\n",
      "[epoch 163] [epoch 164] Starting epoch 164\n",
      "[epoch 164] Completed in 0:00:00\n",
      "[epoch 164] [epoch 165] Starting epoch 165\n",
      "[epoch 165] Completed in 0:00:00\n",
      "[epoch 165] [epoch 166] Starting epoch 166\n",
      "[epoch 166] Completed in 0:00:00\n",
      "[epoch 166] [epoch 167] Starting epoch 167\n",
      "[epoch 167] Completed in 0:00:00\n",
      "[epoch 167] [epoch 168] Starting epoch 168\n",
      "[epoch 168] Completed in 0:00:00\n",
      "[epoch 168] [epoch 169] Starting epoch 169\n",
      "[epoch 169] Completed in 0:00:00\n",
      "[epoch 169] [epoch 170] Starting epoch 170\n",
      "[epoch 170] Completed in 0:00:00\n",
      "[epoch 170] [epoch 171] Starting epoch 171\n",
      "[epoch 171] Completed in 0:00:00\n",
      "[epoch 171] [epoch 172] Starting epoch 172\n",
      "[epoch 172] Completed in 0:00:00\n",
      "[epoch 172] [epoch 173] Starting epoch 173\n",
      "[epoch 173] Completed in 0:00:00\n",
      "[epoch 173] [epoch 174] Starting epoch 174\n",
      "[epoch 174] Completed in 0:00:00\n",
      "[epoch 174] [epoch 175] Starting epoch 175\n",
      "[epoch 175] Completed in 0:00:00\n",
      "[epoch 175] [epoch 176] Starting epoch 176\n",
      "[epoch 176] Completed in 0:00:00\n",
      "[epoch 176] [epoch 177] Starting epoch 177\n",
      "[epoch 177] Completed in 0:00:00\n",
      "[epoch 177] [epoch 178] Starting epoch 178\n",
      "[epoch 178] Completed in 0:00:00\n",
      "[epoch 178] [epoch 179] Starting epoch 179\n",
      "[epoch 179] Completed in 0:00:00\n",
      "[epoch 179] [epoch 180] Starting epoch 180\n",
      "[epoch 180] Completed in 0:00:00\n",
      "[epoch 180] [epoch 181] Starting epoch 181\n",
      "[epoch 181] Completed in 0:00:00\n",
      "[epoch 181] [epoch 182] Starting epoch 182\n",
      "[epoch 182] Completed in 0:00:00\n",
      "[epoch 182] [epoch 183] Starting epoch 183\n",
      "[epoch 183] Completed in 0:00:00\n",
      "[epoch 183] [epoch 184] Starting epoch 184\n",
      "[epoch 184] Completed in 0:00:00\n",
      "[epoch 184] [epoch 185] Starting epoch 185\n",
      "[epoch 185] Completed in 0:00:00\n",
      "[epoch 185] [epoch 186] Starting epoch 186\n",
      "[epoch 186] Completed in 0:00:00\n",
      "[epoch 186] [epoch 187] Starting epoch 187\n",
      "[epoch 187] Completed in 0:00:00\n",
      "[epoch 187] [epoch 188] Starting epoch 188\n",
      "[epoch 188] Completed in 0:00:00\n",
      "[epoch 188] [epoch 189] Starting epoch 189\n",
      "[epoch 189] Completed in 0:00:00\n",
      "[epoch 189] [epoch 190] Starting epoch 190\n",
      "[epoch 190] Completed in 0:00:00\n",
      "[epoch 190] [epoch 191] Starting epoch 191\n",
      "[epoch 191] Completed in 0:00:00\n",
      "[epoch 191] [epoch 192] Starting epoch 192\n",
      "[epoch 192] Completed in 0:00:00\n",
      "[epoch 192] [epoch 193] Starting epoch 193\n",
      "[epoch 193] Completed in 0:00:00\n",
      "[epoch 193] [epoch 194] Starting epoch 194\n",
      "[epoch 194] Completed in 0:00:00\n",
      "[epoch 194] [epoch 195] Starting epoch 195\n",
      "[epoch 195] Completed in 0:00:00\n",
      "[epoch 195] [epoch 196] Starting epoch 196\n",
      "[epoch 196] Completed in 0:00:00\n",
      "[epoch 196] [epoch 197] Starting epoch 197\n",
      "[epoch 197] Completed in 0:00:00\n",
      "[epoch 197] [epoch 198] Starting epoch 198\n",
      "[epoch 198] Completed in 0:00:00\n",
      "[epoch 198] [epoch 199] Starting epoch 199\n",
      "[epoch 199] Completed in 0:00:00\n",
      "[epoch 199] [epoch 200] Starting epoch 200\n",
      "[epoch 200] Completed in 0:00:00\n",
      "[epoch 200] [epoch 201] Starting epoch 201\n",
      "[epoch 201] Completed in 0:00:00\n",
      "[epoch 201] [epoch 202] Starting epoch 202\n",
      "[epoch 202] Completed in 0:00:00\n",
      "[epoch 202] [epoch 203] Starting epoch 203\n",
      "[epoch 203] Completed in 0:00:00\n",
      "[epoch 203] [epoch 204] Starting epoch 204\n",
      "[epoch 204] Completed in 0:00:00\n",
      "[epoch 204] [epoch 205] Starting epoch 205\n",
      "[epoch 205] Completed in 0:00:00\n",
      "[epoch 205] [epoch 206] Starting epoch 206\n",
      "[epoch 206] Completed in 0:00:00\n",
      "[epoch 206] [epoch 207] Starting epoch 207\n",
      "[epoch 207] Completed in 0:00:00\n",
      "[epoch 207] [epoch 208] Starting epoch 208\n",
      "[epoch 208] Completed in 0:00:00\n",
      "[epoch 208] [epoch 209] Starting epoch 209\n",
      "[epoch 209] Completed in 0:00:00\n",
      "[epoch 209] [epoch 210] Starting epoch 210\n",
      "[epoch 210] Completed in 0:00:00\n",
      "[epoch 210] [epoch 211] Starting epoch 211\n",
      "[epoch 211] Completed in 0:00:00\n",
      "[epoch 211] [epoch 212] Starting epoch 212\n",
      "[epoch 212] Completed in 0:00:00\n",
      "[epoch 212] [epoch 213] Starting epoch 213\n",
      "[epoch 213] Completed in 0:00:00\n",
      "[epoch 213] [epoch 214] Starting epoch 214\n",
      "[epoch 214] Completed in 0:00:00\n",
      "[epoch 214] [epoch 215] Starting epoch 215\n",
      "[epoch 215] Completed in 0:00:00\n",
      "[epoch 215] [epoch 216] Starting epoch 216\n",
      "[epoch 216] Completed in 0:00:00\n",
      "[epoch 216] [epoch 217] Starting epoch 217\n",
      "[epoch 217] Completed in 0:00:00\n",
      "[epoch 217] [epoch 218] Starting epoch 218\n",
      "[epoch 218] Completed in 0:00:00\n",
      "[epoch 218] [epoch 219] Starting epoch 219\n",
      "[epoch 219] Completed in 0:00:00\n",
      "[epoch 219] [epoch 220] Starting epoch 220\n",
      "[epoch 220] Completed in 0:00:00\n",
      "[epoch 220] [epoch 221] Starting epoch 221\n",
      "[epoch 221] Completed in 0:00:00\n",
      "[epoch 221] [epoch 222] Starting epoch 222\n",
      "[epoch 222] Completed in 0:00:00\n",
      "[epoch 222] [epoch 223] Starting epoch 223\n",
      "[epoch 223] Completed in 0:00:00\n",
      "[epoch 223] [epoch 224] Starting epoch 224\n",
      "[epoch 224] Completed in 0:00:00\n",
      "[epoch 224] [epoch 225] Starting epoch 225\n",
      "[epoch 225] Completed in 0:00:00\n",
      "[epoch 225] [epoch 226] Starting epoch 226\n",
      "[epoch 226] Completed in 0:00:00\n",
      "[epoch 226] [epoch 227] Starting epoch 227\n",
      "[epoch 227] Completed in 0:00:00\n",
      "[epoch 227] [epoch 228] Starting epoch 228\n",
      "[epoch 228] Completed in 0:00:00\n",
      "[epoch 228] [epoch 229] Starting epoch 229\n",
      "[epoch 229] Completed in 0:00:00\n",
      "[epoch 229] [epoch 230] Starting epoch 230\n",
      "[epoch 230] Completed in 0:00:00\n",
      "[epoch 230] [epoch 231] Starting epoch 231\n",
      "[epoch 231] Completed in 0:00:00\n",
      "[epoch 231] [epoch 232] Starting epoch 232\n",
      "[epoch 232] Completed in 0:00:00\n",
      "[epoch 232] [epoch 233] Starting epoch 233\n",
      "[epoch 233] Completed in 0:00:00\n",
      "[epoch 233] [epoch 234] Starting epoch 234\n",
      "[epoch 234] Completed in 0:00:00\n",
      "[epoch 234] [epoch 235] Starting epoch 235\n",
      "[epoch 235] Completed in 0:00:00\n",
      "[epoch 235] [epoch 236] Starting epoch 236\n",
      "[epoch 236] Completed in 0:00:00\n",
      "[epoch 236] [epoch 237] Starting epoch 237\n",
      "[epoch 237] Completed in 0:00:00\n",
      "[epoch 237] [epoch 238] Starting epoch 238\n",
      "[epoch 238] Completed in 0:00:00\n",
      "[epoch 238] [epoch 239] Starting epoch 239\n",
      "[epoch 239] Completed in 0:00:00\n",
      "[epoch 239] [epoch 240] Starting epoch 240\n",
      "[epoch 240] Completed in 0:00:00\n",
      "[epoch 240] [epoch 241] Starting epoch 241\n",
      "[epoch 241] Completed in 0:00:00\n",
      "[epoch 241] [epoch 242] Starting epoch 242\n",
      "[epoch 242] Completed in 0:00:00\n",
      "[epoch 242] [epoch 243] Starting epoch 243\n",
      "[epoch 243] Completed in 0:00:00\n",
      "[epoch 243] [epoch 244] Starting epoch 244\n",
      "[epoch 244] Completed in 0:00:00\n",
      "[epoch 244] [epoch 245] Starting epoch 245\n",
      "[epoch 245] Completed in 0:00:00\n",
      "[epoch 245] [epoch 246] Starting epoch 246\n",
      "[epoch 246] Completed in 0:00:00\n",
      "[epoch 246] [epoch 247] Starting epoch 247\n",
      "[epoch 247] Completed in 0:00:00\n",
      "[epoch 247] [epoch 248] Starting epoch 248\n",
      "[epoch 248] Completed in 0:00:00\n",
      "[epoch 248] [epoch 249] Starting epoch 249\n",
      "[epoch 249] Completed in 0:00:00\n",
      "[epoch 249] [epoch 250] Starting epoch 250\n",
      "[epoch 250] Completed in 0:00:00\n",
      "[epoch 250] [epoch 251] Starting epoch 251\n",
      "[epoch 251] Completed in 0:00:00\n",
      "[epoch 251] [epoch 252] Starting epoch 252\n",
      "[epoch 252] Completed in 0:00:00\n",
      "[epoch 252] [epoch 253] Starting epoch 253\n",
      "[epoch 253] Completed in 0:00:00\n",
      "[epoch 253] [epoch 254] Starting epoch 254\n",
      "[epoch 254] Completed in 0:00:00\n",
      "[epoch 254] [epoch 255] Starting epoch 255\n",
      "[epoch 255] Completed in 0:00:00\n",
      "[epoch 255] [epoch 256] Starting epoch 256\n",
      "[epoch 256] Completed in 0:00:00\n",
      "[epoch 256] [epoch 257] Starting epoch 257\n",
      "[epoch 257] Completed in 0:00:00\n",
      "[epoch 257] [epoch 258] Starting epoch 258\n",
      "[epoch 258] Completed in 0:00:00\n",
      "[epoch 258] [epoch 259] Starting epoch 259\n",
      "[epoch 259] Completed in 0:00:00\n",
      "[epoch 259] [epoch 260] Starting epoch 260\n",
      "[epoch 260] Completed in 0:00:00\n",
      "[epoch 260] [epoch 261] Starting epoch 261\n",
      "[epoch 261] Completed in 0:00:00\n",
      "[epoch 261] [epoch 262] Starting epoch 262\n",
      "[epoch 262] Completed in 0:00:00\n",
      "[epoch 262] [epoch 263] Starting epoch 263\n",
      "[epoch 263] Completed in 0:00:00\n",
      "[epoch 263] [epoch 264] Starting epoch 264\n",
      "[epoch 264] Completed in 0:00:00\n",
      "[epoch 264] [epoch 265] Starting epoch 265\n",
      "[epoch 265] Completed in 0:00:00\n",
      "[epoch 265] [epoch 266] Starting epoch 266\n",
      "[epoch 266] Completed in 0:00:00\n",
      "[epoch 266] [epoch 267] Starting epoch 267\n",
      "[epoch 267] Completed in 0:00:00\n",
      "[epoch 267] [epoch 268] Starting epoch 268\n",
      "[epoch 268] Completed in 0:00:00\n",
      "[epoch 268] [epoch 269] Starting epoch 269\n",
      "[epoch 269] Completed in 0:00:00\n",
      "[epoch 269] [epoch 270] Starting epoch 270\n",
      "[epoch 270] Completed in 0:00:00\n",
      "[epoch 270] [epoch 271] Starting epoch 271\n",
      "[epoch 271] Completed in 0:00:00\n",
      "[epoch 271] [epoch 272] Starting epoch 272\n",
      "[epoch 272] Completed in 0:00:00\n",
      "[epoch 272] [epoch 273] Starting epoch 273\n",
      "[epoch 273] Completed in 0:00:00\n",
      "[epoch 273] [epoch 274] Starting epoch 274\n",
      "[epoch 274] Completed in 0:00:00\n",
      "[epoch 274] [epoch 275] Starting epoch 275\n",
      "[epoch 275] Completed in 0:00:00\n",
      "[epoch 275] [epoch 276] Starting epoch 276\n",
      "[epoch 276] Completed in 0:00:00\n",
      "[epoch 276] [epoch 277] Starting epoch 277\n",
      "[epoch 277] Completed in 0:00:00\n",
      "[epoch 277] [epoch 278] Starting epoch 278\n",
      "[epoch 278] Completed in 0:00:00\n",
      "[epoch 278] [epoch 279] Starting epoch 279\n",
      "[epoch 279] Completed in 0:00:00\n",
      "[epoch 279] [epoch 280] Starting epoch 280\n",
      "[epoch 280] Completed in 0:00:00\n",
      "[epoch 280] [epoch 281] Starting epoch 281\n",
      "[epoch 281] Completed in 0:00:00\n",
      "[epoch 281] [epoch 282] Starting epoch 282\n",
      "[epoch 282] Completed in 0:00:00\n",
      "[epoch 282] [epoch 283] Starting epoch 283\n",
      "[epoch 283] Completed in 0:00:00\n",
      "[epoch 283] [epoch 284] Starting epoch 284\n",
      "[epoch 284] Completed in 0:00:00\n",
      "[epoch 284] [epoch 285] Starting epoch 285\n",
      "[epoch 285] Completed in 0:00:00\n",
      "[epoch 285] [epoch 286] Starting epoch 286\n",
      "[epoch 286] Completed in 0:00:00\n",
      "[epoch 286] [epoch 287] Starting epoch 287\n",
      "[epoch 287] Completed in 0:00:00\n",
      "[epoch 287] [epoch 288] Starting epoch 288\n",
      "[epoch 288] Completed in 0:00:00\n",
      "[epoch 288] [epoch 289] Starting epoch 289\n",
      "[epoch 289] Completed in 0:00:00\n",
      "[epoch 289] [epoch 290] Starting epoch 290\n",
      "[epoch 290] Completed in 0:00:00\n",
      "[epoch 290] [epoch 291] Starting epoch 291\n",
      "[epoch 291] Completed in 0:00:00\n",
      "[epoch 291] [epoch 292] Starting epoch 292\n",
      "[epoch 292] Completed in 0:00:00\n",
      "[epoch 292] [epoch 293] Starting epoch 293\n",
      "[epoch 293] Completed in 0:00:00\n",
      "[epoch 293] [epoch 294] Starting epoch 294\n",
      "[epoch 294] Completed in 0:00:00\n",
      "[epoch 294] [epoch 295] Starting epoch 295\n",
      "[epoch 295] Completed in 0:00:00\n",
      "[epoch 295] [epoch 296] Starting epoch 296\n",
      "[epoch 296] Completed in 0:00:00\n",
      "[epoch 296] [epoch 297] Starting epoch 297\n",
      "[epoch 297] Completed in 0:00:00\n",
      "[epoch 297] [epoch 298] Starting epoch 298\n",
      "[epoch 298] Completed in 0:00:00\n",
      "[epoch 298] [epoch 299] Starting epoch 299\n",
      "[epoch 299] Completed in 0:00:00\n",
      "[epoch 299] [epoch 300] Starting epoch 300\n",
      "[epoch 300] Completed in 0:00:00\n",
      "[epoch 300] Predicting for Federalist Paper 20\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "james_madison: 0.41\n",
      "alexander_hamilton: 0.33\n",
      "john_jay: 0.26\n",
      "\n",
      "Predicting for Federalist Paper 58\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "james_madison: 0.47\n",
      "alexander_hamilton: 0.34\n",
      "john_jay: 0.19\n",
      "\n",
      "Predicting for Federalist Paper 49\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "james_madison: 0.34\n",
      "alexander_hamilton: 0.48\n",
      "john_jay: 0.18\n",
      "\n",
      "Predicting for Federalist Paper 55\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "james_madison: 0.42\n",
      "alexander_hamilton: 0.34\n",
      "john_jay: 0.24\n",
      "\n",
      "Predicting for Federalist Paper 54\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "james_madison: 0.43\n",
      "alexander_hamilton: 0.35\n",
      "john_jay: 0.22\n",
      "\n",
      "Predicting for Federalist Paper 57\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "james_madison: 0.34\n",
      "alexander_hamilton: 0.45\n",
      "john_jay: 0.21\n",
      "\n",
      "Predicting for Federalist Paper 56\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "james_madison: 0.40\n",
      "alexander_hamilton: 0.41\n",
      "john_jay: 0.19\n",
      "\n",
      "Predicting for Federalist Paper 51\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "james_madison: 0.56\n",
      "alexander_hamilton: 0.33\n",
      "john_jay: 0.11\n",
      "\n",
      "Predicting for Federalist Paper 50\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "james_madison: 0.28\n",
      "alexander_hamilton: 0.36\n",
      "john_jay: 0.36\n",
      "\n",
      "Predicting for Federalist Paper 53\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "james_madison: 0.45\n",
      "alexander_hamilton: 0.35\n",
      "john_jay: 0.20\n",
      "\n",
      "Predicting for Federalist Paper 52\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "james_madison: 0.46\n",
      "alexander_hamilton: 0.39\n",
      "john_jay: 0.15\n",
      "\n",
      "Predicting for Federalist Paper 19\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "james_madison: 0.45\n",
      "alexander_hamilton: 0.31\n",
      "john_jay: 0.24\n",
      "\n",
      "Predicting for Federalist Paper 62\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "james_madison: 0.45\n",
      "alexander_hamilton: 0.34\n",
      "john_jay: 0.21\n",
      "\n",
      "Predicting for Federalist Paper 63\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "james_madison: 0.44\n",
      "alexander_hamilton: 0.34\n",
      "john_jay: 0.22\n",
      "\n",
      "Predicting for Federalist Paper 72\n",
      "Truth: alexander_hamilton\n",
      "Prediction Summary:\n",
      "james_madison: 0.21\n",
      "alexander_hamilton: 0.64\n",
      "john_jay: 0.15\n",
      "\n",
      "Predicting for Federalist Paper 18\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "james_madison: 0.42\n",
      "alexander_hamilton: 0.35\n",
      "john_jay: 0.23\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reload(rnnlm)\n",
    "\n",
    "# Will print status every this many seconds\n",
    "print_interval = 5\n",
    "\n",
    "# Clear old log directory\n",
    "shutil.rmtree(\"tf_summaries\", ignore_errors=True)\n",
    "\n",
    "lm = rnnlm.RNNLM(**model_params)\n",
    "lm.BuildCoreGraph()\n",
    "lm.BuildTrainGraph()\n",
    "lm.BuildClassifierGraph()\n",
    "\n",
    "# Explicitly add global initializer and variable saver to LM graph\n",
    "with lm.graph.as_default():\n",
    "    initializer = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "# Clear old log directory\n",
    "shutil.rmtree(TF_SAVEDIR, ignore_errors=True)\n",
    "if not os.path.isdir(TF_SAVEDIR):\n",
    "    os.makedirs(TF_SAVEDIR)\n",
    "\n",
    "with tf.Session(graph=lm.graph) as session:\n",
    "    # Seed RNG for repeatability\n",
    "    tf.set_random_seed(42)\n",
    "\n",
    "    session.run(initializer)\n",
    "\n",
    "    # List for saving the unkown paper predictions from each epoch\n",
    "    if save_predictions:\n",
    "        epoch_predictions = []\n",
    "        \n",
    "    for epoch in xrange(1,num_epochs+1):\n",
    "        t0_epoch = time.time()\n",
    "        bi = batch_generator(X_train_shaped, y_train_shaped, batch_size)\n",
    "        print \"[epoch %d] Starting epoch %d\" % (epoch, epoch)\n",
    "        # Run a training epoch.\n",
    "\n",
    "        run_epoch(lm, session, bi, train=True, verbose=True, tick_s=100, learning_rate=learning_rate)\n",
    "    \n",
    "        print \"[epoch %d] Completed in %s\" % (epoch, pretty_timedelta(since=t0_epoch))\n",
    "    \n",
    "        # Save a checkpoint\n",
    "        saver.save(session, checkpoint_filename, global_step=epoch)\n",
    "    \n",
    "        ##\n",
    "        # score_dataset will run a forward pass over the entire dataset\n",
    "        # and report perplexity scores. This can be slow (around 1/2 to \n",
    "        # 1/4 as long as a full epoch), so you may want to comment it out\n",
    "        # to speed up training on a slow machine. Be sure to run it at the \n",
    "        # end to evaluate your score.\n",
    "        print (\"[epoch %d]\" % epoch),\n",
    "        #score_dataset(lm, session, eval_X['18'], eval_y['18'], max_time, name=\"Federalist Paper 18\")\n",
    "        #score_dataset(lm, session, test_ids, name=\"Test set\")\n",
    "\n",
    "        # test three of the federalist papers whose author is known after each epoch\n",
    "        # test_predictions = test_papers(lm, session, X_test_shaped, y_test_shaped, author_to_id, batch_size, print_results=True)\n",
    "        \n",
    "        if save_predictions:\n",
    "            # testing against all unkown federalist papers\n",
    "            unk_predictions = test_papers(lm, session, X_eval_shaped, y_eval_shaped, author_to_id, batch_size, print_results=False)\n",
    "            epoch_predictions.append(unk_predictions)\n",
    "\n",
    "    # Testing final model against all unkown federalist papers\n",
    "    final_test = test_papers(lm, session, X_eval_shaped, y_eval_shaped, author_to_id, batch_size, print_results=True)    \n",
    "    # Save final model\n",
    "    saver.save(session, trained_filename)\n",
    "    \n",
    "    if save_predictions:\n",
    "        df = create_predictions_dataframe(epoch_predictions)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAVING: Uncomment and run to save the current model results to disk\n",
    "By default, results will be placed in their own directory within `/nn_saved_results`, which is named with the current datetime stamp. This is to prevent overwrites when we are pushing to the directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RESULTS_SAVE_DIR = './nn_saved_results/' + datetime.now().strftime('%Y-%m-%d_%H_%M_%S')\n",
    "save_results(RESULTS_SAVE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>72</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0000</th>\n",
       "      <td>0.6933</td>\n",
       "      <td>0.7133</td>\n",
       "      <td>0.5600</td>\n",
       "      <td>0.5200</td>\n",
       "      <td>0.5200</td>\n",
       "      <td>0.5100</td>\n",
       "      <td>0.5200</td>\n",
       "      <td>0.6267</td>\n",
       "      <td>0.5200</td>\n",
       "      <td>0.4800</td>\n",
       "      <td>0.5100</td>\n",
       "      <td>0.5333</td>\n",
       "      <td>0.6133</td>\n",
       "      <td>0.5467</td>\n",
       "      <td>0.5150</td>\n",
       "      <td>0.5600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0000</th>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.2300</td>\n",
       "      <td>0.1900</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.3200</td>\n",
       "      <td>0.2600</td>\n",
       "      <td>0.2400</td>\n",
       "      <td>0.2800</td>\n",
       "      <td>0.2800</td>\n",
       "      <td>0.2700</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.2133</td>\n",
       "      <td>0.2867</td>\n",
       "      <td>0.2600</td>\n",
       "      <td>0.3100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0000</th>\n",
       "      <td>0.1467</td>\n",
       "      <td>0.1867</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>0.2900</td>\n",
       "      <td>0.2800</td>\n",
       "      <td>0.1700</td>\n",
       "      <td>0.2200</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.2400</td>\n",
       "      <td>0.2200</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.1733</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>0.1300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0000</th>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.6733</td>\n",
       "      <td>0.5100</td>\n",
       "      <td>0.4800</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.5400</td>\n",
       "      <td>0.5300</td>\n",
       "      <td>0.5933</td>\n",
       "      <td>0.5100</td>\n",
       "      <td>0.5100</td>\n",
       "      <td>0.5300</td>\n",
       "      <td>0.5400</td>\n",
       "      <td>0.5800</td>\n",
       "      <td>0.5133</td>\n",
       "      <td>0.5200</td>\n",
       "      <td>0.5100</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0000</th>\n",
       "      <td>0.2933</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.2800</td>\n",
       "      <td>0.2900</td>\n",
       "      <td>0.2400</td>\n",
       "      <td>0.3500</td>\n",
       "      <td>0.3200</td>\n",
       "      <td>0.3067</td>\n",
       "      <td>0.3200</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.3200</td>\n",
       "      <td>0.3533</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>0.3450</td>\n",
       "      <td>0.3700</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0000</th>\n",
       "      <td>0.1067</td>\n",
       "      <td>0.1267</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>0.2300</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.1100</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1700</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.1700</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>0.0667</td>\n",
       "      <td>0.1467</td>\n",
       "      <td>0.1350</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0000</th>\n",
       "      <td>0.6067</td>\n",
       "      <td>0.6400</td>\n",
       "      <td>0.5500</td>\n",
       "      <td>0.4800</td>\n",
       "      <td>0.5200</td>\n",
       "      <td>0.5300</td>\n",
       "      <td>0.5200</td>\n",
       "      <td>0.6133</td>\n",
       "      <td>0.5400</td>\n",
       "      <td>0.5500</td>\n",
       "      <td>0.5100</td>\n",
       "      <td>0.5800</td>\n",
       "      <td>0.6267</td>\n",
       "      <td>0.4867</td>\n",
       "      <td>0.5750</td>\n",
       "      <td>0.5600</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0000</th>\n",
       "      <td>0.2200</td>\n",
       "      <td>0.1533</td>\n",
       "      <td>0.2600</td>\n",
       "      <td>0.3100</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.3200</td>\n",
       "      <td>0.3100</td>\n",
       "      <td>0.2600</td>\n",
       "      <td>0.2900</td>\n",
       "      <td>0.2900</td>\n",
       "      <td>0.2800</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.2800</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0000</th>\n",
       "      <td>0.1733</td>\n",
       "      <td>0.2067</td>\n",
       "      <td>0.1900</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>0.1800</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.1700</td>\n",
       "      <td>0.1267</td>\n",
       "      <td>0.1700</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>0.1733</td>\n",
       "      <td>0.1267</td>\n",
       "      <td>0.1733</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0000</th>\n",
       "      <td>0.5667</td>\n",
       "      <td>0.6467</td>\n",
       "      <td>0.4900</td>\n",
       "      <td>0.4800</td>\n",
       "      <td>0.5400</td>\n",
       "      <td>0.5300</td>\n",
       "      <td>0.5100</td>\n",
       "      <td>0.5133</td>\n",
       "      <td>0.5200</td>\n",
       "      <td>0.4900</td>\n",
       "      <td>0.4300</td>\n",
       "      <td>0.5133</td>\n",
       "      <td>0.5067</td>\n",
       "      <td>0.4933</td>\n",
       "      <td>0.4750</td>\n",
       "      <td>0.4100</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0000</th>\n",
       "      <td>0.2667</td>\n",
       "      <td>0.1733</td>\n",
       "      <td>0.2900</td>\n",
       "      <td>0.3200</td>\n",
       "      <td>0.2200</td>\n",
       "      <td>0.3300</td>\n",
       "      <td>0.3300</td>\n",
       "      <td>0.3533</td>\n",
       "      <td>0.3500</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>0.3600</td>\n",
       "      <td>0.3600</td>\n",
       "      <td>0.3533</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.3450</td>\n",
       "      <td>0.3800</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0000</th>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.1800</td>\n",
       "      <td>0.2200</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.2400</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>0.1300</td>\n",
       "      <td>0.1700</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>0.1267</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>0.1733</td>\n",
       "      <td>0.1800</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0000</th>\n",
       "      <td>0.5467</td>\n",
       "      <td>0.6133</td>\n",
       "      <td>0.4500</td>\n",
       "      <td>0.5100</td>\n",
       "      <td>0.5600</td>\n",
       "      <td>0.5400</td>\n",
       "      <td>0.5700</td>\n",
       "      <td>0.5400</td>\n",
       "      <td>0.5400</td>\n",
       "      <td>0.5500</td>\n",
       "      <td>0.4600</td>\n",
       "      <td>0.5467</td>\n",
       "      <td>0.5400</td>\n",
       "      <td>0.4867</td>\n",
       "      <td>0.5050</td>\n",
       "      <td>0.4300</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0000</th>\n",
       "      <td>0.2333</td>\n",
       "      <td>0.1733</td>\n",
       "      <td>0.2900</td>\n",
       "      <td>0.2300</td>\n",
       "      <td>0.2400</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>0.2600</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.2900</td>\n",
       "      <td>0.2700</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.3267</td>\n",
       "      <td>0.3133</td>\n",
       "      <td>0.3533</td>\n",
       "      <td>0.2950</td>\n",
       "      <td>0.3300</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0000</th>\n",
       "      <td>0.2200</td>\n",
       "      <td>0.2133</td>\n",
       "      <td>0.2600</td>\n",
       "      <td>0.2600</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>0.1700</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.1700</td>\n",
       "      <td>0.1800</td>\n",
       "      <td>0.2400</td>\n",
       "      <td>0.1267</td>\n",
       "      <td>0.1467</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.2400</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0000</th>\n",
       "      <td>0.5733</td>\n",
       "      <td>0.5600</td>\n",
       "      <td>0.4600</td>\n",
       "      <td>0.4500</td>\n",
       "      <td>0.5400</td>\n",
       "      <td>0.4400</td>\n",
       "      <td>0.5100</td>\n",
       "      <td>0.4733</td>\n",
       "      <td>0.4900</td>\n",
       "      <td>0.4900</td>\n",
       "      <td>0.4300</td>\n",
       "      <td>0.4733</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.4533</td>\n",
       "      <td>0.4300</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0000</th>\n",
       "      <td>0.2667</td>\n",
       "      <td>0.2800</td>\n",
       "      <td>0.3500</td>\n",
       "      <td>0.3600</td>\n",
       "      <td>0.2600</td>\n",
       "      <td>0.4300</td>\n",
       "      <td>0.3500</td>\n",
       "      <td>0.3733</td>\n",
       "      <td>0.3700</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>0.4067</td>\n",
       "      <td>0.3800</td>\n",
       "      <td>0.3867</td>\n",
       "      <td>0.3950</td>\n",
       "      <td>0.4100</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0000</th>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.1900</td>\n",
       "      <td>0.1900</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.1300</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>0.1533</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>0.1700</td>\n",
       "      <td>0.2300</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.1750</td>\n",
       "      <td>0.1900</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0000</th>\n",
       "      <td>0.4400</td>\n",
       "      <td>0.5400</td>\n",
       "      <td>0.3900</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.4200</td>\n",
       "      <td>0.4400</td>\n",
       "      <td>0.4800</td>\n",
       "      <td>0.4467</td>\n",
       "      <td>0.3900</td>\n",
       "      <td>0.4800</td>\n",
       "      <td>0.4400</td>\n",
       "      <td>0.4067</td>\n",
       "      <td>0.4600</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.3950</td>\n",
       "      <td>0.3500</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0000</th>\n",
       "      <td>0.3400</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>0.3800</td>\n",
       "      <td>0.3800</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.4500</td>\n",
       "      <td>0.3300</td>\n",
       "      <td>0.3867</td>\n",
       "      <td>0.4600</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>0.3500</td>\n",
       "      <td>0.4333</td>\n",
       "      <td>0.3667</td>\n",
       "      <td>0.4333</td>\n",
       "      <td>0.4150</td>\n",
       "      <td>0.4300</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0000</th>\n",
       "      <td>0.2200</td>\n",
       "      <td>0.1933</td>\n",
       "      <td>0.2300</td>\n",
       "      <td>0.2200</td>\n",
       "      <td>0.1800</td>\n",
       "      <td>0.1100</td>\n",
       "      <td>0.1900</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.1800</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.1733</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.1900</td>\n",
       "      <td>0.2200</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0000</th>\n",
       "      <td>0.4867</td>\n",
       "      <td>0.5133</td>\n",
       "      <td>0.4200</td>\n",
       "      <td>0.3500</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.3600</td>\n",
       "      <td>0.4700</td>\n",
       "      <td>0.4133</td>\n",
       "      <td>0.4200</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.4700</td>\n",
       "      <td>0.4467</td>\n",
       "      <td>0.5200</td>\n",
       "      <td>0.4067</td>\n",
       "      <td>0.4250</td>\n",
       "      <td>0.3300</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0000</th>\n",
       "      <td>0.3400</td>\n",
       "      <td>0.3267</td>\n",
       "      <td>0.3700</td>\n",
       "      <td>0.5200</td>\n",
       "      <td>0.4200</td>\n",
       "      <td>0.5500</td>\n",
       "      <td>0.4500</td>\n",
       "      <td>0.4933</td>\n",
       "      <td>0.4900</td>\n",
       "      <td>0.4100</td>\n",
       "      <td>0.3900</td>\n",
       "      <td>0.4533</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.4700</td>\n",
       "      <td>0.5200</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0000</th>\n",
       "      <td>0.1733</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>0.1300</td>\n",
       "      <td>0.0800</td>\n",
       "      <td>0.0900</td>\n",
       "      <td>0.0800</td>\n",
       "      <td>0.0933</td>\n",
       "      <td>0.0900</td>\n",
       "      <td>0.0900</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.0800</td>\n",
       "      <td>0.0933</td>\n",
       "      <td>0.1050</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0000</th>\n",
       "      <td>0.4267</td>\n",
       "      <td>0.4800</td>\n",
       "      <td>0.3900</td>\n",
       "      <td>0.3200</td>\n",
       "      <td>0.4800</td>\n",
       "      <td>0.3600</td>\n",
       "      <td>0.4500</td>\n",
       "      <td>0.3933</td>\n",
       "      <td>0.4200</td>\n",
       "      <td>0.4400</td>\n",
       "      <td>0.4400</td>\n",
       "      <td>0.4400</td>\n",
       "      <td>0.4600</td>\n",
       "      <td>0.4067</td>\n",
       "      <td>0.4050</td>\n",
       "      <td>0.3300</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0000</th>\n",
       "      <td>0.3067</td>\n",
       "      <td>0.2533</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>0.4800</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>0.5300</td>\n",
       "      <td>0.3900</td>\n",
       "      <td>0.4400</td>\n",
       "      <td>0.4200</td>\n",
       "      <td>0.4200</td>\n",
       "      <td>0.3800</td>\n",
       "      <td>0.4067</td>\n",
       "      <td>0.3867</td>\n",
       "      <td>0.4267</td>\n",
       "      <td>0.4150</td>\n",
       "      <td>0.4500</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0000</th>\n",
       "      <td>0.2667</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>0.2700</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.1800</td>\n",
       "      <td>0.1100</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>0.1800</td>\n",
       "      <td>0.1533</td>\n",
       "      <td>0.1533</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.1800</td>\n",
       "      <td>0.2200</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0000</th>\n",
       "      <td>0.5600</td>\n",
       "      <td>0.5733</td>\n",
       "      <td>0.4800</td>\n",
       "      <td>0.4500</td>\n",
       "      <td>0.5600</td>\n",
       "      <td>0.4400</td>\n",
       "      <td>0.5200</td>\n",
       "      <td>0.4933</td>\n",
       "      <td>0.5200</td>\n",
       "      <td>0.4700</td>\n",
       "      <td>0.4700</td>\n",
       "      <td>0.5400</td>\n",
       "      <td>0.5267</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.4750</td>\n",
       "      <td>0.4700</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0000</th>\n",
       "      <td>0.2267</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.2600</td>\n",
       "      <td>0.4100</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>0.3600</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>0.3600</td>\n",
       "      <td>0.3500</td>\n",
       "      <td>0.3467</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>0.3467</td>\n",
       "      <td>0.3550</td>\n",
       "      <td>0.3800</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0000</th>\n",
       "      <td>0.2133</td>\n",
       "      <td>0.2267</td>\n",
       "      <td>0.2600</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.0600</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>0.1467</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>0.1700</td>\n",
       "      <td>0.1800</td>\n",
       "      <td>0.1133</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>0.1533</td>\n",
       "      <td>0.1700</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0000</th>\n",
       "      <td>0.3600</td>\n",
       "      <td>0.4133</td>\n",
       "      <td>0.3500</td>\n",
       "      <td>0.3200</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.5300</td>\n",
       "      <td>0.4700</td>\n",
       "      <td>0.4200</td>\n",
       "      <td>0.4400</td>\n",
       "      <td>0.4500</td>\n",
       "      <td>0.4300</td>\n",
       "      <td>0.3467</td>\n",
       "      <td>0.4467</td>\n",
       "      <td>0.4400</td>\n",
       "      <td>0.3850</td>\n",
       "      <td>0.1900</td>\n",
       "      <td>291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0000</th>\n",
       "      <td>0.4400</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>0.3500</td>\n",
       "      <td>0.4900</td>\n",
       "      <td>0.3600</td>\n",
       "      <td>0.3800</td>\n",
       "      <td>0.3800</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.3700</td>\n",
       "      <td>0.3500</td>\n",
       "      <td>0.3800</td>\n",
       "      <td>0.4800</td>\n",
       "      <td>0.3933</td>\n",
       "      <td>0.3600</td>\n",
       "      <td>0.4200</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0000</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.1900</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>0.0900</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.1800</td>\n",
       "      <td>0.1900</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.1900</td>\n",
       "      <td>0.1733</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.1950</td>\n",
       "      <td>0.1100</td>\n",
       "      <td>291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0000</th>\n",
       "      <td>0.3533</td>\n",
       "      <td>0.4467</td>\n",
       "      <td>0.3600</td>\n",
       "      <td>0.3500</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.5600</td>\n",
       "      <td>0.4600</td>\n",
       "      <td>0.4400</td>\n",
       "      <td>0.4500</td>\n",
       "      <td>0.4200</td>\n",
       "      <td>0.4300</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.4333</td>\n",
       "      <td>0.3900</td>\n",
       "      <td>0.1800</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0000</th>\n",
       "      <td>0.4133</td>\n",
       "      <td>0.2933</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.4600</td>\n",
       "      <td>0.2800</td>\n",
       "      <td>0.3200</td>\n",
       "      <td>0.3600</td>\n",
       "      <td>0.3733</td>\n",
       "      <td>0.3500</td>\n",
       "      <td>0.3300</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>0.4533</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>0.3133</td>\n",
       "      <td>0.3700</td>\n",
       "      <td>0.6600</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0000</th>\n",
       "      <td>0.2333</td>\n",
       "      <td>0.2600</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>0.1900</td>\n",
       "      <td>0.4200</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>0.1800</td>\n",
       "      <td>0.1867</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.2300</td>\n",
       "      <td>0.2067</td>\n",
       "      <td>0.1933</td>\n",
       "      <td>0.2533</td>\n",
       "      <td>0.2400</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0000</th>\n",
       "      <td>0.3933</td>\n",
       "      <td>0.4867</td>\n",
       "      <td>0.4200</td>\n",
       "      <td>0.4200</td>\n",
       "      <td>0.3800</td>\n",
       "      <td>0.6400</td>\n",
       "      <td>0.5400</td>\n",
       "      <td>0.4733</td>\n",
       "      <td>0.4600</td>\n",
       "      <td>0.4500</td>\n",
       "      <td>0.4900</td>\n",
       "      <td>0.3733</td>\n",
       "      <td>0.5067</td>\n",
       "      <td>0.5133</td>\n",
       "      <td>0.4550</td>\n",
       "      <td>0.2300</td>\n",
       "      <td>293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0000</th>\n",
       "      <td>0.4200</td>\n",
       "      <td>0.2800</td>\n",
       "      <td>0.2800</td>\n",
       "      <td>0.4300</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.3200</td>\n",
       "      <td>0.3533</td>\n",
       "      <td>0.3500</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>0.3500</td>\n",
       "      <td>0.4600</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.3600</td>\n",
       "      <td>0.6500</td>\n",
       "      <td>293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0000</th>\n",
       "      <td>0.1867</td>\n",
       "      <td>0.2333</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.2800</td>\n",
       "      <td>0.0600</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>0.1733</td>\n",
       "      <td>0.1900</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.1867</td>\n",
       "      <td>0.1850</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0000</th>\n",
       "      <td>0.4333</td>\n",
       "      <td>0.4600</td>\n",
       "      <td>0.4300</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.3800</td>\n",
       "      <td>0.6100</td>\n",
       "      <td>0.5400</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.4700</td>\n",
       "      <td>0.4300</td>\n",
       "      <td>0.4800</td>\n",
       "      <td>0.3933</td>\n",
       "      <td>0.5200</td>\n",
       "      <td>0.5133</td>\n",
       "      <td>0.4650</td>\n",
       "      <td>0.2400</td>\n",
       "      <td>294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0000</th>\n",
       "      <td>0.3667</td>\n",
       "      <td>0.2933</td>\n",
       "      <td>0.2800</td>\n",
       "      <td>0.4400</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.2900</td>\n",
       "      <td>0.3200</td>\n",
       "      <td>0.3467</td>\n",
       "      <td>0.3200</td>\n",
       "      <td>0.3200</td>\n",
       "      <td>0.3300</td>\n",
       "      <td>0.4267</td>\n",
       "      <td>0.2933</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.3300</td>\n",
       "      <td>0.6200</td>\n",
       "      <td>294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0000</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.2900</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.3200</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>0.1867</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.1900</td>\n",
       "      <td>0.1800</td>\n",
       "      <td>0.1867</td>\n",
       "      <td>0.1867</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0000</th>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.4400</td>\n",
       "      <td>0.4300</td>\n",
       "      <td>0.3600</td>\n",
       "      <td>0.6300</td>\n",
       "      <td>0.5600</td>\n",
       "      <td>0.4733</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.4900</td>\n",
       "      <td>0.4800</td>\n",
       "      <td>0.4067</td>\n",
       "      <td>0.5267</td>\n",
       "      <td>0.5200</td>\n",
       "      <td>0.4950</td>\n",
       "      <td>0.2300</td>\n",
       "      <td>295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0000</th>\n",
       "      <td>0.3467</td>\n",
       "      <td>0.2933</td>\n",
       "      <td>0.2800</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.2900</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.3667</td>\n",
       "      <td>0.3300</td>\n",
       "      <td>0.3100</td>\n",
       "      <td>0.3600</td>\n",
       "      <td>0.4400</td>\n",
       "      <td>0.3133</td>\n",
       "      <td>0.3067</td>\n",
       "      <td>0.3350</td>\n",
       "      <td>0.6500</td>\n",
       "      <td>295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0000</th>\n",
       "      <td>0.1867</td>\n",
       "      <td>0.2067</td>\n",
       "      <td>0.2800</td>\n",
       "      <td>0.1700</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>0.0800</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.1700</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.1533</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.1733</td>\n",
       "      <td>0.1700</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0000</th>\n",
       "      <td>0.4400</td>\n",
       "      <td>0.5067</td>\n",
       "      <td>0.4200</td>\n",
       "      <td>0.4100</td>\n",
       "      <td>0.3800</td>\n",
       "      <td>0.6400</td>\n",
       "      <td>0.5500</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.4800</td>\n",
       "      <td>0.4600</td>\n",
       "      <td>0.4900</td>\n",
       "      <td>0.3867</td>\n",
       "      <td>0.5467</td>\n",
       "      <td>0.5333</td>\n",
       "      <td>0.5250</td>\n",
       "      <td>0.2300</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0000</th>\n",
       "      <td>0.3667</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.4100</td>\n",
       "      <td>0.3200</td>\n",
       "      <td>0.2700</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.3067</td>\n",
       "      <td>0.3300</td>\n",
       "      <td>0.3200</td>\n",
       "      <td>0.3500</td>\n",
       "      <td>0.4400</td>\n",
       "      <td>0.2733</td>\n",
       "      <td>0.2867</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.6500</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0000</th>\n",
       "      <td>0.1933</td>\n",
       "      <td>0.2267</td>\n",
       "      <td>0.2800</td>\n",
       "      <td>0.1800</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.0900</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.1933</td>\n",
       "      <td>0.1900</td>\n",
       "      <td>0.2200</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.1733</td>\n",
       "      <td>0.1800</td>\n",
       "      <td>0.1800</td>\n",
       "      <td>0.1750</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0000</th>\n",
       "      <td>0.4467</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.4100</td>\n",
       "      <td>0.3600</td>\n",
       "      <td>0.5900</td>\n",
       "      <td>0.5200</td>\n",
       "      <td>0.4733</td>\n",
       "      <td>0.4600</td>\n",
       "      <td>0.4600</td>\n",
       "      <td>0.4900</td>\n",
       "      <td>0.3867</td>\n",
       "      <td>0.5200</td>\n",
       "      <td>0.4867</td>\n",
       "      <td>0.4750</td>\n",
       "      <td>0.2300</td>\n",
       "      <td>297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0000</th>\n",
       "      <td>0.3600</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.3200</td>\n",
       "      <td>0.4100</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>0.3200</td>\n",
       "      <td>0.3300</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>0.3600</td>\n",
       "      <td>0.3500</td>\n",
       "      <td>0.4333</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>0.3267</td>\n",
       "      <td>0.3300</td>\n",
       "      <td>0.6500</td>\n",
       "      <td>297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0000</th>\n",
       "      <td>0.1933</td>\n",
       "      <td>0.2333</td>\n",
       "      <td>0.2800</td>\n",
       "      <td>0.1800</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.0900</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.1933</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.1800</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.1800</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>0.1867</td>\n",
       "      <td>0.1950</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0000</th>\n",
       "      <td>0.4467</td>\n",
       "      <td>0.4933</td>\n",
       "      <td>0.4500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.3800</td>\n",
       "      <td>0.6100</td>\n",
       "      <td>0.5400</td>\n",
       "      <td>0.4600</td>\n",
       "      <td>0.4700</td>\n",
       "      <td>0.4500</td>\n",
       "      <td>0.4700</td>\n",
       "      <td>0.3867</td>\n",
       "      <td>0.4933</td>\n",
       "      <td>0.5267</td>\n",
       "      <td>0.4800</td>\n",
       "      <td>0.2600</td>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0000</th>\n",
       "      <td>0.3600</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>0.2800</td>\n",
       "      <td>0.4200</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>0.3200</td>\n",
       "      <td>0.3700</td>\n",
       "      <td>0.3300</td>\n",
       "      <td>0.4267</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.2800</td>\n",
       "      <td>0.3250</td>\n",
       "      <td>0.6200</td>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0000</th>\n",
       "      <td>0.1933</td>\n",
       "      <td>0.2400</td>\n",
       "      <td>0.2700</td>\n",
       "      <td>0.1800</td>\n",
       "      <td>0.2800</td>\n",
       "      <td>0.0900</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>0.1800</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.1867</td>\n",
       "      <td>0.1733</td>\n",
       "      <td>0.1933</td>\n",
       "      <td>0.1950</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0000</th>\n",
       "      <td>0.4400</td>\n",
       "      <td>0.4733</td>\n",
       "      <td>0.4500</td>\n",
       "      <td>0.3500</td>\n",
       "      <td>0.3600</td>\n",
       "      <td>0.5800</td>\n",
       "      <td>0.4900</td>\n",
       "      <td>0.4467</td>\n",
       "      <td>0.4500</td>\n",
       "      <td>0.4200</td>\n",
       "      <td>0.4200</td>\n",
       "      <td>0.3800</td>\n",
       "      <td>0.4600</td>\n",
       "      <td>0.4800</td>\n",
       "      <td>0.4400</td>\n",
       "      <td>0.2200</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0000</th>\n",
       "      <td>0.3467</td>\n",
       "      <td>0.2800</td>\n",
       "      <td>0.2800</td>\n",
       "      <td>0.4800</td>\n",
       "      <td>0.3600</td>\n",
       "      <td>0.3300</td>\n",
       "      <td>0.3600</td>\n",
       "      <td>0.3467</td>\n",
       "      <td>0.3500</td>\n",
       "      <td>0.3600</td>\n",
       "      <td>0.3900</td>\n",
       "      <td>0.4400</td>\n",
       "      <td>0.3533</td>\n",
       "      <td>0.3267</td>\n",
       "      <td>0.3700</td>\n",
       "      <td>0.6200</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0000</th>\n",
       "      <td>0.2133</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.2700</td>\n",
       "      <td>0.1700</td>\n",
       "      <td>0.2800</td>\n",
       "      <td>0.0900</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.2067</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.2200</td>\n",
       "      <td>0.1900</td>\n",
       "      <td>0.1800</td>\n",
       "      <td>0.1867</td>\n",
       "      <td>0.1933</td>\n",
       "      <td>0.1900</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0000</th>\n",
       "      <td>0.4200</td>\n",
       "      <td>0.4467</td>\n",
       "      <td>0.4100</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>0.2800</td>\n",
       "      <td>0.5600</td>\n",
       "      <td>0.4600</td>\n",
       "      <td>0.4467</td>\n",
       "      <td>0.4300</td>\n",
       "      <td>0.4200</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.4467</td>\n",
       "      <td>0.4400</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0000</th>\n",
       "      <td>0.3533</td>\n",
       "      <td>0.3133</td>\n",
       "      <td>0.3300</td>\n",
       "      <td>0.4800</td>\n",
       "      <td>0.3600</td>\n",
       "      <td>0.3300</td>\n",
       "      <td>0.3900</td>\n",
       "      <td>0.3533</td>\n",
       "      <td>0.3500</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>0.4100</td>\n",
       "      <td>0.4533</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>0.6400</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0000</th>\n",
       "      <td>0.2267</td>\n",
       "      <td>0.2400</td>\n",
       "      <td>0.2600</td>\n",
       "      <td>0.1800</td>\n",
       "      <td>0.3600</td>\n",
       "      <td>0.1100</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.2200</td>\n",
       "      <td>0.2400</td>\n",
       "      <td>0.1900</td>\n",
       "      <td>0.2067</td>\n",
       "      <td>0.1933</td>\n",
       "      <td>0.2133</td>\n",
       "      <td>0.2200</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>900 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           18     19     20     49     50     51     52     53     54     55  \\\n",
       "0.0000 0.6933 0.7133 0.5600 0.5200 0.5200 0.5100 0.5200 0.6267 0.5200 0.4800   \n",
       "1.0000 0.1600 0.1000 0.2300 0.1900 0.2000 0.3200 0.2600 0.2400 0.2800 0.2800   \n",
       "2.0000 0.1467 0.1867 0.2100 0.2900 0.2800 0.1700 0.2200 0.1333 0.2000 0.2400   \n",
       "0.0000 0.6000 0.6733 0.5100 0.4800 0.6000 0.5400 0.5300 0.5933 0.5100 0.5100   \n",
       "1.0000 0.2933 0.2000 0.2800 0.2900 0.2400 0.3500 0.3200 0.3067 0.3200 0.3400   \n",
       "2.0000 0.1067 0.1267 0.2100 0.2300 0.1600 0.1100 0.1500 0.1000 0.1700 0.1500   \n",
       "0.0000 0.6067 0.6400 0.5500 0.4800 0.5200 0.5300 0.5200 0.6133 0.5400 0.5500   \n",
       "1.0000 0.2200 0.1533 0.2600 0.3100 0.3000 0.3200 0.3100 0.2600 0.2900 0.2900   \n",
       "2.0000 0.1733 0.2067 0.1900 0.2100 0.1800 0.1500 0.1700 0.1267 0.1700 0.1600   \n",
       "0.0000 0.5667 0.6467 0.4900 0.4800 0.5400 0.5300 0.5100 0.5133 0.5200 0.4900   \n",
       "1.0000 0.2667 0.1733 0.2900 0.3200 0.2200 0.3300 0.3300 0.3533 0.3500 0.3400   \n",
       "2.0000 0.1667 0.1800 0.2200 0.2000 0.2400 0.1400 0.1600 0.1333 0.1300 0.1700   \n",
       "0.0000 0.5467 0.6133 0.4500 0.5100 0.5600 0.5400 0.5700 0.5400 0.5400 0.5500   \n",
       "1.0000 0.2333 0.1733 0.2900 0.2300 0.2400 0.3400 0.2600 0.3000 0.2900 0.2700   \n",
       "2.0000 0.2200 0.2133 0.2600 0.2600 0.2000 0.1200 0.1700 0.1600 0.1700 0.1800   \n",
       "0.0000 0.5733 0.5600 0.4600 0.4500 0.5400 0.4400 0.5100 0.4733 0.4900 0.4900   \n",
       "1.0000 0.2667 0.2800 0.3500 0.3600 0.2600 0.4300 0.3500 0.3733 0.3700 0.3400   \n",
       "2.0000 0.1600 0.1600 0.1900 0.1900 0.2000 0.1300 0.1400 0.1533 0.1400 0.1700   \n",
       "0.0000 0.4400 0.5400 0.3900 0.4000 0.4200 0.4400 0.4800 0.4467 0.3900 0.4800   \n",
       "1.0000 0.3400 0.2667 0.3800 0.3800 0.4000 0.4500 0.3300 0.3867 0.4600 0.3400   \n",
       "2.0000 0.2200 0.1933 0.2300 0.2200 0.1800 0.1100 0.1900 0.1667 0.1500 0.1800   \n",
       "0.0000 0.4867 0.5133 0.4200 0.3500 0.5000 0.3600 0.4700 0.4133 0.4200 0.5000   \n",
       "1.0000 0.3400 0.3267 0.3700 0.5200 0.4200 0.5500 0.4500 0.4933 0.4900 0.4100   \n",
       "2.0000 0.1733 0.1600 0.2100 0.1300 0.0800 0.0900 0.0800 0.0933 0.0900 0.0900   \n",
       "0.0000 0.4267 0.4800 0.3900 0.3200 0.4800 0.3600 0.4500 0.3933 0.4200 0.4400   \n",
       "1.0000 0.3067 0.2533 0.3400 0.4800 0.3400 0.5300 0.3900 0.4400 0.4200 0.4200   \n",
       "2.0000 0.2667 0.2667 0.2700 0.2000 0.1800 0.1100 0.1600 0.1667 0.1600 0.1400   \n",
       "0.0000 0.5600 0.5733 0.4800 0.4500 0.5600 0.4400 0.5200 0.4933 0.5200 0.4700   \n",
       "1.0000 0.2267 0.2000 0.2600 0.4100 0.3400 0.5000 0.3400 0.3600 0.3400 0.3600   \n",
       "2.0000 0.2133 0.2267 0.2600 0.1400 0.1000 0.0600 0.1400 0.1467 0.1400 0.1700   \n",
       "...       ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "0.0000 0.3600 0.4133 0.3500 0.3200 0.3000 0.5300 0.4700 0.4200 0.4400 0.4500   \n",
       "1.0000 0.4400 0.3400 0.3500 0.4900 0.3600 0.3800 0.3800 0.4000 0.3700 0.3500   \n",
       "2.0000 0.2000 0.2467 0.3000 0.1900 0.3400 0.0900 0.1500 0.1800 0.1900 0.2000   \n",
       "0.0000 0.3533 0.4467 0.3600 0.3500 0.3000 0.5600 0.4600 0.4400 0.4500 0.4200   \n",
       "1.0000 0.4133 0.2933 0.3000 0.4600 0.2800 0.3200 0.3600 0.3733 0.3500 0.3300   \n",
       "2.0000 0.2333 0.2600 0.3400 0.1900 0.4200 0.1200 0.1800 0.1867 0.2000 0.2500   \n",
       "0.0000 0.3933 0.4867 0.4200 0.4200 0.3800 0.6400 0.5400 0.4733 0.4600 0.4500   \n",
       "1.0000 0.4200 0.2800 0.2800 0.4300 0.3400 0.3000 0.3200 0.3533 0.3500 0.3400   \n",
       "2.0000 0.1867 0.2333 0.3000 0.1500 0.2800 0.0600 0.1400 0.1733 0.1900 0.2100   \n",
       "0.0000 0.4333 0.4600 0.4300 0.4000 0.3800 0.6100 0.5400 0.4667 0.4700 0.4300   \n",
       "1.0000 0.3667 0.2933 0.2800 0.4400 0.3000 0.2900 0.3200 0.3467 0.3200 0.3200   \n",
       "2.0000 0.2000 0.2467 0.2900 0.1600 0.3200 0.1000 0.1400 0.1867 0.2100 0.2500   \n",
       "0.0000 0.4667 0.5000 0.4400 0.4300 0.3600 0.6300 0.5600 0.4733 0.5000 0.4900   \n",
       "1.0000 0.3467 0.2933 0.2800 0.4000 0.3000 0.2900 0.3000 0.3667 0.3300 0.3100   \n",
       "2.0000 0.1867 0.2067 0.2800 0.1700 0.3400 0.0800 0.1400 0.1600 0.1700 0.2000   \n",
       "0.0000 0.4400 0.5067 0.4200 0.4100 0.3800 0.6400 0.5500 0.5000 0.4800 0.4600   \n",
       "1.0000 0.3667 0.2667 0.3000 0.4100 0.3200 0.2700 0.3000 0.3067 0.3300 0.3200   \n",
       "2.0000 0.1933 0.2267 0.2800 0.1800 0.3000 0.0900 0.1500 0.1933 0.1900 0.2200   \n",
       "0.0000 0.4467 0.4667 0.4000 0.4100 0.3600 0.5900 0.5200 0.4733 0.4600 0.4600   \n",
       "1.0000 0.3600 0.3000 0.3200 0.4100 0.3400 0.3200 0.3300 0.3333 0.3400 0.3600   \n",
       "2.0000 0.1933 0.2333 0.2800 0.1800 0.3000 0.0900 0.1500 0.1933 0.2000 0.1800   \n",
       "0.0000 0.4467 0.4933 0.4500 0.4000 0.3800 0.6100 0.5400 0.4600 0.4700 0.4500   \n",
       "1.0000 0.3600 0.2667 0.2800 0.4200 0.3400 0.3000 0.3000 0.3400 0.3200 0.3700   \n",
       "2.0000 0.1933 0.2400 0.2700 0.1800 0.2800 0.0900 0.1600 0.2000 0.2100 0.1800   \n",
       "0.0000 0.4400 0.4733 0.4500 0.3500 0.3600 0.5800 0.4900 0.4467 0.4500 0.4200   \n",
       "1.0000 0.3467 0.2800 0.2800 0.4800 0.3600 0.3300 0.3600 0.3467 0.3500 0.3600   \n",
       "2.0000 0.2133 0.2467 0.2700 0.1700 0.2800 0.0900 0.1500 0.2067 0.2000 0.2200   \n",
       "0.0000 0.4200 0.4467 0.4100 0.3400 0.2800 0.5600 0.4600 0.4467 0.4300 0.4200   \n",
       "1.0000 0.3533 0.3133 0.3300 0.4800 0.3600 0.3300 0.3900 0.3533 0.3500 0.3400   \n",
       "2.0000 0.2267 0.2400 0.2600 0.1800 0.3600 0.1100 0.1500 0.2000 0.2200 0.2400   \n",
       "\n",
       "           56     57     58     62     63     72  epoch  \n",
       "0.0000 0.5100 0.5333 0.6133 0.5467 0.5150 0.5600      1  \n",
       "1.0000 0.2700 0.3000 0.2133 0.2867 0.2600 0.3100      1  \n",
       "2.0000 0.2200 0.1667 0.1733 0.1667 0.2250 0.1300      1  \n",
       "0.0000 0.5300 0.5400 0.5800 0.5133 0.5200 0.5100      2  \n",
       "1.0000 0.3000 0.3200 0.3533 0.3400 0.3450 0.3700      2  \n",
       "2.0000 0.1700 0.1400 0.0667 0.1467 0.1350 0.1200      2  \n",
       "0.0000 0.5100 0.5800 0.6267 0.4867 0.5750 0.5600      3  \n",
       "1.0000 0.2800 0.2467 0.2467 0.3400 0.2750 0.2800      3  \n",
       "2.0000 0.2100 0.1733 0.1267 0.1733 0.1500 0.1600      3  \n",
       "0.0000 0.4300 0.5133 0.5067 0.4933 0.4750 0.4100      4  \n",
       "1.0000 0.3600 0.3600 0.3533 0.3333 0.3450 0.3800      4  \n",
       "2.0000 0.2100 0.1267 0.1400 0.1733 0.1800 0.2100      4  \n",
       "0.0000 0.4600 0.5467 0.5400 0.4867 0.5050 0.4300      5  \n",
       "1.0000 0.3000 0.3267 0.3133 0.3533 0.2950 0.3300      5  \n",
       "2.0000 0.2400 0.1267 0.1467 0.1600 0.2000 0.2400      5  \n",
       "0.0000 0.4300 0.4733 0.5000 0.4533 0.4300 0.4000      6  \n",
       "1.0000 0.3400 0.4067 0.3800 0.3867 0.3950 0.4100      6  \n",
       "2.0000 0.2300 0.1200 0.1200 0.1600 0.1750 0.1900      6  \n",
       "0.0000 0.4400 0.4067 0.4600 0.4000 0.3950 0.3500      7  \n",
       "1.0000 0.3500 0.4333 0.3667 0.4333 0.4150 0.4300      7  \n",
       "2.0000 0.2100 0.1600 0.1733 0.1667 0.1900 0.2200      7  \n",
       "0.0000 0.4700 0.4467 0.5200 0.4067 0.4250 0.3300      8  \n",
       "1.0000 0.3900 0.4533 0.4000 0.5000 0.4700 0.5200      8  \n",
       "2.0000 0.1400 0.1000 0.0800 0.0933 0.1050 0.1500      8  \n",
       "0.0000 0.4400 0.4400 0.4600 0.4067 0.4050 0.3300      9  \n",
       "1.0000 0.3800 0.4067 0.3867 0.4267 0.4150 0.4500      9  \n",
       "2.0000 0.1800 0.1533 0.1533 0.1667 0.1800 0.2200      9  \n",
       "0.0000 0.4700 0.5400 0.5267 0.5000 0.4750 0.4700     10  \n",
       "1.0000 0.3500 0.3467 0.3400 0.3467 0.3550 0.3800     10  \n",
       "2.0000 0.1800 0.1133 0.1333 0.1533 0.1700 0.1500     10  \n",
       "...       ...    ...    ...    ...    ...    ...    ...  \n",
       "0.0000 0.4300 0.3467 0.4467 0.4400 0.3850 0.1900    291  \n",
       "1.0000 0.3800 0.4800 0.3933 0.3600 0.4200 0.7000    291  \n",
       "2.0000 0.1900 0.1733 0.1600 0.2000 0.1950 0.1100    291  \n",
       "0.0000 0.4300 0.3400 0.4667 0.4333 0.3900 0.1800    292  \n",
       "1.0000 0.3400 0.4533 0.3400 0.3133 0.3700 0.6600    292  \n",
       "2.0000 0.2300 0.2067 0.1933 0.2533 0.2400 0.1600    292  \n",
       "0.0000 0.4900 0.3733 0.5067 0.5133 0.4550 0.2300    293  \n",
       "1.0000 0.3500 0.4600 0.3333 0.3000 0.3600 0.6500    293  \n",
       "2.0000 0.1600 0.1667 0.1600 0.1867 0.1850 0.1200    293  \n",
       "0.0000 0.4800 0.3933 0.5200 0.5133 0.4650 0.2400    294  \n",
       "1.0000 0.3300 0.4267 0.2933 0.3000 0.3300 0.6200    294  \n",
       "2.0000 0.1900 0.1800 0.1867 0.1867 0.2050 0.1400    294  \n",
       "0.0000 0.4800 0.4067 0.5267 0.5200 0.4950 0.2300    295  \n",
       "1.0000 0.3600 0.4400 0.3133 0.3067 0.3350 0.6500    295  \n",
       "2.0000 0.1600 0.1533 0.1600 0.1733 0.1700 0.1200    295  \n",
       "0.0000 0.4900 0.3867 0.5467 0.5333 0.5250 0.2300    296  \n",
       "1.0000 0.3500 0.4400 0.2733 0.2867 0.3000 0.6500    296  \n",
       "2.0000 0.1600 0.1733 0.1800 0.1800 0.1750 0.1200    296  \n",
       "0.0000 0.4900 0.3867 0.5200 0.4867 0.4750 0.2300    297  \n",
       "1.0000 0.3500 0.4333 0.3400 0.3267 0.3300 0.6500    297  \n",
       "2.0000 0.1600 0.1800 0.1400 0.1867 0.1950 0.1200    297  \n",
       "0.0000 0.4700 0.3867 0.4933 0.5267 0.4800 0.2600    298  \n",
       "1.0000 0.3300 0.4267 0.3333 0.2800 0.3250 0.6200    298  \n",
       "2.0000 0.2000 0.1867 0.1733 0.1933 0.1950 0.1200    298  \n",
       "0.0000 0.4200 0.3800 0.4600 0.4800 0.4400 0.2200    299  \n",
       "1.0000 0.3900 0.4400 0.3533 0.3267 0.3700 0.6200    299  \n",
       "2.0000 0.1900 0.1800 0.1867 0.1933 0.1900 0.1600    299  \n",
       "0.0000 0.4000 0.3400 0.4667 0.4467 0.4400 0.2100    300  \n",
       "1.0000 0.4100 0.4533 0.3400 0.3400 0.3400 0.6400    300  \n",
       "2.0000 0.1900 0.2067 0.1933 0.2133 0.2200 0.1500    300  \n",
       "\n",
       "[900 rows x 17 columns]"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

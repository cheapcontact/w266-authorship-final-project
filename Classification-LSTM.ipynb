{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'rnnlm' from 'rnnlm.pyc'>"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json, os, re, shutil, sys, time\n",
    "import collections, itertools\n",
    "import unittest\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# NLTK for NLP utils and corpora\n",
    "import nltk\n",
    "\n",
    "# NumPy and TensorFlow\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "assert(tf.__version__.startswith(\"1.\"))\n",
    "\n",
    "# utils.pretty_print_matrix uses Pandas. Configure float format here.\n",
    "import pandas as pd\n",
    "pd.set_option('float_format', lambda f: \"{0:.04f}\".format(f))\n",
    "\n",
    "# RNNLM Model\n",
    "import rnnlm\n",
    "reload(rnnlm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "class Vocabulary(object):\n",
    "\n",
    "  UNK_TOKEN = \"<unk>\"\n",
    "\n",
    "  def __init__(self, tokens, size=None):\n",
    "    self.unigram_counts = collections.Counter(tokens)\n",
    "    # leave space for \"<s>\", \"</s>\", and \"<unk>\"\n",
    "    top_counts = self.unigram_counts.most_common(None if size is None else (size - 1))\n",
    "    vocab = ([self.UNK_TOKEN] +\n",
    "             [w for w,c in top_counts])\n",
    "\n",
    "    # Assign an id to each word, by frequency\n",
    "    self.id_to_word = dict(enumerate(vocab))\n",
    "    self.word_to_id = {v:k for k,v in self.id_to_word.iteritems()}\n",
    "    self.size = len(self.id_to_word)\n",
    "    if size is not None:\n",
    "        assert(self.size <= size)\n",
    "\n",
    "    # For convenience\n",
    "    self.wordset = set(self.word_to_id.iterkeys())\n",
    "\n",
    "    # Store special IDs\n",
    "    self.UNK_ID = self.word_to_id[self.UNK_TOKEN]\n",
    "\n",
    "  def words_to_ids(self, words):\n",
    "    return [self.word_to_id.get(w, self.UNK_ID) for w in words]\n",
    "\n",
    "  def ids_to_words(self, ids):\n",
    "    return [self.id_to_word[i] for i in ids]\n",
    "\n",
    "  def ordered_words(self):\n",
    "    \"\"\"Return a list of words, ordered by id.\"\"\"\n",
    "    return self.ids_to_words(range(self.size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import re\n",
    "\n",
    "def canonicalize_digits(word):\n",
    "    if any([c.isalpha() for c in word]): return word\n",
    "    word = re.sub(\"\\d\", \"DG\", word)\n",
    "    if word.startswith(\"DG\"):\n",
    "        word = word.replace(\",\", \"\") # remove thousands separator\n",
    "    return word\n",
    "\n",
    "def canonicalize_word(word):\n",
    "    word = word.lower()\n",
    "    return canonicalize_digits(word) # try to canonicalize numbers\n",
    "\n",
    "def canonicalize_words(words):\n",
    "    current = []\n",
    "    for word in words.split(\" \"):   \n",
    "        if word and word[-1] in (\".\", ',', '?', ';', '!'):\n",
    "            punk = word[-1]\n",
    "            current.append(punk)\n",
    "            word = word[0:-1]\n",
    "\n",
    "        word = canonicalize_word(word)\n",
    "        current.append(word)\n",
    "    return current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pretty_timedelta(fmt=\"%d:%02d:%02d\", since=None, until=None):\n",
    "    \"\"\"Pretty-print a timedelta, using the given format string.\"\"\"\n",
    "    since = since or time.time()\n",
    "    until = until or time.time()\n",
    "    delta_s = until - since\n",
    "    hours, remainder = divmod(delta_s, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    return fmt % (hours, minutes, seconds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_train_data():\n",
    "    train_data_dir = 'train_data'\n",
    "    y = []\n",
    "    X = []\n",
    "    all_tokens = []\n",
    "    author_to_id = {}\n",
    "    for author_id, author in enumerate(listdir(train_data_dir)):\n",
    "        author_to_id[author] = author_id\n",
    "        author_path = \"%s/%s\" % (train_data_dir, author)\n",
    "        print author, author_id\n",
    "\n",
    "        for file_name in listdir(author_path):\n",
    "            full_path = \"%s/%s\" % (author_path, file_name)\n",
    "            y.append(author_id)            \n",
    "            with open(full_path, \"r\") as f:\n",
    "                current = canonicalize_words(f.read())\n",
    "                all_tokens += current\n",
    "                X.append(np.array(current))\n",
    "                \n",
    "    vocab = Vocabulary(all_tokens)\n",
    "\n",
    "    # replace words with ids\n",
    "    for i, x in enumerate(X):\n",
    "        X[i] = np.array(vocab.words_to_ids(x))\n",
    "\n",
    "    return vocab, np.array(X), np.array(y), author_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thomas_paine 0\n",
      "thomas_jefferson 1\n",
      "john_adams 2\n",
      "james_madison 3\n",
      "alexander_hamilton 4\n",
      "james_monroe 5\n",
      "john_jay 6\n",
      "george_washington 7\n",
      "benjamin_franklin 8\n",
      "vocab.size 145546\n",
      "{'thomas_jefferson': 1, 'john_adams': 2, 'alexander_hamilton': 4, 'benjamin_franklin': 8, 'george_washington': 7, 'thomas_paine': 0, 'james_madison': 3, 'james_monroe': 5, 'john_jay': 6}\n"
     ]
    }
   ],
   "source": [
    "vocab, X_train, y_train, author_to_id = load_train_data()\n",
    "num_classes = len(np.unique(y_train))\n",
    "print \"vocab.size\", vocab.size\n",
    "print author_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\n",
      "[[ 184    2 3790 ...,  365    5  497]]\n"
     ]
    }
   ],
   "source": [
    "def load_eval_data(vocab):\n",
    "    eval_data_dir = \"unknown_data\"\n",
    "    eval_X = {}\n",
    "    eval_y = {}\n",
    "    for file_name in listdir(eval_data_dir):\n",
    "        full_path = \"%s/%s\" % (eval_data_dir, file_name)\n",
    "        with open(full_path, \"r\") as f:\n",
    "            current = vocab.words_to_ids(canonicalize_words(f.read()))\n",
    "\n",
    "        expanded_X = np.array(current)\n",
    "        id = file_name.split(\"_\")[2].split(\".\")[0]\n",
    "        eval_X[id] = np.array([expanded_X])\n",
    "        # working with the assumption that James Madison wrote all the disputed papers\n",
    "        eval_y[id] = np.array([author_to_id['james_madison']])\n",
    "\n",
    "    return eval_X, eval_y\n",
    "\n",
    "eval_X, eval_y = load_eval_data(vocab)\n",
    "print eval_y['18']\n",
    "print eval_X['18']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 1 1 1 1 1 1 1 1 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 5 6 6 6 6 6 7 7 8]\n",
      "[array([   214,      3, 110275, ...,      3,    107, 117020])\n",
      " array([42483,   344, 22831, ...,     1,   135, 14900])\n",
      " array([   279, 116136,   3396, ...,   6758,      3,  21317])\n",
      " array([   47,   192,     3, ...,   591,   516, 38425])\n",
      " array([   13,    58,    19, ...,  2333,   120, 96859])\n",
      " array([61541,     1,   135, ...,   432,     6, 38425])\n",
      " array([   13,   789,    27, ...,     5,  3499, 45432])\n",
      " array([   11,    12,     8, ...,     5, 51014,  1028])\n",
      " array([ 56122,    132,   1821, ...,     14,    613, 118907])\n",
      " array([   13,   156,     8, ...,   169, 15270, 57131])\n",
      " array([  1028,      4,    712, ...,      3,      2, 125230])\n",
      " array([   13,   696,     4, ...,   527,     6, 27168])\n",
      " array([   13,    31,    18, ..., 77518,     5,  7580])\n",
      " array([   2,  132,  346, ...,    5,  231, 3420])\n",
      " array([  11,   31, 1149, ...,    5,  313, 3420])\n",
      " array([  2, 418, 271, ...,   3,   5, 690])\n",
      " array([ 157, 1149,    9, ...,    5,  278, 3420])\n",
      " array([ 157, 8665,    2, ...,    5,  346, 3420])\n",
      " array([   2,  418, 1129, ...,    5,  704, 3420])\n",
      " array([     7,    482,      3, ...,      3,    220, 124105])\n",
      " array([    13,    102,     21, ..., 114169,      5,  21061])\n",
      " array([   44,  1750,    22, ...,   182,   143, 51870])\n",
      " array([ 184,    2, 1018, ...,    5, 1707, 3420])\n",
      " array([7819,    2,  116, ...,    5,   43, 3420])\n",
      " array([  42,   19,  397, ...,    5,  715, 3420])\n",
      " array([   2,  137,  303, ...,  746, 3012, 3420])\n",
      " array([   7, 7549,    2, ...,  103,    5, 3294])\n",
      " array([  11,   12,   21, ...,    5, 1664, 3420])\n",
      " array([   8, 3018, 1129, ...,    5, 1879, 3420])\n",
      " array([  35,    2,  484, ...,   12,    5, 2446])\n",
      " array([ 613,    3,    2, ..., 6827,  516, 4965])\n",
      " array([ 22727,    714,      3, ...,      3, 121423,  66101])\n",
      " array([   2, 2076, 1129, ...,    5,   54, 3420])\n",
      " array([ 57471,    132,     31, ...,     20,     32, 141555])\n",
      " array([ 28329,    248,     17, ...,     18,      9, 122739])\n",
      " array([     1,   6717,    977, ...,   9650,      4, 121872])\n",
      " array([  11,   40,  249, ...,    5, 2906, 3420])\n",
      " array([   2,  208,   12, ...,    5,  627, 3420])\n",
      " array([19151, 34633,  3800, ...,   432,     4, 21317])\n",
      " array([ 171,   36, 3623, ...,  103,    5,  137])\n",
      " array([  1886,      4,  42536, ...,    301,      3, 123882])\n",
      " array([   11,    12,   758, ...,  1356,     5, 14355])\n",
      " array([   2,  671, 4074, ...,   24,    5,  276])\n",
      " array([  42,   19,  397, ...,  229,    5, 7919])\n",
      " array([ 394,    4, 6621, ...,  239,    5,  186])\n",
      " array([   2,  208,    3, ...,    5, 3472, 3420])\n",
      " array([   2,  510,    3, ...,    5, 2022, 3420])\n",
      " array([  1264,      1,    186, ..., 116951,   1886,  23764])\n",
      " array([306,  72,  95, ..., 394,   5, 346])\n",
      " array([    5,    50, 84966, ...,     3,  4962, 74944])\n",
      " array([  1320,      1,    135, ...,     39,     37, 135205])\n",
      " array([   2, 2502,    3, ...,    5,  278, 3420])\n",
      " array([   8, 1810,    3, ...,    3,    5, 5378])\n",
      " array([    1,    42,     2, ...,    53,     3, 25775])\n",
      " array([42, 19,  1, ..., 24,  5, 75])\n",
      " array([  11,   39,   37, ...,  229,    5, 7919])\n",
      " array([   2, 1189,  185, ...,    5, 2839, 3420])\n",
      " array([   2,  402,    3, ...,    5, 1528, 3420])\n",
      " array([   2, 6091,    3, ..., 1917,    5,  135])\n",
      " array([  816,     3,     2, ...,    48,    53, 93581])\n",
      " array([  11,   31,    8, ...,    5, 3458, 3420])\n",
      " array([   361,      6, 111267, ...,   1238,      6,  74759])\n",
      " array([ 822,   13,  102, ...,    5,  442, 3420])\n",
      " array([    5,    50, 95938, ...,  4231,     8, 53971])\n",
      " array([  5751,      3,      2, ..., 125721, 118755, 123349])\n",
      " array([ 1273,     1,   186, ...,    28, 13288, 23764])\n",
      " array([  270,    21,    78, ...,    99,  1405, 46169])\n",
      " array([ 127,   42,  619, ...,    5,  205, 3420])\n",
      " array([  4,   2, 185, ...,  24,   5, 169])\n",
      " array([ 73759, 138934,    215, ...,     12,     21,  63520])\n",
      " array([  11,   39,   37, ...,  779,    5, 8489])\n",
      " array([  388,     4,     2, ..., 29405, 38987,     2])\n",
      " array([  2, 468, 230, ..., 977,   5, 239])\n",
      " array([ 2058,     6,  1551, ...,    18,    28, 96168])\n",
      " array([  13, 2520,  199, ...,    5,  378, 3420])\n",
      " array([   8, 1591,  278, ..., 8490,    5,   13])\n",
      " array([   40,    11,  1360, ...,    25,    10, 76328])\n",
      " array([     2,    752,    135, ..., 123599,  14851,  23764])\n",
      " array([4817,   11,  138, ...,   24,    5,  116])\n",
      " array([     2,   3559, 119806, ...,     29,      8,  45279])\n",
      " array([   2,  621,    4, ...,    6,    5, 9790])\n",
      " array([   2,   97,    3, ...,    5, 3763, 3420])\n",
      " array([  11,   39,   37, ...,    5,   11, 3420])\n",
      " array([  42,  619,   95, ..., 1719,    5, 3416])\n",
      " array([    2,   208,    12, ...,     7, 29356,  3420])\n",
      " array([ 73127,      4,     47, ...,      7,     41, 142475])\n",
      " array([    2,   237,   132, ...,   317,     5, 39598])\n",
      " array([    2,  1074,     3, ...,     5, 18185,  3420])\n",
      " array([  36,    1,  621, ...,    5,  395, 3420])\n",
      " array([  145,   150,  4585, ...,     3,     2, 91446])\n",
      " array([  2, 137,   3, ..., 963,   5, 135])\n",
      " array([    7, 10615,     3, ...,     5,    57,  3420])\n",
      " array([ 157,    7,    2, ...,    5,  443, 3420])\n",
      " array([    2,   494,     3, ...,  8388,  4446, 61230])\n",
      " array([     5,     73, 115293, ...,    976,     12,  83049])\n",
      " array([81572,     1,   186, ...,   537,     3, 79784])\n",
      " array([1886,    4, 5115, ...,    5, 1029, 4031])\n",
      " array([    7,     2,   168, ...,    18,     2, 16539])\n",
      " array([  14, 1284,   20, ...,    5,  107, 3420])\n",
      " array([  59,   12,   36, ...,  229,    5, 7919])\n",
      " array([     5,     50, 105165, ...,      6,   4386,  44155])\n",
      " array([   9,   59,   40, ..., 2045,    5, 1375])\n",
      " array([   2,  921,    3, ...,  604,    5, 1338])\n",
      " array([    15,  16399,    135, ...,   9309,      8, 118249])\n",
      " array([   4,  438,   20, ...,    5,  663, 3420])\n",
      " array([    50, 109235,      2, ...,   3443, 106208,  61818])\n",
      " array([  7, 956,   4, ...,   8,   5, 456])\n",
      " array([    2,   123,     3, ...,  3389,     2, 78497])\n",
      " array([   59,    30,  2043, ...,     3,  9325, 42863])\n",
      " array([119574,      1,    135, ...,     36,   3365,  55076])\n",
      " array([1740,    7,  324, ...,    2,    5,  123])\n",
      " array([   2,   56, 2100, ...,    5, 7148, 3420])\n",
      " array([     2,    533,      3, ...,  90744,      5, 113690])\n",
      " array([    4,     2,  1565, ...,     2,    54, 97797])\n",
      " array([  13,  619,   95, ...,   93,    5, 1317])\n",
      " array([    7,     2,   168, ...,     6,     5, 15136])\n",
      " array([   35,    50,   484, ...,     3,     5, 15139])\n",
      " array([ 3942,     1, 16424, ...,     5,   148,  3420])\n",
      " array([    98,      2,    123, ...,     46, 121152,   3420])\n",
      " array([  11,   12,   21, ...,  105,  139, 3420])\n",
      " array([  46,  132,  346, ...,    5,  202, 3420])\n",
      " array([  11,   12,    8, ...,    5, 5378, 3420])\n",
      " array([    13,   2354,     20, ...,      5, 104911,    712])\n",
      " array([  672,     1,    15, ...,     1,     3, 47280])\n",
      " array([    1, 72603,    35, ..., 66877,     5, 53167])]\n"
     ]
    }
   ],
   "source": [
    "print y_train\n",
    "print X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def batch_generator(publications, authors, batch_size, max_time):\n",
    "    \"\"\"Convert ids to data-matrix form.\"\"\"\n",
    "    all_w = []\n",
    "    all_y = []\n",
    "    for i, ids in enumerate(publications):\n",
    "        # Clip to multiple of max_time for convenience\n",
    "        clip_len = ((len(ids)-1) / batch_size) * batch_size\n",
    "        \n",
    "        input_w = ids[:clip_len]     # current word\n",
    "        target_y = ids[1:clip_len+1]  # next word\n",
    "        # Reshape so we can select columns\n",
    "        input_w = input_w.reshape([batch_size,-1])\n",
    "\n",
    "        for j in xrange(0, input_w.shape[1], max_time):\n",
    "            this_w = input_w[:,j:j+max_time]\n",
    "            all_w.append(this_w)\n",
    "            all_y.append(np.full_like(this_w, authors[i]))\n",
    "\n",
    "    # Yield batches in random order     \n",
    "    data = range(0, len(all_y)-1)\n",
    "    random.shuffle(data)   \n",
    "\n",
    "    for k in data:\n",
    "        yield all_w[k], all_y[k]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 4 4 4 4]\n",
      " [4 4 4 4 4]\n",
      " [4 4 4 4 4]\n",
      " [4 4 4 4 4]\n",
      " [4 4 4 4 4]\n",
      " [4 4 4 4 4]\n",
      " [4 4 4 4 4]\n",
      " [4 4 4 4 4]\n",
      " [4 4 4 4 4]\n",
      " [4 4 4 4 4]]\n",
      "[[   515     38    994      3     55]\n",
      " [     6      1  14093     30      7]\n",
      " [  8629 117527      2   4224      3]\n",
      " [     1    386     30      2    917]\n",
      " [    11   3161      8     56   4136]\n",
      " [    12     36    375      3     44]\n",
      " [    10   2192     82     21     78]\n",
      " [  1258     14     33     30    371]\n",
      " [     2      5   4866      2   1561]\n",
      " [    36   2364  49771    413      4]]\n"
     ]
    }
   ],
   "source": [
    "for i, (w, y) in enumerate(batch_generator(X_train, y_train, 10, 5)):\n",
    "    print y\n",
    "    print w \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_epoch(lm, session, batch_iterator,\n",
    "              train=False, verbose=False,\n",
    "              tick_s=10, learning_rate=0.1):\n",
    "    start_time = time.time()\n",
    "    tick_time = start_time  # for showing status\n",
    "    total_cost = 0.0  # total cost, summed over all words\n",
    "    total_batches = 0\n",
    "    total_words = 0\n",
    "\n",
    "    if train:\n",
    "        train_op = lm.train_step_\n",
    "        use_dropout = True\n",
    "    else:\n",
    "        train_op = tf.no_op()\n",
    "        use_dropout = False  # no dropout at test time\n",
    "\n",
    "    for i, (w, y) in enumerate(batch_iterator):\n",
    "        cost = 0.0\n",
    "        # At first batch in epoch, get a clean intitial state.\n",
    "        if i == 0:\n",
    "            h = session.run(lm.initial_h_, {lm.input_w_: w})\n",
    "            \n",
    "        feed_dict = {lm.input_w_: w,\n",
    "                     lm.target_y_: y,\n",
    "                     lm.initial_h_: h,\n",
    "                     lm.learning_rate_: learning_rate,\n",
    "                     lm.use_dropout_: use_dropout}\n",
    "        \n",
    "        _, h, cost = session.run([train_op, lm.final_h_, lm.loss_], feed_dict)  \n",
    "\n",
    "        total_cost += cost\n",
    "        total_batches = i + 1\n",
    "        total_words += w.size  # w.size = batch_size * max_time\n",
    "\n",
    "        ##\n",
    "        # Print average loss-so-far for epoch\n",
    "        # If using train_loss_, this may be an underestimate.\n",
    "        if verbose and (time.time() - tick_time >= tick_s):\n",
    "            avg_cost = total_cost / total_batches\n",
    "            avg_wps = total_words / (time.time() - start_time)\n",
    "            print \"[batch %d]: seen %d words at %d wps, loss = %.3f\" % (\n",
    "                i, total_words, avg_wps, avg_cost)\n",
    "            tick_time = time.time()  # reset time ticker\n",
    "\n",
    "    return total_cost / total_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score_dataset(lm, session, ids, authors, max_time, name=\"Data\"):\n",
    "    # For scoring, we can use larger batches to speed things up.\n",
    "    bi = batch_generator(ids, authors, batch_size=100, max_time=max_time)\n",
    "    cost = run_epoch(lm, session, bi, \n",
    "                     learning_rate=1.0, train=False, \n",
    "                     verbose=False, tick_s=3600)\n",
    "    print \"%s: avg. loss: %.03f  (perplexity: %.02f)\" % (name, cost, np.exp(cost))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.50\n",
      "john_adams: 0.50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def print_prediction_results(predictions, author_to_id):\n",
    "    print \"Truth:\", 'james_madison'\n",
    "    counts = defaultdict(float)\n",
    "    for p in predictions:\n",
    "        counts[p] += 1\n",
    "\n",
    "    print \"Prediction Summary:\"\n",
    "    for id, count in counts.iteritems():\n",
    "        print \"%s: %.2f\" % (id_to_author(author_to_id, id), count/len(predictions))\n",
    "    print \"\"\n",
    "\n",
    "def id_to_author(author_to_id, id):\n",
    "    for author, author_id in author_to_id.iteritems():\n",
    "        if id == author_id:\n",
    "            return author\n",
    "    \n",
    "def predict_paper(lm, session, batch_iterator, authors, paper_name):\n",
    "    total_predictions = np.array([])\n",
    "    print \"Predicting for %s\" % paper_name\n",
    "    for i, (w, y) in enumerate(batch_iterator):        \n",
    "        feed_dict = {lm.input_w_: w,\n",
    "                     lm.target_y_: y}\n",
    "        \n",
    "        cost, truths, logits, predictions = session.run([lm.loss_, lm.target_y_last_, lm.logits_last_, lm.predictions_], feed_dict)  \n",
    "        total_predictions = np.append(total_predictions, predictions.reshape(-1))\n",
    "\n",
    "    print_prediction_results(total_predictions, authors)\n",
    "    \n",
    "print_prediction_results([1, 2, 1, 2], author_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "max_time = 15\n",
    "batch_size = 40\n",
    "learning_rate = 0.1\n",
    "num_epochs = 10\n",
    "\n",
    "# Model parameters\n",
    "model_params = dict(V=vocab.size, \n",
    "                    H=100, \n",
    "                    num_classes=num_classes,\n",
    "                    num_layers=1)\n",
    "\n",
    "TF_SAVEDIR = \"tf_saved\"\n",
    "checkpoint_filename = os.path.join(TF_SAVEDIR, \"rnnlm\")\n",
    "trained_filename = os.path.join(TF_SAVEDIR, \"rnnlm_trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] Starting epoch 1\n",
      "[batch 5667]: seen 3371120 words at 33707 wps, loss = 1.425\n",
      "[epoch 1] Completed in 0:01:48\n",
      "[epoch 1] Federalist Paper 18: avg. loss: 1.531  (perplexity: 4.62)\n",
      "Predicting for Federalist Paper 20\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.79\n",
      "james_madison: 0.11\n",
      "alexander_hamilton: 0.10\n",
      "\n",
      "Predicting for Federalist Paper 58\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.56\n",
      "james_madison: 0.19\n",
      "alexander_hamilton: 0.25\n",
      "\n",
      "Predicting for Federalist Paper 49\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.53\n",
      "james_madison: 0.12\n",
      "alexander_hamilton: 0.35\n",
      "\n",
      "Predicting for Federalist Paper 55\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.58\n",
      "james_madison: 0.13\n",
      "alexander_hamilton: 0.28\n",
      "\n",
      "Predicting for Federalist Paper 54\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.57\n",
      "james_madison: 0.14\n",
      "alexander_hamilton: 0.28\n",
      "\n",
      "Predicting for Federalist Paper 57\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.53\n",
      "james_madison: 0.17\n",
      "alexander_hamilton: 0.29\n",
      "\n",
      "Predicting for Federalist Paper 56\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.57\n",
      "james_madison: 0.12\n",
      "alexander_hamilton: 0.30\n",
      "\n",
      "Predicting for Federalist Paper 51\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.48\n",
      "james_madison: 0.14\n",
      "alexander_hamilton: 0.38\n",
      "\n",
      "Predicting for Federalist Paper 50\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.71\n",
      "james_madison: 0.09\n",
      "alexander_hamilton: 0.20\n",
      "\n",
      "Predicting for Federalist Paper 53\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.63\n",
      "james_madison: 0.11\n",
      "alexander_hamilton: 0.26\n",
      "\n",
      "Predicting for Federalist Paper 52\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.61\n",
      "james_madison: 0.22\n",
      "alexander_hamilton: 0.17\n",
      "\n",
      "Predicting for Federalist Paper 19\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.69\n",
      "james_madison: 0.12\n",
      "alexander_hamilton: 0.18\n",
      "\n",
      "Predicting for Federalist Paper 62\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.61\n",
      "james_madison: 0.14\n",
      "alexander_hamilton: 0.25\n",
      "\n",
      "Predicting for Federalist Paper 63\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.69\n",
      "james_madison: 0.14\n",
      "alexander_hamilton: 0.18\n",
      "\n",
      "Predicting for Federalist Paper 18\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.77\n",
      "james_madison: 0.08\n",
      "alexander_hamilton: 0.15\n",
      "\n",
      "\n",
      "[epoch 2] Starting epoch 2\n",
      "[batch 5673]: seen 3376280 words at 33759 wps, loss = 1.350\n",
      "[epoch 2] Completed in 0:01:48\n",
      "[epoch 2] Federalist Paper 18: avg. loss: 1.703  (perplexity: 5.49)\n",
      "Predicting for Federalist Paper 20\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.71\n",
      "james_madison: 0.12\n",
      "alexander_hamilton: 0.16\n",
      "\n",
      "Predicting for Federalist Paper 58\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.39\n",
      "james_madison: 0.23\n",
      "alexander_hamilton: 0.38\n",
      "\n",
      "Predicting for Federalist Paper 49\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.34\n",
      "james_madison: 0.20\n",
      "alexander_hamilton: 0.46\n",
      "\n",
      "Predicting for Federalist Paper 55\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.48\n",
      "james_madison: 0.19\n",
      "alexander_hamilton: 0.33\n",
      "\n",
      "Predicting for Federalist Paper 54\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.44\n",
      "james_madison: 0.20\n",
      "alexander_hamilton: 0.36\n",
      "\n",
      "Predicting for Federalist Paper 57\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.42\n",
      "james_madison: 0.26\n",
      "alexander_hamilton: 0.32\n",
      "\n",
      "Predicting for Federalist Paper 56\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.46\n",
      "james_madison: 0.21\n",
      "alexander_hamilton: 0.33\n",
      "\n",
      "Predicting for Federalist Paper 51\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.33\n",
      "james_madison: 0.21\n",
      "alexander_hamilton: 0.46\n",
      "\n",
      "Predicting for Federalist Paper 50\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.56\n",
      "james_madison: 0.14\n",
      "alexander_hamilton: 0.30\n",
      "\n",
      "Predicting for Federalist Paper 53\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.46\n",
      "james_madison: 0.13\n",
      "alexander_hamilton: 0.41\n",
      "\n",
      "Predicting for Federalist Paper 52\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.44\n",
      "james_madison: 0.23\n",
      "alexander_hamilton: 0.33\n",
      "\n",
      "Predicting for Federalist Paper 19\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.57\n",
      "james_madison: 0.15\n",
      "alexander_hamilton: 0.28\n",
      "\n",
      "Predicting for Federalist Paper 62\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.47\n",
      "james_madison: 0.23\n",
      "alexander_hamilton: 0.31\n",
      "\n",
      "Predicting for Federalist Paper 63\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.49\n",
      "james_madison: 0.19\n",
      "alexander_hamilton: 0.32\n",
      "\n",
      "Predicting for Federalist Paper 18\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.62\n",
      "james_madison: 0.09\n",
      "alexander_hamilton: 0.28\n",
      "\n",
      "\n",
      "[epoch 3] Starting epoch 3\n",
      "[batch 5684]: seen 3381680 words at 33815 wps, loss = 1.315\n",
      "[epoch 3] Completed in 0:01:48\n",
      "[epoch 3] Federalist Paper 18: avg. loss: 1.879  (perplexity: 6.55)\n",
      "Predicting for Federalist Paper 20\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.55\n",
      "alexander_hamilton: 0.45\n",
      "\n",
      "Predicting for Federalist Paper 58\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.27\n",
      "james_madison: 0.02\n",
      "alexander_hamilton: 0.72\n",
      "\n",
      "Predicting for Federalist Paper 49\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.23\n",
      "james_madison: 0.01\n",
      "alexander_hamilton: 0.76\n",
      "\n",
      "Predicting for Federalist Paper 55\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.38\n",
      "james_madison: 0.03\n",
      "alexander_hamilton: 0.59\n",
      "\n",
      "Predicting for Federalist Paper 54\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.31\n",
      "james_madison: 0.04\n",
      "alexander_hamilton: 0.65\n",
      "\n",
      "Predicting for Federalist Paper 57\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.35\n",
      "james_madison: 0.03\n",
      "alexander_hamilton: 0.62\n",
      "\n",
      "Predicting for Federalist Paper 56\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.34\n",
      "james_madison: 0.01\n",
      "alexander_hamilton: 0.65\n",
      "\n",
      "Predicting for Federalist Paper 51\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.26\n",
      "james_madison: 0.06\n",
      "alexander_hamilton: 0.68\n",
      "\n",
      "Predicting for Federalist Paper 50\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.47\n",
      "james_madison: 0.04\n",
      "alexander_hamilton: 0.49\n",
      "\n",
      "Predicting for Federalist Paper 53\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.31\n",
      "james_madison: 0.03\n",
      "alexander_hamilton: 0.67\n",
      "\n",
      "Predicting for Federalist Paper 52\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.34\n",
      "james_madison: 0.05\n",
      "alexander_hamilton: 0.61\n",
      "\n",
      "Predicting for Federalist Paper 19\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.50\n",
      "james_madison: 0.04\n",
      "alexander_hamilton: 0.46\n",
      "\n",
      "Predicting for Federalist Paper 62\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.34\n",
      "james_madison: 0.06\n",
      "alexander_hamilton: 0.60\n",
      "\n",
      "Predicting for Federalist Paper 63\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.39\n",
      "james_madison: 0.04\n",
      "alexander_hamilton: 0.58\n",
      "\n",
      "Predicting for Federalist Paper 18\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.54\n",
      "james_madison: 0.01\n",
      "alexander_hamilton: 0.45\n",
      "\n",
      "\n",
      "[epoch 4] Starting epoch 4\n",
      "[batch 5741]: seen 3415480 words at 34149 wps, loss = 1.283\n",
      "[epoch 4] Completed in 0:01:47\n",
      "[epoch 4] Federalist Paper 18: avg. loss: 1.773  (perplexity: 5.89)\n",
      "Predicting for Federalist Paper 20\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.51\n",
      "james_madison: 0.03\n",
      "alexander_hamilton: 0.46\n",
      "\n",
      "Predicting for Federalist Paper 58\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.27\n",
      "james_madison: 0.08\n",
      "alexander_hamilton: 0.65\n",
      "\n",
      "Predicting for Federalist Paper 49\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.21\n",
      "james_madison: 0.03\n",
      "alexander_hamilton: 0.76\n",
      "\n",
      "Predicting for Federalist Paper 55\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.32\n",
      "james_madison: 0.05\n",
      "alexander_hamilton: 0.63\n",
      "\n",
      "Predicting for Federalist Paper 54\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.27\n",
      "james_madison: 0.10\n",
      "alexander_hamilton: 0.63\n",
      "\n",
      "Predicting for Federalist Paper 57\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.29\n",
      "james_madison: 0.06\n",
      "alexander_hamilton: 0.65\n",
      "\n",
      "Predicting for Federalist Paper 56\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.21\n",
      "james_madison: 0.09\n",
      "alexander_hamilton: 0.70\n",
      "\n",
      "Predicting for Federalist Paper 51\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.21\n",
      "james_madison: 0.10\n",
      "alexander_hamilton: 0.69\n",
      "\n",
      "Predicting for Federalist Paper 50\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.41\n",
      "james_madison: 0.07\n",
      "alexander_hamilton: 0.51\n",
      "\n",
      "Predicting for Federalist Paper 53\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.26\n",
      "james_madison: 0.04\n",
      "alexander_hamilton: 0.70\n",
      "\n",
      "Predicting for Federalist Paper 52\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.29\n",
      "james_madison: 0.12\n",
      "alexander_hamilton: 0.59\n",
      "\n",
      "Predicting for Federalist Paper 19\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.47\n",
      "james_madison: 0.06\n",
      "alexander_hamilton: 0.47\n",
      "\n",
      "Predicting for Federalist Paper 62\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.30\n",
      "james_madison: 0.07\n",
      "alexander_hamilton: 0.63\n",
      "\n",
      "Predicting for Federalist Paper 63\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.34\n",
      "james_madison: 0.10\n",
      "alexander_hamilton: 0.56\n",
      "\n",
      "Predicting for Federalist Paper 18\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.54\n",
      "james_madison: 0.02\n",
      "alexander_hamilton: 0.44\n",
      "\n",
      "\n",
      "[epoch 5] Starting epoch 5\n",
      "[batch 5733]: seen 3410120 words at 34096 wps, loss = 1.272\n",
      "[epoch 5] Completed in 0:01:47\n",
      "[epoch 5] Federalist Paper 18: avg. loss: 1.763  (perplexity: 5.83)\n",
      "Predicting for Federalist Paper 20\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.50\n",
      "james_madison: 0.05\n",
      "alexander_hamilton: 0.45\n",
      "\n",
      "Predicting for Federalist Paper 58\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.23\n",
      "james_madison: 0.10\n",
      "alexander_hamilton: 0.68\n",
      "\n",
      "Predicting for Federalist Paper 49\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.16\n",
      "james_madison: 0.05\n",
      "alexander_hamilton: 0.79\n",
      "\n",
      "Predicting for Federalist Paper 55\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.28\n",
      "james_madison: 0.06\n",
      "alexander_hamilton: 0.66\n",
      "\n",
      "Predicting for Federalist Paper 54\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.18\n",
      "james_madison: 0.12\n",
      "alexander_hamilton: 0.69\n",
      "\n",
      "Predicting for Federalist Paper 57\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.27\n",
      "james_madison: 0.07\n",
      "alexander_hamilton: 0.67\n",
      "\n",
      "Predicting for Federalist Paper 56\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.19\n",
      "james_madison: 0.09\n",
      "alexander_hamilton: 0.72\n",
      "\n",
      "Predicting for Federalist Paper 51\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.20\n",
      "james_madison: 0.12\n",
      "alexander_hamilton: 0.68\n",
      "\n",
      "Predicting for Federalist Paper 50\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.38\n",
      "james_madison: 0.07\n",
      "alexander_hamilton: 0.55\n",
      "\n",
      "Predicting for Federalist Paper 53\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.23\n",
      "james_madison: 0.05\n",
      "alexander_hamilton: 0.72\n",
      "\n",
      "Predicting for Federalist Paper 52\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.27\n",
      "james_madison: 0.12\n",
      "alexander_hamilton: 0.62\n",
      "\n",
      "Predicting for Federalist Paper 19\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.46\n",
      "james_madison: 0.08\n",
      "alexander_hamilton: 0.46\n",
      "\n",
      "Predicting for Federalist Paper 62\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.28\n",
      "james_madison: 0.07\n",
      "alexander_hamilton: 0.65\n",
      "\n",
      "Predicting for Federalist Paper 63\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.28\n",
      "james_madison: 0.12\n",
      "alexander_hamilton: 0.60\n",
      "\n",
      "Predicting for Federalist Paper 18\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.53\n",
      "james_madison: 0.03\n",
      "alexander_hamilton: 0.44\n",
      "\n",
      "\n",
      "[epoch 6] Starting epoch 6\n",
      "[batch 5663]: seen 3367040 words at 33670 wps, loss = 1.263\n",
      "[epoch 6] Completed in 0:01:48\n",
      "[epoch 6] Federalist Paper 18: avg. loss: 1.767  (perplexity: 5.85)\n",
      "Predicting for Federalist Paper 20\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.60\n",
      "james_madison: 0.12\n",
      "alexander_hamilton: 0.28\n",
      "\n",
      "Predicting for Federalist Paper 58\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.33\n",
      "james_madison: 0.22\n",
      "alexander_hamilton: 0.45\n",
      "\n",
      "Predicting for Federalist Paper 49\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.23\n",
      "james_madison: 0.19\n",
      "alexander_hamilton: 0.59\n",
      "\n",
      "Predicting for Federalist Paper 55\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.38\n",
      "james_madison: 0.15\n",
      "alexander_hamilton: 0.47\n",
      "\n",
      "Predicting for Federalist Paper 54\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.30\n",
      "james_madison: 0.23\n",
      "alexander_hamilton: 0.47\n",
      "\n",
      "Predicting for Federalist Paper 57\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.40\n",
      "james_madison: 0.21\n",
      "alexander_hamilton: 0.39\n",
      "\n",
      "Predicting for Federalist Paper 56\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.30\n",
      "james_madison: 0.20\n",
      "alexander_hamilton: 0.50\n",
      "\n",
      "Predicting for Federalist Paper 51\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.25\n",
      "james_madison: 0.24\n",
      "alexander_hamilton: 0.51\n",
      "\n",
      "Predicting for Federalist Paper 50\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.49\n",
      "james_madison: 0.14\n",
      "alexander_hamilton: 0.38\n",
      "\n",
      "Predicting for Federalist Paper 53\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.34\n",
      "james_madison: 0.17\n",
      "alexander_hamilton: 0.49\n",
      "\n",
      "Predicting for Federalist Paper 52\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.34\n",
      "james_madison: 0.23\n",
      "alexander_hamilton: 0.42\n",
      "\n",
      "Predicting for Federalist Paper 19\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.52\n",
      "james_madison: 0.15\n",
      "alexander_hamilton: 0.33\n",
      "\n",
      "Predicting for Federalist Paper 62\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.34\n",
      "james_madison: 0.21\n",
      "alexander_hamilton: 0.45\n",
      "\n",
      "Predicting for Federalist Paper 63\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.40\n",
      "james_madison: 0.23\n",
      "alexander_hamilton: 0.38\n",
      "\n",
      "Predicting for Federalist Paper 18\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.62\n",
      "james_madison: 0.07\n",
      "alexander_hamilton: 0.31\n",
      "\n",
      "\n",
      "[epoch 7] Starting epoch 7\n",
      "[batch 5623]: seen 3346000 words at 33456 wps, loss = 1.252\n",
      "[epoch 7] Completed in 0:01:49\n",
      "[epoch 7] Federalist Paper 18: avg. loss: 1.648  (perplexity: 5.20)\n",
      "Predicting for Federalist Paper 20\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.46\n",
      "james_madison: 0.15\n",
      "alexander_hamilton: 0.39\n",
      "\n",
      "Predicting for Federalist Paper 58\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.24\n",
      "james_madison: 0.23\n",
      "alexander_hamilton: 0.53\n",
      "\n",
      "Predicting for Federalist Paper 49\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.15\n",
      "james_madison: 0.16\n",
      "alexander_hamilton: 0.69\n",
      "\n",
      "Predicting for Federalist Paper 55\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.29\n",
      "james_madison: 0.16\n",
      "alexander_hamilton: 0.55\n",
      "\n",
      "Predicting for Federalist Paper 54\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.21\n",
      "james_madison: 0.26\n",
      "alexander_hamilton: 0.53\n",
      "\n",
      "Predicting for Federalist Paper 57\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.28\n",
      "james_madison: 0.22\n",
      "alexander_hamilton: 0.50\n",
      "\n",
      "Predicting for Federalist Paper 56\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.21\n",
      "james_madison: 0.19\n",
      "alexander_hamilton: 0.60\n",
      "\n",
      "Predicting for Federalist Paper 51\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.19\n",
      "james_madison: 0.27\n",
      "alexander_hamilton: 0.54\n",
      "\n",
      "Predicting for Federalist Paper 50\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.34\n",
      "james_madison: 0.21\n",
      "alexander_hamilton: 0.45\n",
      "\n",
      "Predicting for Federalist Paper 53\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.23\n",
      "james_madison: 0.18\n",
      "alexander_hamilton: 0.58\n",
      "\n",
      "Predicting for Federalist Paper 52\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.23\n",
      "james_madison: 0.27\n",
      "alexander_hamilton: 0.50\n",
      "\n",
      "Predicting for Federalist Paper 19\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.43\n",
      "james_madison: 0.17\n",
      "alexander_hamilton: 0.39\n",
      "\n",
      "Predicting for Federalist Paper 62\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.28\n",
      "james_madison: 0.24\n",
      "alexander_hamilton: 0.48\n",
      "\n",
      "Predicting for Federalist Paper 63\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.29\n",
      "james_madison: 0.22\n",
      "alexander_hamilton: 0.49\n",
      "\n",
      "Predicting for Federalist Paper 18\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.51\n",
      "james_madison: 0.10\n",
      "alexander_hamilton: 0.39\n",
      "\n",
      "\n",
      "[epoch 8] Starting epoch 8\n",
      "[batch 5579]: seen 3317800 words at 33174 wps, loss = 1.239\n",
      "[epoch 8] Completed in 0:01:50\n",
      "[epoch 8] Federalist Paper 18: avg. loss: 1.707  (perplexity: 5.51)\n",
      "Predicting for Federalist Paper 20\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.40\n",
      "james_madison: 0.11\n",
      "alexander_hamilton: 0.49\n",
      "\n",
      "Predicting for Federalist Paper 58\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.17\n",
      "james_madison: 0.17\n",
      "alexander_hamilton: 0.65\n",
      "\n",
      "Predicting for Federalist Paper 49\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.15\n",
      "james_madison: 0.09\n",
      "alexander_hamilton: 0.76\n",
      "\n",
      "Predicting for Federalist Paper 55\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.23\n",
      "james_madison: 0.11\n",
      "alexander_hamilton: 0.67\n",
      "\n",
      "Predicting for Federalist Paper 54\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.15\n",
      "james_madison: 0.18\n",
      "alexander_hamilton: 0.67\n",
      "\n",
      "Predicting for Federalist Paper 57\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.23\n",
      "james_madison: 0.11\n",
      "alexander_hamilton: 0.66\n",
      "\n",
      "Predicting for Federalist Paper 56\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.17\n",
      "james_madison: 0.12\n",
      "alexander_hamilton: 0.70\n",
      "\n",
      "Predicting for Federalist Paper 51\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.13\n",
      "james_madison: 0.20\n",
      "alexander_hamilton: 0.67\n",
      "\n",
      "Predicting for Federalist Paper 50\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.28\n",
      "james_madison: 0.11\n",
      "alexander_hamilton: 0.61\n",
      "\n",
      "Predicting for Federalist Paper 53\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.18\n",
      "james_madison: 0.12\n",
      "alexander_hamilton: 0.70\n",
      "\n",
      "Predicting for Federalist Paper 52\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.17\n",
      "james_madison: 0.16\n",
      "alexander_hamilton: 0.67\n",
      "\n",
      "Predicting for Federalist Paper 19\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.38\n",
      "james_madison: 0.13\n",
      "alexander_hamilton: 0.49\n",
      "\n",
      "Predicting for Federalist Paper 62\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.24\n",
      "james_madison: 0.12\n",
      "alexander_hamilton: 0.63\n",
      "\n",
      "Predicting for Federalist Paper 63\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.26\n",
      "james_madison: 0.17\n",
      "alexander_hamilton: 0.56\n",
      "\n",
      "Predicting for Federalist Paper 18\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.46\n",
      "james_madison: 0.07\n",
      "alexander_hamilton: 0.47\n",
      "\n",
      "\n",
      "[epoch 9] Starting epoch 9\n",
      "[batch 5594]: seen 3329160 words at 33291 wps, loss = 1.226\n",
      "[epoch 9] Completed in 0:01:50\n",
      "[epoch 9] Federalist Paper 18: avg. loss: 1.851  (perplexity: 6.37)\n",
      "Predicting for Federalist Paper 20\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.38\n",
      "james_madison: 0.07\n",
      "alexander_hamilton: 0.55\n",
      "\n",
      "Predicting for Federalist Paper 58\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.17\n",
      "james_madison: 0.12\n",
      "alexander_hamilton: 0.71\n",
      "\n",
      "Predicting for Federalist Paper 49\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.15\n",
      "james_madison: 0.06\n",
      "alexander_hamilton: 0.79\n",
      "\n",
      "Predicting for Federalist Paper 55\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.23\n",
      "james_madison: 0.06\n",
      "alexander_hamilton: 0.71\n",
      "\n",
      "Predicting for Federalist Paper 54\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.14\n",
      "james_madison: 0.11\n",
      "alexander_hamilton: 0.75\n",
      "\n",
      "Predicting for Federalist Paper 57\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.23\n",
      "james_madison: 0.08\n",
      "alexander_hamilton: 0.68\n",
      "\n",
      "Predicting for Federalist Paper 56\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.15\n",
      "james_madison: 0.10\n",
      "alexander_hamilton: 0.75\n",
      "\n",
      "Predicting for Federalist Paper 51\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.14\n",
      "james_madison: 0.12\n",
      "alexander_hamilton: 0.74\n",
      "\n",
      "Predicting for Federalist Paper 50\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.28\n",
      "james_madison: 0.07\n",
      "alexander_hamilton: 0.65\n",
      "\n",
      "Predicting for Federalist Paper 53\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.17\n",
      "james_madison: 0.07\n",
      "alexander_hamilton: 0.76\n",
      "\n",
      "Predicting for Federalist Paper 52\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.18\n",
      "james_madison: 0.11\n",
      "alexander_hamilton: 0.71\n",
      "\n",
      "Predicting for Federalist Paper 19\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.42\n",
      "james_madison: 0.08\n",
      "alexander_hamilton: 0.50\n",
      "\n",
      "Predicting for Federalist Paper 62\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.23\n",
      "james_madison: 0.07\n",
      "alexander_hamilton: 0.70\n",
      "\n",
      "Predicting for Federalist Paper 63\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.24\n",
      "james_madison: 0.12\n",
      "alexander_hamilton: 0.64\n",
      "\n",
      "Predicting for Federalist Paper 18\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.45\n",
      "james_madison: 0.04\n",
      "alexander_hamilton: 0.51\n",
      "\n",
      "\n",
      "[epoch 10] Starting epoch 10\n",
      "[batch 5589]: seen 3323480 words at 33233 wps, loss = 1.219\n",
      "[epoch 10] Completed in 0:01:50\n",
      "[epoch 10] Federalist Paper 18: avg. loss: 1.557  (perplexity: 4.75)\n",
      "Predicting for Federalist Paper 20\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.42\n",
      "james_madison: 0.16\n",
      "alexander_hamilton: 0.41\n",
      "\n",
      "Predicting for Federalist Paper 58\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.18\n",
      "james_madison: 0.25\n",
      "alexander_hamilton: 0.57\n",
      "\n",
      "Predicting for Federalist Paper 49\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.11\n",
      "james_madison: 0.21\n",
      "alexander_hamilton: 0.68\n",
      "\n",
      "Predicting for Federalist Paper 55\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.23\n",
      "james_madison: 0.16\n",
      "alexander_hamilton: 0.61\n",
      "\n",
      "Predicting for Federalist Paper 54\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.17\n",
      "james_madison: 0.27\n",
      "alexander_hamilton: 0.57\n",
      "\n",
      "Predicting for Federalist Paper 57\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.23\n",
      "james_madison: 0.26\n",
      "alexander_hamilton: 0.52\n",
      "\n",
      "Predicting for Federalist Paper 56\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.19\n",
      "james_madison: 0.23\n",
      "alexander_hamilton: 0.59\n",
      "\n",
      "Predicting for Federalist Paper 51\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.17\n",
      "james_madison: 0.26\n",
      "alexander_hamilton: 0.57\n",
      "\n",
      "Predicting for Federalist Paper 50\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.26\n",
      "james_madison: 0.23\n",
      "alexander_hamilton: 0.51\n",
      "\n",
      "Predicting for Federalist Paper 53\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.19\n",
      "james_madison: 0.19\n",
      "alexander_hamilton: 0.62\n",
      "\n",
      "Predicting for Federalist Paper 52\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.18\n",
      "james_madison: 0.24\n",
      "alexander_hamilton: 0.57\n",
      "\n",
      "Predicting for Federalist Paper 19\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.38\n",
      "james_madison: 0.22\n",
      "alexander_hamilton: 0.40\n",
      "\n",
      "Predicting for Federalist Paper 62\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.28\n",
      "james_madison: 0.23\n",
      "alexander_hamilton: 0.50\n",
      "\n",
      "Predicting for Federalist Paper 63\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.28\n",
      "james_madison: 0.24\n",
      "alexander_hamilton: 0.47\n",
      "\n",
      "Predicting for Federalist Paper 18\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "thomas_jefferson: 0.44\n",
      "james_madison: 0.12\n",
      "alexander_hamilton: 0.43\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reload(rnnlm)\n",
    "# Will print status every this many seconds\n",
    "print_interval = 5\n",
    "\n",
    "# Clear old log directory\n",
    "shutil.rmtree(\"tf_summaries\", ignore_errors=True)\n",
    "\n",
    "lm = rnnlm.RNNLM(**model_params)\n",
    "lm.BuildCoreGraph()\n",
    "lm.BuildTrainGraph()\n",
    "lm.BuildClassifierGraph()\n",
    "\n",
    "# Explicitly add global initializer and variable saver to LM graph\n",
    "with lm.graph.as_default():\n",
    "    initializer = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "# Clear old log directory\n",
    "shutil.rmtree(TF_SAVEDIR, ignore_errors=True)\n",
    "if not os.path.isdir(TF_SAVEDIR):\n",
    "    os.makedirs(TF_SAVEDIR)\n",
    "\n",
    "with tf.Session(graph=lm.graph) as session:\n",
    "    # Seed RNG for repeatability\n",
    "    tf.set_random_seed(42)\n",
    "\n",
    "    session.run(initializer)\n",
    "\n",
    "    for epoch in xrange(1,num_epochs+1):\n",
    "        t0_epoch = time.time()\n",
    "        bi = batch_generator(X_train, y_train, batch_size, max_time)\n",
    "        print \"[epoch %d] Starting epoch %d\" % (epoch, epoch)\n",
    "        # Run a training epoch.\n",
    "\n",
    "        run_epoch(lm, session, bi, train=True, verbose=True, tick_s=100, learning_rate=learning_rate)\n",
    "    \n",
    "        print \"[epoch %d] Completed in %s\" % (epoch, pretty_timedelta(since=t0_epoch))\n",
    "    \n",
    "        # Save a checkpoint\n",
    "        saver.save(session, checkpoint_filename, global_step=epoch)\n",
    "    \n",
    "        ##\n",
    "        # score_dataset will run a forward pass over the entire dataset\n",
    "        # and report perplexity scores. This can be slow (around 1/2 to \n",
    "        # 1/4 as long as a full epoch), so you may want to comment it out\n",
    "        # to speed up training on a slow machine. Be sure to run it at the \n",
    "        # end to evaluate your score.\n",
    "        print (\"[epoch %d]\" % epoch),\n",
    "        score_dataset(lm, session, eval_X['18'], eval_y['18'], max_time, name=\"Federalist Paper 18\")\n",
    "        #score_dataset(lm, session, test_ids, name=\"Test set\")\n",
    "\n",
    "        for key in eval_X:\n",
    "            prediction_bi = batch_generator(eval_X[key], eval_y[key], batch_size, max_time)\n",
    "            predict_paper(lm, session, prediction_bi, author_to_id, \"Federalist Paper %s\" % key)        \n",
    "        print \"\"\n",
    "\n",
    "    # Save final model\n",
    "    saver.save(session, trained_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "7\n",
      "{'thomas_jefferson': 1, 'john_adams': 2, 'alexander_hamilton': 4, 'benjamin_franklin': 8, 'george_washington': 7, 'thomas_paine': 0, 'james_madison': 3, 'james_monroe': 5, 'john_jay': 6}\n"
     ]
    }
   ],
   "source": [
    "print author_to_id['james_madison']\n",
    "print author_to_id['george_washington']\n",
    "print author_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

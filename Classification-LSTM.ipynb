{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 2,
>>>>>>> 651ae6c0d146adbeeaade7f56459ce625202a1c1
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json, os, re, shutil, sys, time\n",
    "import collections, itertools\n",
    "import unittest\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# NLTK for NLP utils and corpora\n",
    "import nltk\n",
    "\n",
    "# NumPy and TensorFlow\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "assert(tf.__version__.startswith(\"1.\"))\n",
    "\n",
    "# utils.pretty_print_matrix uses Pandas. Configure float format here.\n",
    "import pandas as pd\n",
    "pd.set_option('float_format', lambda f: \"{0:.04f}\".format(f))\n",
    "\n",
    "# RNNLM Model\n",
    "import rnnlm\n",
    "reload(rnnlm)\n",
    "\n",
    "# Other imports\n",
    "from datetime import datetime\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vocabulary class holds the vocabulary and the mapping between words and ids for the words."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 3,
>>>>>>> 651ae6c0d146adbeeaade7f56459ce625202a1c1
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "'''Vocabulary class, nearly identical to that used in a4'''\n",
    "class Vocabulary(object):\n",
    "\n",
    "  UNK_TOKEN = \"<unk>\"\n",
    "\n",
    "  def __init__(self, tokens, size=None):\n",
    "    self.unigram_counts = collections.Counter(tokens)\n",
    "    # leave space for \"<unk>\"\n",
    "    top_counts = self.unigram_counts.most_common(None if size is None else (size - 1))\n",
    "    vocab = ([self.UNK_TOKEN] +\n",
    "             [w for w,c in top_counts])\n",
    "\n",
    "    # Assign an id to each word, by frequency\n",
    "    self.id_to_word = dict(enumerate(vocab))\n",
    "    self.word_to_id = {v:k for k,v in self.id_to_word.iteritems()}\n",
    "    self.size = len(self.id_to_word)\n",
    "    if size is not None:\n",
    "        assert(self.size <= size)\n",
    "\n",
    "    # For convenience\n",
    "    self.wordset = set(self.word_to_id.iterkeys())\n",
    "\n",
    "    # Store special IDs\n",
    "    self.UNK_ID = self.word_to_id[self.UNK_TOKEN]\n",
    "\n",
    "  def words_to_ids(self, words):\n",
    "    return [self.word_to_id.get(w, self.UNK_ID) for w in words]\n",
    "\n",
    "  def ids_to_words(self, ids):\n",
    "    return [self.id_to_word[i] for i in ids]\n",
    "\n",
    "  def ordered_words(self):\n",
    "    \"\"\"Return a list of words, ordered by id.\"\"\"\n",
    "    return self.ids_to_words(range(self.size))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These functions are used to massage the cleaned data into indivdual words. Punctuation at the end of a word is split into its own distince word. Also accomplishes some minor data cleaning, removing nonsense characters."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 4,
>>>>>>> 651ae6c0d146adbeeaade7f56459ce625202a1c1
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "import re\n",
    "\n",
    "def canonicalize_digits(word):\n",
    "    if any([c.isalpha() for c in word]): return word\n",
    "    word = re.sub(\"\\d\", \"DG\", word)\n",
    "    if word.startswith(\"DG\"):\n",
    "        word = word.replace(\",\", \"\") # remove thousands separator\n",
    "    return word\n",
    "\n",
    "def canonicalize_word(word):\n",
    "    word = word.lower()\n",
    "    return canonicalize_digits(word) # try to canonicalize numbers\n",
    "\n",
    "def replace_all(text, dic):\n",
    "    for i, j in dic.iteritems():\n",
    "        text = text.replace(i, j)\n",
    "    return text\n",
    "\n",
    "def canonicalize_words(words):\n",
    "    current = []\n",
    "    rep_dict = {'\\n':' '\n",
    "                ,'\\xc2':' '\n",
    "                ,'\\xa0':' '\n",
    "                ,'\\xc2':' '\n",
    "                ,'\\xc3':' '\n",
    "                ,'\\xa9':' '\n",
    "                ,'\\xef':' '\n",
    "                ,'\\xbb':' '\n",
    "                ,'\\xbf':' '\n",
    "                ,'\\xa6':' '\n",
    "                ,'\\xb9':' '\n",
    "                ,'\\xa3':' '\n",
    "                ,'\\xbd':' '\n",
    "                ,'\\xb4':' '\n",
    "                ,'\\xcb':' '\n",
    "                ,'\\x9a':' '\n",
    "                ,'\\x86':' '\n",
    "                ,'\\xcf':' '\n",
    "                ,'\\x84':' '\n",
    "                ,'\\xce':' '\n",
    "                ,'\\x87':' '\n",
    "                ,'\\xe2':' '\n",
    "                ,'\\x80':' '\n",
    "                ,'\\x94':' '\n",
    "               }\n",
    "    for word in replace_all(words, rep_dict).split(' '):   \n",
    "        if word:\n",
    "            if word[-1] in ('.', ',', '?', ';', '!'):\n",
    "                punk = word[-1]\n",
    "                current.append(punk)\n",
    "                word = word[0:-1]\n",
    "\n",
    "            word = canonicalize_word(word)\n",
    "            current.append(word)\n",
    "    return current"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 5,
>>>>>>> 651ae6c0d146adbeeaade7f56459ce625202a1c1
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pretty_timedelta(fmt=\"%d:%02d:%02d\", since=None, until=None):\n",
    "    \"\"\"Pretty-print a timedelta, using the given format string.\"\"\"\n",
    "    since = since or time.time()\n",
    "    until = until or time.time()\n",
    "    delta_s = until - since\n",
    "    hours, remainder = divmod(delta_s, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    return fmt % (hours, minutes, seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load_train_data reads in everything in train_data directory from which it generates the vocab (of type Vocabulary defined above), the author_to_id map (which maps author names to ids) and two arrays, one contains the text of each file (as a list of word ids) under \"train_data\". The other holds the author id for each of the texts."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 6,
>>>>>>> 651ae6c0d146adbeeaade7f56459ce625202a1c1
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_train_data(train_data_dir):\n",
    "    y = []\n",
    "    X = []\n",
    "    all_tokens = []\n",
    "    author_to_id = {}\n",
    "    for author_id, author in enumerate(listdir(train_data_dir)):\n",
    "        author_to_id[author] = author_id\n",
    "        author_path = \"%s/%s\" % (train_data_dir, author)\n",
    "        print author, author_id\n",
    "\n",
    "        for file_name in listdir(author_path):\n",
    "            full_path = \"%s/%s\" % (author_path, file_name)\n",
    "            y.append(author_id)            \n",
    "            with open(full_path, \"r\") as f:\n",
    "                current = canonicalize_words(f.read())\n",
    "                all_tokens += current\n",
    "                X.append(np.array(current))\n",
    "                \n",
    "    vocab = Vocabulary(all_tokens)\n",
    "\n",
    "    # replace words with ids\n",
    "    for i, x in enumerate(X):\n",
    "        # X[i] = np.array(x) # This line can be used to make sure your words are useful \n",
    "        X[i] = np.array(vocab.words_to_ids(x))\n",
    "\n",
    "    return vocab, np.array(X), np.array(y), author_to_id\n",
    "\n",
    "\n",
    "def id_to_author(author_to_id, id):\n",
    "    '''\n",
    "    Takes a dictionary mapping author names to IDs and an ID, and returns\n",
    "    the author mapped to that ID\n",
    "    '''\n",
    "    for author, author_id in author_to_id.iteritems():\n",
    "        if id == author_id:\n",
    "            return author"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we load the training data, note resulting number of classes (authors) and display some useful information."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 7,
>>>>>>> 651ae6c0d146adbeeaade7f56459ce625202a1c1
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data_dir = './train_data_small'\n",
    "vocab, X_train, y_train, author_to_id = load_train_data(train_data_dir)\n",
    "num_classes = len(np.unique(y_train))\n",
    "print \"vocab.size\", vocab.size\n",
    "print author_to_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the eval data in the same format as the training data. But each federalist paper here ends up in its own dictionary entry so that they can be scored/classified/attributed separately. Each is assumed to be written by James Madison."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 8,
>>>>>>> 651ae6c0d146adbeeaade7f56459ce625202a1c1
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_eval_data(vocab, eval_data_dir):\n",
    "    eval_X = {}\n",
    "    eval_y = {}\n",
    "    \n",
    "    for author_id, author in enumerate(listdir(eval_data_dir)):\n",
    "        author_path = \"%s/%s\" % (eval_data_dir, author)\n",
    "\n",
    "        for file_name in listdir(author_path):\n",
    "            full_path = \"%s/%s\" % (author_path, file_name)\n",
    "            \n",
    "            with open(full_path, \"r\") as f:\n",
    "                current = vocab.words_to_ids(canonicalize_words(f.read()))\n",
    "                \n",
    "            expanded_X = np.array(current)\n",
    "            id = file_name.split(\"_\")[2].split(\".\")[0]\n",
    "            eval_X[id] = np.array([expanded_X])\n",
    "            eval_y[id] = np.array([author_to_id[author]])\n",
    "                \n",
    "    return eval_X, eval_y\n",
    "\n",
    "eval_X, eval_y = load_eval_data(vocab, \"unknown_data\")\n",
    "print eval_y['18']\n",
    "print eval_X['18']\n",
    "\n",
    "test_X, test_y = load_eval_data(vocab, \"test_data\")\n",
    "print \"Who wrote Federalist paper 5 (John Jay should be answer): %s\" % id_to_author(author_to_id, test_y['5'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cut up the publications based on batch_size, and max_time. To reduce how much code had to be changed from a4 this expands the author id for each document to be an author id for each word in the document. So if you had publication[1] = [1 2 3] and authors[1] = 1, this would output (assuming a batch of 1 and max time of 3) w = [1 2 3] and y = [1 1 1]. In the end we'll ignore all the loss for everything except the last word, but all the matrix functions and multiplications could work as is if I kept expanded the author to be associated with each word (since that is what the sequence math was doing, each word had a corresponding target word). Note: this also randomly shuffles the batches so that an given author's data is mixed through out the training process."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
=======
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['hello', 'I', 'am'], ['mr', '.', 'anderson'], ['what', 'is', 'your']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
>>>>>>> 651ae6c0d146adbeeaade7f56459ce625202a1c1
   "source": [
    "def slice_up_words(words, window_size=10, step_size=1):\n",
    "    clip_len = ((len(words)-1) / window_size) * window_size\n",
    "    words = words[:clip_len]\n",
    "    slices = []\n",
    "    num_words = len(words)\n",
    "    for index in range(0, num_words, step_size):\n",
    "        slices.append(words[index:index+window_size])\n",
    "    return slices\n",
    "        \n",
    "slice_up_words([\"hello\", \"I\", \"am\", \"mr\", \".\", \"anderson\", \"what\", \"is\", \"your\", \"name\", \"?\"], 3, 3)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 10,
>>>>>>> 651ae6c0d146adbeeaade7f56459ce625202a1c1
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "# maybe worth seeding here. or in the batch_generator function\n",
    "\n",
    "def shape_data_for_batching(publications, authors, max_time):\n",
    "    \"\"\"Convert ids to data-matrix form.\"\"\"\n",
    "    all_w = None\n",
    "    all_y = []\n",
    "    for i, ids in enumerate(publications):\n",
    "        ids = np.array(slice_up_words(ids, max_time, max_time))\n",
    "        y = np.full_like(ids, authors[i])\n",
    "        \n",
    "        if all_w is not None:\n",
    "            all_w = np.append(all_w, ids, 0)\n",
    "            all_y = np.append(all_y, y, 0)\n",
    "            \n",
    "        else:\n",
    "            all_w = ids\n",
    "            all_y = y\n",
    "\n",
    "    # Yield batches in random order     \n",
    "    index = range(0, len(all_y)-1)\n",
    "    random.shuffle(index)   \n",
    "\n",
    "    all_w = [all_w[i] for i in index]\n",
    "    all_y = [all_y[i] for i in index]\n",
    "\n",
    "    return all_w, all_y\n",
    "\n",
    "def batch_generator(X_shaped, y_shaped, batch_size):\n",
    "    clip_len = ((len(X_shaped)-1) / batch_size) * batch_size\n",
    "    X_shaped = X_shaped[:clip_len]\n",
    "    y_shaped = y_shaped[:clip_len]  \n",
    "    for j in xrange(0, len(X_shaped), batch_size):\n",
    "        this_x = X_shaped[j:j+batch_size]\n",
    "        this_y = y_shaped[j:j+batch_size]\n",
    "        yield np.array(this_x), np.array(this_y)\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 11,
>>>>>>> 651ae6c0d146adbeeaade7f56459ce625202a1c1
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sanity Check\n",
    "X_shaped, y_shaped = shape_data_for_batching(X_train, y_train, 5)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
=======
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 2 2 2 2]\n",
      " [0 0 0 0 0]\n",
      " [2 2 2 2 2]\n",
      " [1 1 1 1 1]\n",
      " [2 2 2 2 2]\n",
      " [1 1 1 1 1]\n",
      " [1 1 1 1 1]\n",
      " [2 2 2 2 2]\n",
      " [2 2 2 2 2]\n",
      " [0 0 0 0 0]]\n",
      "[[ 515  104   50  481  318]\n",
      " [ 295    3   11  176    3]\n",
      " [  18    2  880    5    1]\n",
      " [ 182   32 2624    1 1349]\n",
      " [  10  105    3   18  666]\n",
      " [ 257 1023    4  779    6]\n",
      " [  11    1   96    2   20]\n",
      " [  41   27  817    2   89]\n",
      " [  10   32   53    1   40]\n",
      " [   6 2735    2  465    1]]\n"
     ]
    }
   ],
>>>>>>> 651ae6c0d146adbeeaade7f56459ce625202a1c1
   "source": [
    "for i, (w, y) in enumerate(batch_generator(X_shaped, y_shaped, 10)):\n",
    "    print y\n",
    "    print w \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Runs the epoch. Mostly the same as a4, but there is no test phase (instead there is no a separate prediction phase) that didn't makes as much sense to me to have in this function, so it has its own function"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 13,
>>>>>>> 651ae6c0d146adbeeaade7f56459ce625202a1c1
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_epoch(lm, session, batch_iterator,\n",
    "              train=False, verbose=False,\n",
    "              tick_s=10, learning_rate=0.1):\n",
    "    start_time = time.time()\n",
    "    tick_time = start_time  # for showing status\n",
    "    total_cost = 0.0  # total cost, summed over all words\n",
    "    total_batches = 0\n",
    "    total_words = 0\n",
    "\n",
    "    if train:\n",
    "        train_op = lm.train_step_\n",
    "        use_dropout = True\n",
    "    else:\n",
    "        train_op = tf.no_op()\n",
    "        use_dropout = False  # no dropout at test time\n",
    "\n",
    "    for i, (w, y) in enumerate(batch_iterator):\n",
    "        cost = 0.0\n",
    "        # At first batch in epoch, get a clean intitial state.\n",
    "        if i == 0:\n",
    "            h = session.run(lm.initial_h_, {lm.input_w_: w})\n",
    "            \n",
    "        feed_dict = {lm.input_w_: w,\n",
    "                     lm.target_y_: y,\n",
    "                     lm.initial_h_: h,\n",
    "                     lm.learning_rate_: learning_rate,\n",
    "                     lm.use_dropout_: use_dropout}\n",
    "        \n",
    "        _, h, cost = session.run([train_op, lm.final_h_, lm.loss_], feed_dict)  \n",
    "\n",
    "        total_cost += cost\n",
    "        total_batches = i + 1\n",
    "        total_words += w.size  # w.size = batch_size * max_time\n",
    "\n",
    "        ##\n",
    "        # Print average loss-so-far for epoch\n",
    "        # If using train_loss_, this may be an underestimate.\n",
    "        if verbose and (time.time() - tick_time >= tick_s):\n",
    "            avg_cost = total_cost / total_batches\n",
    "            avg_wps = total_words / (time.time() - start_time)\n",
    "            print \"[batch %d]: seen %d words at %d wps, loss = %.3f\" % (\n",
    "                i, total_words, avg_wps, avg_cost)\n",
    "            tick_time = time.time()  # reset time ticker\n",
    "\n",
    "    return total_cost / total_batches"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 14,
>>>>>>> 651ae6c0d146adbeeaade7f56459ce625202a1c1
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score_dataset(lm, session, ids, authors, max_time, name=\"Data\"):\n",
    "    # For scoring, we can use larger batches to speed things up. Same as a4\n",
    "    bi = batch_generator(ids, authors, batch_size=100, max_time=max_time)\n",
    "    cost = run_epoch(lm, session, bi, \n",
    "                     learning_rate=1.0, train=False, \n",
    "                     verbose=False, tick_s=3600)\n",
    "    print \"%s: avg. loss: %.03f  (perplexity: %.02f)\" % (name, cost, np.exp(cost))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions used to predict a batch iterators data. Used post training to test the unknown federalist papers."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
=======
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Summary:\n",
      "alexander_hamilton: 0.50\n",
      "john_jay: 0.50\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: 0.5, 2: 0.5}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
>>>>>>> 651ae6c0d146adbeeaade7f56459ce625202a1c1
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def get_prediction_results(predictions, author_to_id, print_results=True):\n",
    "    '''\n",
    "    Takes the predictions for a set of text batches and calculates the percentage\n",
    "    of patches predicted for each author.\n",
    "    '''\n",
    "    counts = defaultdict(float)\n",
    "    for p in predictions:\n",
    "        counts[p] += 1\n",
    "\n",
    "    # getting prediction percentages to return for later viewing\n",
    "    predictions_num = len(predictions)\n",
    "    results_dict = {author_id:float(count)/predictions_num for author_id, count in counts.iteritems()}\n",
    "    \n",
    "    if print_results:\n",
    "        # prints results if indicated\n",
    "        print \"Prediction Summary:\"\n",
    "        for author_id, prediction in results_dict.iteritems():\n",
    "            print \"%s: %.2f\" % (id_to_author(author_to_id, author_id), prediction)\n",
    "        print \"\"\n",
    "\n",
    "    return results_dict\n",
    "    \n",
    "def predict_paper(lm, session, batch_iterator, authors, paper_name, print_results=True):\n",
    "    '''\n",
    "    Splits given paper into batches and predicts the author for each batch.\n",
    "    Passes these predictions to get_prediction_results() to tally the batches for each author\n",
    "    and arrive at a final prediction percentage.\n",
    "    '''\n",
    "    total_predictions = np.array([])\n",
    "    if print_results:\n",
    "        print \"Predicting for %s\" % paper_name\n",
    "    for i, (w, y) in enumerate(batch_iterator):        \n",
    "        if i == 0 and print_results:\n",
    "            print \"Truth:\", id_to_author(authors, y[0][0])\n",
    "            \n",
    "        feed_dict = {lm.input_w_: w,\n",
    "                     lm.target_y_: y}\n",
    "        \n",
    "        cost, truths, logits, predictions = session.run([lm.loss_, lm.target_y_last_, lm.logits_last_, lm.predictions_], feed_dict)  \n",
    "        total_predictions = np.append(total_predictions, predictions.reshape(-1))\n",
    "\n",
    "    # gets final predictions, by author, for the given paper\n",
    "    results_dict = get_prediction_results(total_predictions, authors, print_results=print_results)\n",
    "    return results_dict\n",
    "\n",
    "def test_papers(lm, session, papers, labels, authors, batch_size, print_results=True):\n",
    "    '''\n",
    "    Predicts authorship for given papers.\n",
    "    Returns a dictionary of dictionaries containing the predictions by author for each paper.\n",
    "    '''\n",
    "    full_results = dict()\n",
    "    for key in papers:\n",
    "        prediction_bi = batch_generator(papers[key], labels[key], batch_size)\n",
    "        paper_results = predict_paper(lm, session, prediction_bi, authors, \"Federalist Paper %s\" % key, print_results=print_results)\n",
    "        full_results[key] = paper_results\n",
    "    \n",
    "    return full_results\n",
    "\n",
    "def create_predictions_dataframe(epoch_predictions):\n",
    "    '''\n",
    "    Input: List of predictions for each epoch, where an epochs predictions is a dictionary of dictionaries containing\n",
    "    the predictions for each paper by author.\n",
    "    Output: Pandas dataframe of results for each author by paper, with a flag indicating the epoch.\n",
    "    '''\n",
    "    df_list = []\n",
    "    for epoch in range(len(epoch_predictions)):\n",
    "        epoch_num = epoch + 1 # we indexed our epochs from 1, but this list is 0-indexed of course\n",
    "        df = pd.DataFrame(epoch_predictions[epoch])\n",
    "        df['epoch'] = epoch_num\n",
    "        df_list.append(df)\n",
    "\n",
    "    return pd.concat(df_list)\n",
    "\n",
    "def save_results(save_dir):\n",
    "    '''\n",
    "    Saves results dataframe to csv, pickles the author_to_id dictionary, and creates\n",
    "    a text file with relevant settings that this model was trained with. Also saves the final\n",
    "    trained model.\n",
    "    This function is lazy and calls the objects from out of scope rather than passing, but\n",
    "    it will do for now.\n",
    "    '''\n",
    "    # Creating directory\n",
    "    shutil.rmtree(save_dir, ignore_errors=True)\n",
    "    if not os.path.isdir(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    df.to_csv(save_dir + '/results.csv')\n",
    "    pickle.dump(author_to_id, open(save_dir + '/author_to_id.p', 'wb'))\n",
    "    save_parms = {'max_time':max_time, 'batch_size':batch_size, 'learning_rate':learning_rate,\n",
    "                  'num_epochs':num_epochs, 'train_data_dir':train_data_dir}\n",
    "    with open(save_dir + '/parms.txt', 'w') as f:\n",
    "        for parm, val in save_parms.iteritems():\n",
    "            f.write(parm + ' : ' + str(val) + '\\n')\n",
    "            \n",
    "def get_accuracy(predictions, true_y):\n",
    "    '''Determine accuracy of a test set. This only works properly if the option is binary (ham vs madison)'''\n",
    "    total_documents = len(true_y)\n",
    "    correct_prediction_count = 0.0\n",
    "    for key in true_y:\n",
    "        true_author = true_y[key][0][0]\n",
    "        if predictions[key][true_author] > .50:\n",
    "            correct_prediction_count += 1\n",
    "    return correct_prediction_count / total_documents \n",
    "    \n",
    "    # Copying final trained model to save folder\n",
    "    for file_name in listdir(TF_SAVEDIR):\n",
    "        if file_name.startswith('rnnlm_trained') or file_name == 'checkpoint':\n",
    "            shutil.copyfile(os.path.join(TF_SAVEDIR, file_name), os.path.join(save_dir, file_name))\n",
    "    \n",
    "get_prediction_results([1, 2, 1, 2], author_to_id)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 16,
>>>>>>> 651ae6c0d146adbeeaade7f56459ce625202a1c1
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data_dir = './train_final'\n",
    "vocab, X_train, y_train, author_to_id = load_train_data(train_data_dir)\n",
    "num_classes = len(np.unique(y_train))\n",
    "\n",
    "eval_X, eval_y = load_eval_data(vocab, \"unknown_data\")\n",
    "test_X, test_y = load_eval_data(vocab, \"test_final\")\n",
    "\n",
    "# Training parameters\n",
    "max_time = 15\n",
    "batch_size = 50\n",
    "learning_rate = 0.08\n",
<<<<<<< HEAD
    "num_epochs = 200\n",
=======
    "num_epochs = 500\n",
>>>>>>> 651ae6c0d146adbeeaade7f56459ce625202a1c1
    "\n",
    "save_predictions = True # flag to determine if we save the predictions on unkown papers in each epoch\n",
    "\n",
    "# Model parameters\n",
    "model_params = dict(V=vocab.size, \n",
    "                    H=100, \n",
    "                    num_classes=num_classes,\n",
    "                    num_layers=1)\n",
    "\n",
    "TF_SAVEDIR = \"tf_saved\"\n",
    "checkpoint_filename = os.path.join(TF_SAVEDIR, \"rnnlm\")\n",
    "trained_filename = os.path.join(TF_SAVEDIR, \"rnnlm_trained\")\n",
    "\n",
    "\n",
    "X_train_shaped, y_train_shaped = shape_data_for_batching(X_train, y_train, max_time)\n",
    "\n",
    "X_test_shaped = {}\n",
    "y_test_shaped = {}\n",
    "for key in test_X:\n",
    "    X_test_shaped[key], y_test_shaped[key] = shape_data_for_batching(test_X[key], test_y[key], max_time)\n",
    "\n",
    "X_eval_shaped = {}\n",
    "y_eval_shaped = {}\n",
    "for key in eval_X:\n",
    "    X_eval_shaped[key], y_eval_shaped[key] = shape_data_for_batching(eval_X[key], eval_y[key], max_time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nearly the same as a4, but instead of scoring the data we look at prediction results after each epoch."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 17,
>>>>>>> 651ae6c0d146adbeeaade7f56459ce625202a1c1
   "metadata": {
    "collapsed": false
   },
<<<<<<< HEAD
   "outputs": [],
=======
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] Starting epoch 1\n",
      "[epoch 1] Completed in 0:00:01\n",
      "[epoch 1] [epoch 2] Starting epoch 2\n",
      "[epoch 2] Completed in 0:00:00\n",
      "[epoch 2] [epoch 3] Starting epoch 3\n",
      "[epoch 3] Completed in 0:00:00\n",
      "[epoch 3] [epoch 4] Starting epoch 4\n",
      "[epoch 4] Completed in 0:00:00\n",
      "[epoch 4] [epoch 5] Starting epoch 5\n",
      "[epoch 5] Completed in 0:00:00\n",
      "[epoch 5] [epoch 6] Starting epoch 6\n",
      "[epoch 6] Completed in 0:00:00\n",
      "[epoch 6] [epoch 7] Starting epoch 7\n",
      "[epoch 7] Completed in 0:00:00\n",
      "[epoch 7] [epoch 8] Starting epoch 8\n",
      "[epoch 8] Completed in 0:00:00\n",
      "[epoch 8] [epoch 9] Starting epoch 9\n",
      "[epoch 9] Completed in 0:00:00\n",
      "[epoch 9] [epoch 10] Starting epoch 10\n",
      "[epoch 10] Completed in 0:00:00\n",
      "[epoch 10] [epoch 11] Starting epoch 11\n",
      "[epoch 11] Completed in 0:00:00\n",
      "[epoch 11] [epoch 12] Starting epoch 12\n",
      "[epoch 12] Completed in 0:00:00\n",
      "[epoch 12] [epoch 13] Starting epoch 13\n",
      "[epoch 13] Completed in 0:00:00\n",
      "[epoch 13] [epoch 14] Starting epoch 14\n",
      "[epoch 14] Completed in 0:00:00\n",
      "[epoch 14] [epoch 15] Starting epoch 15\n",
      "[epoch 15] Completed in 0:00:00\n",
      "[epoch 15] [epoch 16] Starting epoch 16\n",
      "[epoch 16] Completed in 0:00:00\n",
      "[epoch 16] [epoch 17] Starting epoch 17\n",
      "[epoch 17] Completed in 0:00:00\n",
      "[epoch 17] [epoch 18] Starting epoch 18\n",
      "[epoch 18] Completed in 0:00:00\n",
      "[epoch 18] [epoch 19] Starting epoch 19\n",
      "[epoch 19] Completed in 0:00:00\n",
      "[epoch 19] [epoch 20] Starting epoch 20\n",
      "[epoch 20] Completed in 0:00:00\n",
      "[epoch 20] [epoch 21] Starting epoch 21\n",
      "[epoch 21] Completed in 0:00:00\n",
      "[epoch 21] [epoch 22] Starting epoch 22\n",
      "[epoch 22] Completed in 0:00:00\n",
      "[epoch 22] [epoch 23] Starting epoch 23\n",
      "[epoch 23] Completed in 0:00:00\n",
      "[epoch 23] [epoch 24] Starting epoch 24\n",
      "[epoch 24] Completed in 0:00:00\n",
      "[epoch 24] [epoch 25] Starting epoch 25\n",
      "[epoch 25] Completed in 0:00:00\n",
      "[epoch 25] [epoch 26] Starting epoch 26\n",
      "[epoch 26] Completed in 0:00:00\n",
      "[epoch 26] [epoch 27] Starting epoch 27\n",
      "[epoch 27] Completed in 0:00:00\n",
      "[epoch 27] [epoch 28] Starting epoch 28\n",
      "[epoch 28] Completed in 0:00:00\n",
      "[epoch 28] [epoch 29] Starting epoch 29\n",
      "[epoch 29] Completed in 0:00:00\n",
      "[epoch 29] [epoch 30] Starting epoch 30\n",
      "[epoch 30] Completed in 0:00:00\n",
      "[epoch 30] [epoch 31] Starting epoch 31\n",
      "[epoch 31] Completed in 0:00:00\n",
      "[epoch 31] [epoch 32] Starting epoch 32\n",
      "[epoch 32] Completed in 0:00:00\n",
      "[epoch 32] [epoch 33] Starting epoch 33\n",
      "[epoch 33] Completed in 0:00:00\n",
      "[epoch 33] [epoch 34] Starting epoch 34\n",
      "[epoch 34] Completed in 0:00:00\n",
      "[epoch 34] [epoch 35] Starting epoch 35\n",
      "[epoch 35] Completed in 0:00:00\n",
      "[epoch 35] [epoch 36] Starting epoch 36\n",
      "[epoch 36] Completed in 0:00:00\n",
      "[epoch 36] [epoch 37] Starting epoch 37\n",
      "[epoch 37] Completed in 0:00:00\n",
      "[epoch 37] [epoch 38] Starting epoch 38\n",
      "[epoch 38] Completed in 0:00:00\n",
      "[epoch 38] [epoch 39] Starting epoch 39\n",
      "[epoch 39] Completed in 0:00:00\n",
      "[epoch 39] [epoch 40] Starting epoch 40\n",
      "[epoch 40] Completed in 0:00:00\n",
      "[epoch 40] [epoch 41] Starting epoch 41\n",
      "[epoch 41] Completed in 0:00:00\n",
      "[epoch 41] [epoch 42] Starting epoch 42\n",
      "[epoch 42] Completed in 0:00:00\n",
      "[epoch 42] [epoch 43] Starting epoch 43\n",
      "[epoch 43] Completed in 0:00:00\n",
      "[epoch 43] [epoch 44] Starting epoch 44\n",
      "[epoch 44] Completed in 0:00:00\n",
      "[epoch 44] [epoch 45] Starting epoch 45\n",
      "[epoch 45] Completed in 0:00:00\n",
      "[epoch 45] [epoch 46] Starting epoch 46\n",
      "[epoch 46] Completed in 0:00:00\n",
      "[epoch 46] [epoch 47] Starting epoch 47\n",
      "[epoch 47] Completed in 0:00:00\n",
      "[epoch 47] [epoch 48] Starting epoch 48\n",
      "[epoch 48] Completed in 0:00:00\n",
      "[epoch 48] [epoch 49] Starting epoch 49\n",
      "[epoch 49] Completed in 0:00:00\n",
      "[epoch 49] [epoch 50] Starting epoch 50\n",
      "[epoch 50] Completed in 0:00:00\n",
      "[epoch 50] [epoch 51] Starting epoch 51\n",
      "[epoch 51] Completed in 0:00:00\n",
      "[epoch 51] [epoch 52] Starting epoch 52\n",
      "[epoch 52] Completed in 0:00:00\n",
      "[epoch 52] [epoch 53] Starting epoch 53\n",
      "[epoch 53] Completed in 0:00:00\n",
      "[epoch 53] [epoch 54] Starting epoch 54\n",
      "[epoch 54] Completed in 0:00:00\n",
      "[epoch 54] [epoch 55] Starting epoch 55\n",
      "[epoch 55] Completed in 0:00:00\n",
      "[epoch 55] [epoch 56] Starting epoch 56\n",
      "[epoch 56] Completed in 0:00:00\n",
      "[epoch 56] [epoch 57] Starting epoch 57\n",
      "[epoch 57] Completed in 0:00:00\n",
      "[epoch 57] [epoch 58] Starting epoch 58\n",
      "[epoch 58] Completed in 0:00:00\n",
      "[epoch 58] [epoch 59] Starting epoch 59\n",
      "[epoch 59] Completed in 0:00:00\n",
      "[epoch 59] [epoch 60] Starting epoch 60\n",
      "[epoch 60] Completed in 0:00:00\n",
      "[epoch 60] [epoch 61] Starting epoch 61\n",
      "[epoch 61] Completed in 0:00:00\n",
      "[epoch 61] [epoch 62] Starting epoch 62\n",
      "[epoch 62] Completed in 0:00:00\n",
      "[epoch 62] [epoch 63] Starting epoch 63\n",
      "[epoch 63] Completed in 0:00:00\n",
      "[epoch 63] [epoch 64] Starting epoch 64\n",
      "[epoch 64] Completed in 0:00:00\n",
      "[epoch 64] [epoch 65] Starting epoch 65\n",
      "[epoch 65] Completed in 0:00:00\n",
      "[epoch 65] [epoch 66] Starting epoch 66\n",
      "[epoch 66] Completed in 0:00:00\n",
      "[epoch 66] [epoch 67] Starting epoch 67\n",
      "[epoch 67] Completed in 0:00:00\n",
      "[epoch 67] [epoch 68] Starting epoch 68\n",
      "[epoch 68] Completed in 0:00:00\n",
      "[epoch 68] [epoch 69] Starting epoch 69\n",
      "[epoch 69] Completed in 0:00:00\n",
      "[epoch 69] [epoch 70] Starting epoch 70\n",
      "[epoch 70] Completed in 0:00:00\n",
      "[epoch 70] [epoch 71] Starting epoch 71\n",
      "[epoch 71] Completed in 0:00:00\n",
      "[epoch 71] [epoch 72] Starting epoch 72\n",
      "[epoch 72] Completed in 0:00:00\n",
      "[epoch 72] [epoch 73] Starting epoch 73\n",
      "[epoch 73] Completed in 0:00:00\n",
      "[epoch 73] [epoch 74] Starting epoch 74\n",
      "[epoch 74] Completed in 0:00:00\n",
      "[epoch 74] [epoch 75] Starting epoch 75\n",
      "[epoch 75] Completed in 0:00:00\n",
      "[epoch 75] [epoch 76] Starting epoch 76\n",
      "[epoch 76] Completed in 0:00:00\n",
      "[epoch 76] [epoch 77] Starting epoch 77\n",
      "[epoch 77] Completed in 0:00:00\n",
      "[epoch 77] [epoch 78] Starting epoch 78\n",
      "[epoch 78] Completed in 0:00:00\n",
      "[epoch 78] [epoch 79] Starting epoch 79\n",
      "[epoch 79] Completed in 0:00:00\n",
      "[epoch 79] [epoch 80] Starting epoch 80\n",
      "[epoch 80] Completed in 0:00:00\n",
      "[epoch 80] [epoch 81] Starting epoch 81\n",
      "[epoch 81] Completed in 0:00:00\n",
      "[epoch 81] [epoch 82] Starting epoch 82\n",
      "[epoch 82] Completed in 0:00:00\n",
      "[epoch 82] [epoch 83] Starting epoch 83\n",
      "[epoch 83] Completed in 0:00:00\n",
      "[epoch 83] [epoch 84] Starting epoch 84\n",
      "[epoch 84] Completed in 0:00:00\n",
      "[epoch 84] [epoch 85] Starting epoch 85\n",
      "[epoch 85] Completed in 0:00:00\n",
      "[epoch 85] [epoch 86] Starting epoch 86\n",
      "[epoch 86] Completed in 0:00:00\n",
      "[epoch 86] [epoch 87] Starting epoch 87\n",
      "[epoch 87] Completed in 0:00:00\n",
      "[epoch 87] [epoch 88] Starting epoch 88\n",
      "[epoch 88] Completed in 0:00:00\n",
      "[epoch 88] [epoch 89] Starting epoch 89\n",
      "[epoch 89] Completed in 0:00:00\n",
      "[epoch 89] [epoch 90] Starting epoch 90\n",
      "[epoch 90] Completed in 0:00:00\n",
      "[epoch 90] [epoch 91] Starting epoch 91\n",
      "[epoch 91] Completed in 0:00:00\n",
      "[epoch 91] [epoch 92] Starting epoch 92\n",
      "[epoch 92] Completed in 0:00:00\n",
      "[epoch 92] [epoch 93] Starting epoch 93\n",
      "[epoch 93] Completed in 0:00:00\n",
      "[epoch 93] [epoch 94] Starting epoch 94\n",
      "[epoch 94] Completed in 0:00:00\n",
      "[epoch 94] [epoch 95] Starting epoch 95\n",
      "[epoch 95] Completed in 0:00:00\n",
      "[epoch 95] [epoch 96] Starting epoch 96\n",
      "[epoch 96] Completed in 0:00:00\n",
      "[epoch 96] [epoch 97] Starting epoch 97\n",
      "[epoch 97] Completed in 0:00:00\n",
      "[epoch 97] [epoch 98] Starting epoch 98\n",
      "[epoch 98] Completed in 0:00:00\n",
      "[epoch 98] [epoch 99] Starting epoch 99\n",
      "[epoch 99] Completed in 0:00:00\n",
      "[epoch 99] [epoch 100] Starting epoch 100\n",
      "[epoch 100] Completed in 0:00:00\n",
      "[epoch 100] [epoch 101] Starting epoch 101\n",
      "[epoch 101] Completed in 0:00:00\n",
      "[epoch 101] [epoch 102] Starting epoch 102\n",
      "[epoch 102] Completed in 0:00:00\n",
      "[epoch 102] [epoch 103] Starting epoch 103\n",
      "[epoch 103] Completed in 0:00:00\n",
      "[epoch 103] [epoch 104] Starting epoch 104\n",
      "[epoch 104] Completed in 0:00:00\n",
      "[epoch 104] [epoch 105] Starting epoch 105\n",
      "[epoch 105] Completed in 0:00:00\n",
      "[epoch 105] [epoch 106] Starting epoch 106\n",
      "[epoch 106] Completed in 0:00:00\n",
      "[epoch 106] [epoch 107] Starting epoch 107\n",
      "[epoch 107] Completed in 0:00:00\n",
      "[epoch 107] [epoch 108] Starting epoch 108\n",
      "[epoch 108] Completed in 0:00:00\n",
      "[epoch 108] [epoch 109] Starting epoch 109\n",
      "[epoch 109] Completed in 0:00:00\n",
      "[epoch 109] [epoch 110] Starting epoch 110\n",
      "[epoch 110] Completed in 0:00:00\n",
      "[epoch 110] [epoch 111] Starting epoch 111\n",
      "[epoch 111] Completed in 0:00:00\n",
      "[epoch 111] [epoch 112] Starting epoch 112\n",
      "[epoch 112] Completed in 0:00:00\n",
      "[epoch 112] [epoch 113] Starting epoch 113\n",
      "[epoch 113] Completed in 0:00:00\n",
      "[epoch 113] [epoch 114] Starting epoch 114\n",
      "[epoch 114] Completed in 0:00:00\n",
      "[epoch 114] [epoch 115] Starting epoch 115\n",
      "[epoch 115] Completed in 0:00:00\n",
      "[epoch 115] [epoch 116] Starting epoch 116\n",
      "[epoch 116] Completed in 0:00:00\n",
      "[epoch 116] [epoch 117] Starting epoch 117\n",
      "[epoch 117] Completed in 0:00:00\n",
      "[epoch 117] [epoch 118] Starting epoch 118\n",
      "[epoch 118] Completed in 0:00:00\n",
      "[epoch 118] [epoch 119] Starting epoch 119\n",
      "[epoch 119] Completed in 0:00:00\n",
      "[epoch 119] [epoch 120] Starting epoch 120\n",
      "[epoch 120] Completed in 0:00:00\n",
      "[epoch 120] [epoch 121] Starting epoch 121\n",
      "[epoch 121] Completed in 0:00:00\n",
      "[epoch 121] [epoch 122] Starting epoch 122\n",
      "[epoch 122] Completed in 0:00:00\n",
      "[epoch 122] [epoch 123] Starting epoch 123\n",
      "[epoch 123] Completed in 0:00:00\n",
      "[epoch 123] [epoch 124] Starting epoch 124\n",
      "[epoch 124] Completed in 0:00:00\n",
      "[epoch 124] [epoch 125] Starting epoch 125\n",
      "[epoch 125] Completed in 0:00:00\n",
      "[epoch 125] [epoch 126] Starting epoch 126\n",
      "[epoch 126] Completed in 0:00:00\n",
      "[epoch 126] [epoch 127] Starting epoch 127\n",
      "[epoch 127] Completed in 0:00:00\n",
      "[epoch 127] [epoch 128] Starting epoch 128\n",
      "[epoch 128] Completed in 0:00:00\n",
      "[epoch 128] [epoch 129] Starting epoch 129\n",
      "[epoch 129] Completed in 0:00:00\n",
      "[epoch 129] [epoch 130] Starting epoch 130\n",
      "[epoch 130] Completed in 0:00:00\n",
      "[epoch 130] [epoch 131] Starting epoch 131\n",
      "[epoch 131] Completed in 0:00:00\n",
      "[epoch 131] [epoch 132] Starting epoch 132\n",
      "[epoch 132] Completed in 0:00:00\n",
      "[epoch 132] [epoch 133] Starting epoch 133\n",
      "[epoch 133] Completed in 0:00:00\n",
      "[epoch 133] [epoch 134] Starting epoch 134\n",
      "[epoch 134] Completed in 0:00:00\n",
      "[epoch 134] [epoch 135] Starting epoch 135\n",
      "[epoch 135] Completed in 0:00:00\n",
      "[epoch 135] [epoch 136] Starting epoch 136\n",
      "[epoch 136] Completed in 0:00:00\n",
      "[epoch 136] [epoch 137] Starting epoch 137\n",
      "[epoch 137] Completed in 0:00:00\n",
      "[epoch 137] [epoch 138] Starting epoch 138\n",
      "[epoch 138] Completed in 0:00:00\n",
      "[epoch 138] [epoch 139] Starting epoch 139\n",
      "[epoch 139] Completed in 0:00:00\n",
      "[epoch 139] [epoch 140] Starting epoch 140\n",
      "[epoch 140] Completed in 0:00:00\n",
      "[epoch 140] [epoch 141] Starting epoch 141\n",
      "[epoch 141] Completed in 0:00:00\n",
      "[epoch 141] [epoch 142] Starting epoch 142\n",
      "[epoch 142] Completed in 0:00:00\n",
      "[epoch 142] [epoch 143] Starting epoch 143\n",
      "[epoch 143] Completed in 0:00:00\n",
      "[epoch 143] [epoch 144] Starting epoch 144\n",
      "[epoch 144] Completed in 0:00:00\n",
      "[epoch 144] [epoch 145] Starting epoch 145\n",
      "[epoch 145] Completed in 0:00:00\n",
      "[epoch 145] [epoch 146] Starting epoch 146\n",
      "[epoch 146] Completed in 0:00:00\n",
      "[epoch 146] [epoch 147] Starting epoch 147\n",
      "[epoch 147] Completed in 0:00:00\n",
      "[epoch 147] [epoch 148] Starting epoch 148\n",
      "[epoch 148] Completed in 0:00:00\n",
      "[epoch 148] [epoch 149] Starting epoch 149\n",
      "[epoch 149] Completed in 0:00:00\n",
      "[epoch 149] [epoch 150] Starting epoch 150\n",
      "[epoch 150] Completed in 0:00:00\n",
      "[epoch 150] [epoch 151] Starting epoch 151\n",
      "[epoch 151] Completed in 0:00:00\n",
      "[epoch 151] [epoch 152] Starting epoch 152\n",
      "[epoch 152] Completed in 0:00:00\n",
      "[epoch 152] [epoch 153] Starting epoch 153\n",
      "[epoch 153] Completed in 0:00:00\n",
      "[epoch 153] [epoch 154] Starting epoch 154\n",
      "[epoch 154] Completed in 0:00:00\n",
      "[epoch 154] [epoch 155] Starting epoch 155\n",
      "[epoch 155] Completed in 0:00:00\n",
      "[epoch 155] [epoch 156] Starting epoch 156\n",
      "[epoch 156] Completed in 0:00:00\n",
      "[epoch 156] [epoch 157] Starting epoch 157\n",
      "[epoch 157] Completed in 0:00:00\n",
      "[epoch 157] [epoch 158] Starting epoch 158\n",
      "[epoch 158] Completed in 0:00:00\n",
      "[epoch 158] [epoch 159] Starting epoch 159\n",
      "[epoch 159] Completed in 0:00:00\n",
      "[epoch 159] [epoch 160] Starting epoch 160\n",
      "[epoch 160] Completed in 0:00:00\n",
      "[epoch 160] [epoch 161] Starting epoch 161\n",
      "[epoch 161] Completed in 0:00:00\n",
      "[epoch 161] [epoch 162] Starting epoch 162\n",
      "[epoch 162] Completed in 0:00:00\n",
      "[epoch 162] [epoch 163] Starting epoch 163\n",
      "[epoch 163] Completed in 0:00:00\n",
      "[epoch 163] [epoch 164] Starting epoch 164\n",
      "[epoch 164] Completed in 0:00:00\n",
      "[epoch 164] [epoch 165] Starting epoch 165\n",
      "[epoch 165] Completed in 0:00:00\n",
      "[epoch 165] [epoch 166] Starting epoch 166\n",
      "[epoch 166] Completed in 0:00:00\n",
      "[epoch 166] [epoch 167] Starting epoch 167\n",
      "[epoch 167] Completed in 0:00:00\n",
      "[epoch 167] [epoch 168] Starting epoch 168\n",
      "[epoch 168] Completed in 0:00:00\n",
      "[epoch 168] [epoch 169] Starting epoch 169\n",
      "[epoch 169] Completed in 0:00:00\n",
      "[epoch 169] [epoch 170] Starting epoch 170\n",
      "[epoch 170] Completed in 0:00:00\n",
      "[epoch 170] [epoch 171] Starting epoch 171\n",
      "[epoch 171] Completed in 0:00:00\n",
      "[epoch 171] [epoch 172] Starting epoch 172\n",
      "[epoch 172] Completed in 0:00:00\n",
      "[epoch 172] [epoch 173] Starting epoch 173\n",
      "[epoch 173] Completed in 0:00:00\n",
      "[epoch 173] [epoch 174] Starting epoch 174\n",
      "[epoch 174] Completed in 0:00:00\n",
      "[epoch 174] [epoch 175] Starting epoch 175\n",
      "[epoch 175] Completed in 0:00:00\n",
      "[epoch 175] [epoch 176] Starting epoch 176\n",
      "[epoch 176] Completed in 0:00:00\n",
      "[epoch 176] [epoch 177] Starting epoch 177\n",
      "[epoch 177] Completed in 0:00:00\n",
      "[epoch 177] [epoch 178] Starting epoch 178\n",
      "[epoch 178] Completed in 0:00:00\n",
      "[epoch 178] [epoch 179] Starting epoch 179\n",
      "[epoch 179] Completed in 0:00:00\n",
      "[epoch 179] [epoch 180] Starting epoch 180\n",
      "[epoch 180] Completed in 0:00:00\n",
      "[epoch 180] [epoch 181] Starting epoch 181\n",
      "[epoch 181] Completed in 0:00:00\n",
      "[epoch 181] [epoch 182] Starting epoch 182\n",
      "[epoch 182] Completed in 0:00:00\n",
      "[epoch 182] [epoch 183] Starting epoch 183\n",
      "[epoch 183] Completed in 0:00:00\n",
      "[epoch 183] [epoch 184] Starting epoch 184\n",
      "[epoch 184] Completed in 0:00:00\n",
      "[epoch 184] [epoch 185] Starting epoch 185\n",
      "[epoch 185] Completed in 0:00:00\n",
      "[epoch 185] [epoch 186] Starting epoch 186\n",
      "[epoch 186] Completed in 0:00:00\n",
      "[epoch 186] [epoch 187] Starting epoch 187\n",
      "[epoch 187] Completed in 0:00:00\n",
      "[epoch 187] [epoch 188] Starting epoch 188\n",
      "[epoch 188] Completed in 0:00:00\n",
      "[epoch 188] [epoch 189] Starting epoch 189\n",
      "[epoch 189] Completed in 0:00:00\n",
      "[epoch 189] [epoch 190] Starting epoch 190\n",
      "[epoch 190] Completed in 0:00:00\n",
      "[epoch 190] [epoch 191] Starting epoch 191\n",
      "[epoch 191] Completed in 0:00:00\n",
      "[epoch 191] [epoch 192] Starting epoch 192\n",
      "[epoch 192] Completed in 0:00:00\n",
      "[epoch 192] [epoch 193] Starting epoch 193\n",
      "[epoch 193] Completed in 0:00:00\n",
      "[epoch 193] [epoch 194] Starting epoch 194\n",
      "[epoch 194] Completed in 0:00:00\n",
      "[epoch 194] [epoch 195] Starting epoch 195\n",
      "[epoch 195] Completed in 0:00:00\n",
      "[epoch 195] [epoch 196] Starting epoch 196\n",
      "[epoch 196] Completed in 0:00:00\n",
      "[epoch 196] [epoch 197] Starting epoch 197\n",
      "[epoch 197] Completed in 0:00:00\n",
      "[epoch 197] [epoch 198] Starting epoch 198\n",
      "[epoch 198] Completed in 0:00:00\n",
      "[epoch 198] [epoch 199] Starting epoch 199\n",
      "[epoch 199] Completed in 0:00:00\n",
      "[epoch 199] [epoch 200] Starting epoch 200\n",
      "[epoch 200] Completed in 0:00:00\n",
      "[epoch 200] [epoch 201] Starting epoch 201\n",
      "[epoch 201] Completed in 0:00:00\n",
      "[epoch 201] [epoch 202] Starting epoch 202\n",
      "[epoch 202] Completed in 0:00:00\n",
      "[epoch 202] [epoch 203] Starting epoch 203\n",
      "[epoch 203] Completed in 0:00:00\n",
      "[epoch 203] [epoch 204] Starting epoch 204\n",
      "[epoch 204] Completed in 0:00:00\n",
      "[epoch 204] [epoch 205] Starting epoch 205\n",
      "[epoch 205] Completed in 0:00:00\n",
      "[epoch 205] [epoch 206] Starting epoch 206\n",
      "[epoch 206] Completed in 0:00:00\n",
      "[epoch 206] [epoch 207] Starting epoch 207\n",
      "[epoch 207] Completed in 0:00:00\n",
      "[epoch 207] [epoch 208] Starting epoch 208\n",
      "[epoch 208] Completed in 0:00:00\n",
      "[epoch 208] [epoch 209] Starting epoch 209\n",
      "[epoch 209] Completed in 0:00:00\n",
      "[epoch 209] [epoch 210] Starting epoch 210\n",
      "[epoch 210] Completed in 0:00:00\n",
      "[epoch 210] [epoch 211] Starting epoch 211\n",
      "[epoch 211] Completed in 0:00:00\n",
      "[epoch 211] [epoch 212] Starting epoch 212\n",
      "[epoch 212] Completed in 0:00:00\n",
      "[epoch 212] [epoch 213] Starting epoch 213\n",
      "[epoch 213] Completed in 0:00:00\n",
      "[epoch 213] [epoch 214] Starting epoch 214\n",
      "[epoch 214] Completed in 0:00:00\n",
      "[epoch 214] [epoch 215] Starting epoch 215\n",
      "[epoch 215] Completed in 0:00:00\n",
      "[epoch 215] [epoch 216] Starting epoch 216\n",
      "[epoch 216] Completed in 0:00:00\n",
      "[epoch 216] [epoch 217] Starting epoch 217\n",
      "[epoch 217] Completed in 0:00:00\n",
      "[epoch 217] [epoch 218] Starting epoch 218\n",
      "[epoch 218] Completed in 0:00:00\n",
      "[epoch 218] [epoch 219] Starting epoch 219\n",
      "[epoch 219] Completed in 0:00:00\n",
      "[epoch 219] [epoch 220] Starting epoch 220\n",
      "[epoch 220] Completed in 0:00:00\n",
      "[epoch 220] [epoch 221] Starting epoch 221\n",
      "[epoch 221] Completed in 0:00:00\n",
      "[epoch 221] [epoch 222] Starting epoch 222\n",
      "[epoch 222] Completed in 0:00:00\n",
      "[epoch 222] [epoch 223] Starting epoch 223\n",
      "[epoch 223] Completed in 0:00:00\n",
      "[epoch 223] [epoch 224] Starting epoch 224\n",
      "[epoch 224] Completed in 0:00:00\n",
      "[epoch 224] [epoch 225] Starting epoch 225\n",
      "[epoch 225] Completed in 0:00:00\n",
      "[epoch 225] [epoch 226] Starting epoch 226\n",
      "[epoch 226] Completed in 0:00:00\n",
      "[epoch 226] [epoch 227] Starting epoch 227\n",
      "[epoch 227] Completed in 0:00:00\n",
      "[epoch 227] [epoch 228] Starting epoch 228\n",
      "[epoch 228] Completed in 0:00:00\n",
      "[epoch 228] [epoch 229] Starting epoch 229\n",
      "[epoch 229] Completed in 0:00:00\n",
      "[epoch 229] [epoch 230] Starting epoch 230\n",
      "[epoch 230] Completed in 0:00:00\n",
      "[epoch 230] [epoch 231] Starting epoch 231\n",
      "[epoch 231] Completed in 0:00:00\n",
      "[epoch 231] [epoch 232] Starting epoch 232\n",
      "[epoch 232] Completed in 0:00:00\n",
      "[epoch 232] [epoch 233] Starting epoch 233\n",
      "[epoch 233] Completed in 0:00:00\n",
      "[epoch 233] [epoch 234] Starting epoch 234\n",
      "[epoch 234] Completed in 0:00:00\n",
      "[epoch 234] [epoch 235] Starting epoch 235\n",
      "[epoch 235] Completed in 0:00:00\n",
      "[epoch 235] [epoch 236] Starting epoch 236\n",
      "[epoch 236] Completed in 0:00:00\n",
      "[epoch 236] [epoch 237] Starting epoch 237\n",
      "[epoch 237] Completed in 0:00:00\n",
      "[epoch 237] [epoch 238] Starting epoch 238\n",
      "[epoch 238] Completed in 0:00:00\n",
      "[epoch 238] [epoch 239] Starting epoch 239\n",
      "[epoch 239] Completed in 0:00:00\n",
      "[epoch 239] [epoch 240] Starting epoch 240\n",
      "[epoch 240] Completed in 0:00:00\n",
      "[epoch 240] [epoch 241] Starting epoch 241\n",
      "[epoch 241] Completed in 0:00:00\n",
      "[epoch 241] [epoch 242] Starting epoch 242\n",
      "[epoch 242] Completed in 0:00:00\n",
      "[epoch 242] [epoch 243] Starting epoch 243\n",
      "[epoch 243] Completed in 0:00:00\n",
      "[epoch 243] [epoch 244] Starting epoch 244\n",
      "[epoch 244] Completed in 0:00:00\n",
      "[epoch 244] [epoch 245] Starting epoch 245\n",
      "[epoch 245] Completed in 0:00:00\n",
      "[epoch 245] [epoch 246] Starting epoch 246\n",
      "[epoch 246] Completed in 0:00:00\n",
      "[epoch 246] [epoch 247] Starting epoch 247\n",
      "[epoch 247] Completed in 0:00:00\n",
      "[epoch 247] [epoch 248] Starting epoch 248\n",
      "[epoch 248] Completed in 0:00:00\n",
      "[epoch 248] [epoch 249] Starting epoch 249\n",
      "[epoch 249] Completed in 0:00:00\n",
      "[epoch 249] [epoch 250] Starting epoch 250\n",
      "[epoch 250] Completed in 0:00:00\n",
      "[epoch 250] [epoch 251] Starting epoch 251\n",
      "[epoch 251] Completed in 0:00:00\n",
      "[epoch 251] [epoch 252] Starting epoch 252\n",
      "[epoch 252] Completed in 0:00:00\n",
      "[epoch 252] [epoch 253] Starting epoch 253\n",
      "[epoch 253] Completed in 0:00:00\n",
      "[epoch 253] [epoch 254] Starting epoch 254\n",
      "[epoch 254] Completed in 0:00:00\n",
      "[epoch 254] [epoch 255] Starting epoch 255\n",
      "[epoch 255] Completed in 0:00:00\n",
      "[epoch 255] [epoch 256] Starting epoch 256\n",
      "[epoch 256] Completed in 0:00:00\n",
      "[epoch 256] [epoch 257] Starting epoch 257\n",
      "[epoch 257] Completed in 0:00:00\n",
      "[epoch 257] [epoch 258] Starting epoch 258\n",
      "[epoch 258] Completed in 0:00:00\n",
      "[epoch 258] [epoch 259] Starting epoch 259\n",
      "[epoch 259] Completed in 0:00:00\n",
      "[epoch 259] [epoch 260] Starting epoch 260\n",
      "[epoch 260] Completed in 0:00:00\n",
      "[epoch 260] [epoch 261] Starting epoch 261\n",
      "[epoch 261] Completed in 0:00:00\n",
      "[epoch 261] [epoch 262] Starting epoch 262\n",
      "[epoch 262] Completed in 0:00:00\n",
      "[epoch 262] [epoch 263] Starting epoch 263\n",
      "[epoch 263] Completed in 0:00:00\n",
      "[epoch 263] [epoch 264] Starting epoch 264\n",
      "[epoch 264] Completed in 0:00:00\n",
      "[epoch 264] [epoch 265] Starting epoch 265\n",
      "[epoch 265] Completed in 0:00:00\n",
      "[epoch 265] [epoch 266] Starting epoch 266\n",
      "[epoch 266] Completed in 0:00:00\n",
      "[epoch 266] [epoch 267] Starting epoch 267\n",
      "[epoch 267] Completed in 0:00:00\n",
      "[epoch 267] [epoch 268] Starting epoch 268\n",
      "[epoch 268] Completed in 0:00:00\n",
      "[epoch 268] [epoch 269] Starting epoch 269\n",
      "[epoch 269] Completed in 0:00:00\n",
      "[epoch 269] [epoch 270] Starting epoch 270\n",
      "[epoch 270] Completed in 0:00:00\n",
      "[epoch 270] [epoch 271] Starting epoch 271\n",
      "[epoch 271] Completed in 0:00:00\n",
      "[epoch 271] [epoch 272] Starting epoch 272\n",
      "[epoch 272] Completed in 0:00:00\n",
      "[epoch 272] [epoch 273] Starting epoch 273\n",
      "[epoch 273] Completed in 0:00:00\n",
      "[epoch 273] [epoch 274] Starting epoch 274\n",
      "[epoch 274] Completed in 0:00:00\n",
      "[epoch 274] [epoch 275] Starting epoch 275\n",
      "[epoch 275] Completed in 0:00:00\n",
      "[epoch 275] [epoch 276] Starting epoch 276\n",
      "[epoch 276] Completed in 0:00:00\n",
      "[epoch 276] [epoch 277] Starting epoch 277\n",
      "[epoch 277] Completed in 0:00:00\n",
      "[epoch 277] [epoch 278] Starting epoch 278\n",
      "[epoch 278] Completed in 0:00:00\n",
      "[epoch 278] [epoch 279] Starting epoch 279\n",
      "[epoch 279] Completed in 0:00:00\n",
      "[epoch 279] [epoch 280] Starting epoch 280\n",
      "[epoch 280] Completed in 0:00:00\n",
      "[epoch 280] [epoch 281] Starting epoch 281\n",
      "[epoch 281] Completed in 0:00:00\n",
      "[epoch 281] [epoch 282] Starting epoch 282\n",
      "[epoch 282] Completed in 0:00:00\n",
      "[epoch 282] [epoch 283] Starting epoch 283\n",
      "[epoch 283] Completed in 0:00:00\n",
      "[epoch 283] [epoch 284] Starting epoch 284\n",
      "[epoch 284] Completed in 0:00:00\n",
      "[epoch 284] [epoch 285] Starting epoch 285\n",
      "[epoch 285] Completed in 0:00:00\n",
      "[epoch 285] [epoch 286] Starting epoch 286\n",
      "[epoch 286] Completed in 0:00:00\n",
      "[epoch 286] [epoch 287] Starting epoch 287\n",
      "[epoch 287] Completed in 0:00:00\n",
      "[epoch 287] [epoch 288] Starting epoch 288\n",
      "[epoch 288] Completed in 0:00:00\n",
      "[epoch 288] [epoch 289] Starting epoch 289\n",
      "[epoch 289] Completed in 0:00:00\n",
      "[epoch 289] [epoch 290] Starting epoch 290\n",
      "[epoch 290] Completed in 0:00:00\n",
      "[epoch 290] [epoch 291] Starting epoch 291\n",
      "[epoch 291] Completed in 0:00:00\n",
      "[epoch 291] [epoch 292] Starting epoch 292\n",
      "[epoch 292] Completed in 0:00:00\n",
      "[epoch 292] [epoch 293] Starting epoch 293\n",
      "[epoch 293] Completed in 0:00:00\n",
      "[epoch 293] [epoch 294] Starting epoch 294\n",
      "[epoch 294] Completed in 0:00:00\n",
      "[epoch 294] [epoch 295] Starting epoch 295\n",
      "[epoch 295] Completed in 0:00:00\n",
      "[epoch 295] [epoch 296] Starting epoch 296\n",
      "[epoch 296] Completed in 0:00:00\n",
      "[epoch 296] [epoch 297] Starting epoch 297\n",
      "[epoch 297] Completed in 0:00:00\n",
      "[epoch 297] [epoch 298] Starting epoch 298\n",
      "[epoch 298] Completed in 0:00:00\n",
      "[epoch 298] [epoch 299] Starting epoch 299\n",
      "[epoch 299] Completed in 0:00:00\n",
      "[epoch 299] [epoch 300] Starting epoch 300\n",
      "[epoch 300] Completed in 0:00:00\n",
      "[epoch 300] [epoch 301] Starting epoch 301\n",
      "[epoch 301] Completed in 0:00:00\n",
      "[epoch 301] [epoch 302] Starting epoch 302\n",
      "[epoch 302] Completed in 0:00:00\n",
      "[epoch 302] [epoch 303] Starting epoch 303\n",
      "[epoch 303] Completed in 0:00:00\n",
      "[epoch 303] [epoch 304] Starting epoch 304\n",
      "[epoch 304] Completed in 0:00:00\n",
      "[epoch 304] [epoch 305] Starting epoch 305\n",
      "[epoch 305] Completed in 0:00:00\n",
      "[epoch 305] [epoch 306] Starting epoch 306\n",
      "[epoch 306] Completed in 0:00:00\n",
      "[epoch 306] [epoch 307] Starting epoch 307\n",
      "[epoch 307] Completed in 0:00:00\n",
      "[epoch 307] [epoch 308] Starting epoch 308\n",
      "[epoch 308] Completed in 0:00:00\n",
      "[epoch 308] [epoch 309] Starting epoch 309\n",
      "[epoch 309] Completed in 0:00:00\n",
      "[epoch 309] [epoch 310] Starting epoch 310\n",
      "[epoch 310] Completed in 0:00:00\n",
      "[epoch 310] [epoch 311] Starting epoch 311\n",
      "[epoch 311] Completed in 0:00:00\n",
      "[epoch 311] [epoch 312] Starting epoch 312\n",
      "[epoch 312] Completed in 0:00:00\n",
      "[epoch 312] [epoch 313] Starting epoch 313\n",
      "[epoch 313] Completed in 0:00:00\n",
      "[epoch 313] [epoch 314] Starting epoch 314\n",
      "[epoch 314] Completed in 0:00:00\n",
      "[epoch 314] [epoch 315] Starting epoch 315\n",
      "[epoch 315] Completed in 0:00:00\n",
      "[epoch 315] [epoch 316] Starting epoch 316\n",
      "[epoch 316] Completed in 0:00:00\n",
      "[epoch 316] [epoch 317] Starting epoch 317\n",
      "[epoch 317] Completed in 0:00:00\n",
      "[epoch 317] [epoch 318] Starting epoch 318\n",
      "[epoch 318] Completed in 0:00:00\n",
      "[epoch 318] [epoch 319] Starting epoch 319\n",
      "[epoch 319] Completed in 0:00:00\n",
      "[epoch 319] [epoch 320] Starting epoch 320\n",
      "[epoch 320] Completed in 0:00:00\n",
      "[epoch 320] [epoch 321] Starting epoch 321\n",
      "[epoch 321] Completed in 0:00:00\n",
      "[epoch 321] [epoch 322] Starting epoch 322\n",
      "[epoch 322] Completed in 0:00:00\n",
      "[epoch 322] [epoch 323] Starting epoch 323\n",
      "[epoch 323] Completed in 0:00:00\n",
      "[epoch 323] [epoch 324] Starting epoch 324\n",
      "[epoch 324] Completed in 0:00:00\n",
      "[epoch 324] [epoch 325] Starting epoch 325\n",
      "[epoch 325] Completed in 0:00:00\n",
      "[epoch 325] [epoch 326] Starting epoch 326\n",
      "[epoch 326] Completed in 0:00:00\n",
      "[epoch 326] [epoch 327] Starting epoch 327\n",
      "[epoch 327] Completed in 0:00:00\n",
      "[epoch 327] [epoch 328] Starting epoch 328\n",
      "[epoch 328] Completed in 0:00:00\n",
      "[epoch 328] [epoch 329] Starting epoch 329\n",
      "[epoch 329] Completed in 0:00:00\n",
      "[epoch 329] [epoch 330] Starting epoch 330\n",
      "[epoch 330] Completed in 0:00:00\n",
      "[epoch 330] [epoch 331] Starting epoch 331\n",
      "[epoch 331] Completed in 0:00:00\n",
      "[epoch 331] [epoch 332] Starting epoch 332\n",
      "[epoch 332] Completed in 0:00:00\n",
      "[epoch 332] [epoch 333] Starting epoch 333\n",
      "[epoch 333] Completed in 0:00:00\n",
      "[epoch 333] [epoch 334] Starting epoch 334\n",
      "[epoch 334] Completed in 0:00:00\n",
      "[epoch 334] [epoch 335] Starting epoch 335\n",
      "[epoch 335] Completed in 0:00:00\n",
      "[epoch 335] [epoch 336] Starting epoch 336\n",
      "[epoch 336] Completed in 0:00:00\n",
      "[epoch 336] [epoch 337] Starting epoch 337\n",
      "[epoch 337] Completed in 0:00:00\n",
      "[epoch 337] [epoch 338] Starting epoch 338\n",
      "[epoch 338] Completed in 0:00:00\n",
      "[epoch 338] [epoch 339] Starting epoch 339\n",
      "[epoch 339] Completed in 0:00:00\n",
      "[epoch 339] [epoch 340] Starting epoch 340\n",
      "[epoch 340] Completed in 0:00:00\n",
      "[epoch 340] [epoch 341] Starting epoch 341\n",
      "[epoch 341] Completed in 0:00:00\n",
      "[epoch 341] [epoch 342] Starting epoch 342\n",
      "[epoch 342] Completed in 0:00:00\n",
      "[epoch 342] [epoch 343] Starting epoch 343\n",
      "[epoch 343] Completed in 0:00:00\n",
      "[epoch 343] [epoch 344] Starting epoch 344\n",
      "[epoch 344] Completed in 0:00:00\n",
      "[epoch 344] [epoch 345] Starting epoch 345\n",
      "[epoch 345] Completed in 0:00:00\n",
      "[epoch 345] [epoch 346] Starting epoch 346\n",
      "[epoch 346] Completed in 0:00:00\n",
      "[epoch 346] [epoch 347] Starting epoch 347\n",
      "[epoch 347] Completed in 0:00:00\n",
      "[epoch 347] [epoch 348] Starting epoch 348\n",
      "[epoch 348] Completed in 0:00:00\n",
      "[epoch 348] [epoch 349] Starting epoch 349\n",
      "[epoch 349] Completed in 0:00:00\n",
      "[epoch 349] [epoch 350] Starting epoch 350\n",
      "[epoch 350] Completed in 0:00:00\n",
      "[epoch 350] [epoch 351] Starting epoch 351\n",
      "[epoch 351] Completed in 0:00:00\n",
      "[epoch 351] [epoch 352] Starting epoch 352\n",
      "[epoch 352] Completed in 0:00:00\n",
      "[epoch 352] [epoch 353] Starting epoch 353\n",
      "[epoch 353] Completed in 0:00:00\n",
      "[epoch 353] [epoch 354] Starting epoch 354\n",
      "[epoch 354] Completed in 0:00:00\n",
      "[epoch 354] [epoch 355] Starting epoch 355\n",
      "[epoch 355] Completed in 0:00:00\n",
      "[epoch 355] [epoch 356] Starting epoch 356\n",
      "[epoch 356] Completed in 0:00:00\n",
      "[epoch 356] [epoch 357] Starting epoch 357\n",
      "[epoch 357] Completed in 0:00:00\n",
      "[epoch 357] [epoch 358] Starting epoch 358\n",
      "[epoch 358] Completed in 0:00:00\n",
      "[epoch 358] [epoch 359] Starting epoch 359\n",
      "[epoch 359] Completed in 0:00:00\n",
      "[epoch 359] [epoch 360] Starting epoch 360\n",
      "[epoch 360] Completed in 0:00:00\n",
      "[epoch 360] [epoch 361] Starting epoch 361\n",
      "[epoch 361] Completed in 0:00:00\n",
      "[epoch 361] [epoch 362] Starting epoch 362\n",
      "[epoch 362] Completed in 0:00:00\n",
      "[epoch 362] [epoch 363] Starting epoch 363\n",
      "[epoch 363] Completed in 0:00:00\n",
      "[epoch 363] [epoch 364] Starting epoch 364\n",
      "[epoch 364] Completed in 0:00:00\n",
      "[epoch 364] [epoch 365] Starting epoch 365\n",
      "[epoch 365] Completed in 0:00:00\n",
      "[epoch 365] [epoch 366] Starting epoch 366\n",
      "[epoch 366] Completed in 0:00:00\n",
      "[epoch 366] [epoch 367] Starting epoch 367\n",
      "[epoch 367] Completed in 0:00:00\n",
      "[epoch 367] [epoch 368] Starting epoch 368\n",
      "[epoch 368] Completed in 0:00:00\n",
      "[epoch 368] [epoch 369] Starting epoch 369\n",
      "[epoch 369] Completed in 0:00:00\n",
      "[epoch 369] [epoch 370] Starting epoch 370\n",
      "[epoch 370] Completed in 0:00:00\n",
      "[epoch 370] [epoch 371] Starting epoch 371\n",
      "[epoch 371] Completed in 0:00:00\n",
      "[epoch 371] [epoch 372] Starting epoch 372\n",
      "[epoch 372] Completed in 0:00:00\n",
      "[epoch 372] [epoch 373] Starting epoch 373\n",
      "[epoch 373] Completed in 0:00:00\n",
      "[epoch 373] [epoch 374] Starting epoch 374\n",
      "[epoch 374] Completed in 0:00:00\n",
      "[epoch 374] [epoch 375] Starting epoch 375\n",
      "[epoch 375] Completed in 0:00:00\n",
      "[epoch 375] [epoch 376] Starting epoch 376\n",
      "[epoch 376] Completed in 0:00:00\n",
      "[epoch 376] [epoch 377] Starting epoch 377\n",
      "[epoch 377] Completed in 0:00:00\n",
      "[epoch 377] [epoch 378] Starting epoch 378\n",
      "[epoch 378] Completed in 0:00:00\n",
      "[epoch 378] [epoch 379] Starting epoch 379\n",
      "[epoch 379] Completed in 0:00:00\n",
      "[epoch 379] [epoch 380] Starting epoch 380\n",
      "[epoch 380] Completed in 0:00:00\n",
      "[epoch 380] [epoch 381] Starting epoch 381\n",
      "[epoch 381] Completed in 0:00:00\n",
      "[epoch 381] [epoch 382] Starting epoch 382\n",
      "[epoch 382] Completed in 0:00:00\n",
      "[epoch 382] [epoch 383] Starting epoch 383\n",
      "[epoch 383] Completed in 0:00:00\n",
      "[epoch 383] [epoch 384] Starting epoch 384\n",
      "[epoch 384] Completed in 0:00:00\n",
      "[epoch 384] [epoch 385] Starting epoch 385\n",
      "[epoch 385] Completed in 0:00:00\n",
      "[epoch 385] [epoch 386] Starting epoch 386\n",
      "[epoch 386] Completed in 0:00:00\n",
      "[epoch 386] [epoch 387] Starting epoch 387\n",
      "[epoch 387] Completed in 0:00:00\n",
      "[epoch 387] [epoch 388] Starting epoch 388\n",
      "[epoch 388] Completed in 0:00:00\n",
      "[epoch 388] [epoch 389] Starting epoch 389\n",
      "[epoch 389] Completed in 0:00:00\n",
      "[epoch 389] [epoch 390] Starting epoch 390\n",
      "[epoch 390] Completed in 0:00:00\n",
      "[epoch 390] [epoch 391] Starting epoch 391\n",
      "[epoch 391] Completed in 0:00:00\n",
      "[epoch 391] [epoch 392] Starting epoch 392\n",
      "[epoch 392] Completed in 0:00:00\n",
      "[epoch 392] [epoch 393] Starting epoch 393\n",
      "[epoch 393] Completed in 0:00:00\n",
      "[epoch 393] [epoch 394] Starting epoch 394\n",
      "[epoch 394] Completed in 0:00:00\n",
      "[epoch 394] [epoch 395] Starting epoch 395\n",
      "[epoch 395] Completed in 0:00:00\n",
      "[epoch 395] [epoch 396] Starting epoch 396\n",
      "[epoch 396] Completed in 0:00:00\n",
      "[epoch 396] [epoch 397] Starting epoch 397\n",
      "[epoch 397] Completed in 0:00:00\n",
      "[epoch 397] [epoch 398] Starting epoch 398\n",
      "[epoch 398] Completed in 0:00:00\n",
      "[epoch 398] [epoch 399] Starting epoch 399\n",
      "[epoch 399] Completed in 0:00:00\n",
      "[epoch 399] [epoch 400] Starting epoch 400\n",
      "[epoch 400] Completed in 0:00:00\n",
      "[epoch 400] [epoch 401] Starting epoch 401\n",
      "[epoch 401] Completed in 0:00:00\n",
      "[epoch 401] [epoch 402] Starting epoch 402\n",
      "[epoch 402] Completed in 0:00:00\n",
      "[epoch 402] [epoch 403] Starting epoch 403\n",
      "[epoch 403] Completed in 0:00:00\n",
      "[epoch 403] [epoch 404] Starting epoch 404\n",
      "[epoch 404] Completed in 0:00:00\n",
      "[epoch 404] [epoch 405] Starting epoch 405\n",
      "[epoch 405] Completed in 0:00:00\n",
      "[epoch 405] [epoch 406] Starting epoch 406\n",
      "[epoch 406] Completed in 0:00:00\n",
      "[epoch 406] [epoch 407] Starting epoch 407\n",
      "[epoch 407] Completed in 0:00:00\n",
      "[epoch 407] [epoch 408] Starting epoch 408\n",
      "[epoch 408] Completed in 0:00:00\n",
      "[epoch 408] [epoch 409] Starting epoch 409\n",
      "[epoch 409] Completed in 0:00:00\n",
      "[epoch 409] [epoch 410] Starting epoch 410\n",
      "[epoch 410] Completed in 0:00:00\n",
      "[epoch 410] [epoch 411] Starting epoch 411\n",
      "[epoch 411] Completed in 0:00:00\n",
      "[epoch 411] [epoch 412] Starting epoch 412\n",
      "[epoch 412] Completed in 0:00:00\n",
      "[epoch 412] [epoch 413] Starting epoch 413\n",
      "[epoch 413] Completed in 0:00:00\n",
      "[epoch 413] [epoch 414] Starting epoch 414\n",
      "[epoch 414] Completed in 0:00:00\n",
      "[epoch 414] [epoch 415] Starting epoch 415\n",
      "[epoch 415] Completed in 0:00:00\n",
      "[epoch 415] [epoch 416] Starting epoch 416\n",
      "[epoch 416] Completed in 0:00:00\n",
      "[epoch 416] [epoch 417] Starting epoch 417\n",
      "[epoch 417] Completed in 0:00:00\n",
      "[epoch 417] [epoch 418] Starting epoch 418\n",
      "[epoch 418] Completed in 0:00:00\n",
      "[epoch 418] [epoch 419] Starting epoch 419\n",
      "[epoch 419] Completed in 0:00:00\n",
      "[epoch 419] [epoch 420] Starting epoch 420\n",
      "[epoch 420] Completed in 0:00:00\n",
      "[epoch 420] [epoch 421] Starting epoch 421\n",
      "[epoch 421] Completed in 0:00:00\n",
      "[epoch 421] [epoch 422] Starting epoch 422\n",
      "[epoch 422] Completed in 0:00:00\n",
      "[epoch 422] [epoch 423] Starting epoch 423\n",
      "[epoch 423] Completed in 0:00:00\n",
      "[epoch 423] [epoch 424] Starting epoch 424\n",
      "[epoch 424] Completed in 0:00:00\n",
      "[epoch 424] [epoch 425] Starting epoch 425\n",
      "[epoch 425] Completed in 0:00:00\n",
      "[epoch 425] [epoch 426] Starting epoch 426\n",
      "[epoch 426] Completed in 0:00:00\n",
      "[epoch 426] [epoch 427] Starting epoch 427\n",
      "[epoch 427] Completed in 0:00:00\n",
      "[epoch 427] [epoch 428] Starting epoch 428\n",
      "[epoch 428] Completed in 0:00:00\n",
      "[epoch 428] [epoch 429] Starting epoch 429\n",
      "[epoch 429] Completed in 0:00:00\n",
      "[epoch 429] [epoch 430] Starting epoch 430\n",
      "[epoch 430] Completed in 0:00:00\n",
      "[epoch 430] [epoch 431] Starting epoch 431\n",
      "[epoch 431] Completed in 0:00:00\n",
      "[epoch 431] [epoch 432] Starting epoch 432\n",
      "[epoch 432] Completed in 0:00:00\n",
      "[epoch 432] [epoch 433] Starting epoch 433\n",
      "[epoch 433] Completed in 0:00:00\n",
      "[epoch 433] [epoch 434] Starting epoch 434\n",
      "[epoch 434] Completed in 0:00:00\n",
      "[epoch 434] [epoch 435] Starting epoch 435\n",
      "[epoch 435] Completed in 0:00:00\n",
      "[epoch 435] [epoch 436] Starting epoch 436\n",
      "[epoch 436] Completed in 0:00:00\n",
      "[epoch 436] [epoch 437] Starting epoch 437\n",
      "[epoch 437] Completed in 0:00:00\n",
      "[epoch 437] [epoch 438] Starting epoch 438\n",
      "[epoch 438] Completed in 0:00:00\n",
      "[epoch 438] [epoch 439] Starting epoch 439\n",
      "[epoch 439] Completed in 0:00:00\n",
      "[epoch 439] [epoch 440] Starting epoch 440\n",
      "[epoch 440] Completed in 0:00:00\n",
      "[epoch 440] [epoch 441] Starting epoch 441\n",
      "[epoch 441] Completed in 0:00:00\n",
      "[epoch 441] [epoch 442] Starting epoch 442\n",
      "[epoch 442] Completed in 0:00:00\n",
      "[epoch 442] [epoch 443] Starting epoch 443\n",
      "[epoch 443] Completed in 0:00:00\n",
      "[epoch 443] [epoch 444] Starting epoch 444\n",
      "[epoch 444] Completed in 0:00:00\n",
      "[epoch 444] [epoch 445] Starting epoch 445\n",
      "[epoch 445] Completed in 0:00:00\n",
      "[epoch 445] [epoch 446] Starting epoch 446\n",
      "[epoch 446] Completed in 0:00:00\n",
      "[epoch 446] [epoch 447] Starting epoch 447\n",
      "[epoch 447] Completed in 0:00:00\n",
      "[epoch 447] [epoch 448] Starting epoch 448\n",
      "[epoch 448] Completed in 0:00:00\n",
      "[epoch 448] [epoch 449] Starting epoch 449\n",
      "[epoch 449] Completed in 0:00:00\n",
      "[epoch 449] [epoch 450] Starting epoch 450\n",
      "[epoch 450] Completed in 0:00:00\n",
      "[epoch 450] [epoch 451] Starting epoch 451\n",
      "[epoch 451] Completed in 0:00:00\n",
      "[epoch 451] [epoch 452] Starting epoch 452\n",
      "[epoch 452] Completed in 0:00:00\n",
      "[epoch 452] [epoch 453] Starting epoch 453\n",
      "[epoch 453] Completed in 0:00:00\n",
      "[epoch 453] [epoch 454] Starting epoch 454\n",
      "[epoch 454] Completed in 0:00:00\n",
      "[epoch 454] [epoch 455] Starting epoch 455\n",
      "[epoch 455] Completed in 0:00:00\n",
      "[epoch 455] [epoch 456] Starting epoch 456\n",
      "[epoch 456] Completed in 0:00:00\n",
      "[epoch 456] [epoch 457] Starting epoch 457\n",
      "[epoch 457] Completed in 0:00:00\n",
      "[epoch 457] [epoch 458] Starting epoch 458\n",
      "[epoch 458] Completed in 0:00:00\n",
      "[epoch 458] [epoch 459] Starting epoch 459\n",
      "[epoch 459] Completed in 0:00:00\n",
      "[epoch 459] [epoch 460] Starting epoch 460\n",
      "[epoch 460] Completed in 0:00:00\n",
      "[epoch 460] [epoch 461] Starting epoch 461\n",
      "[epoch 461] Completed in 0:00:00\n",
      "[epoch 461] [epoch 462] Starting epoch 462\n",
      "[epoch 462] Completed in 0:00:00\n",
      "[epoch 462] [epoch 463] Starting epoch 463\n",
      "[epoch 463] Completed in 0:00:00\n",
      "[epoch 463] [epoch 464] Starting epoch 464\n",
      "[epoch 464] Completed in 0:00:00\n",
      "[epoch 464] [epoch 465] Starting epoch 465\n",
      "[epoch 465] Completed in 0:00:00\n",
      "[epoch 465] [epoch 466] Starting epoch 466\n",
      "[epoch 466] Completed in 0:00:00\n",
      "[epoch 466] [epoch 467] Starting epoch 467\n",
      "[epoch 467] Completed in 0:00:00\n",
      "[epoch 467] [epoch 468] Starting epoch 468\n",
      "[epoch 468] Completed in 0:00:00\n",
      "[epoch 468] [epoch 469] Starting epoch 469\n",
      "[epoch 469] Completed in 0:00:00\n",
      "[epoch 469] [epoch 470] Starting epoch 470\n",
      "[epoch 470] Completed in 0:00:00\n",
      "[epoch 470] [epoch 471] Starting epoch 471\n",
      "[epoch 471] Completed in 0:00:00\n",
      "[epoch 471] [epoch 472] Starting epoch 472\n",
      "[epoch 472] Completed in 0:00:00\n",
      "[epoch 472] [epoch 473] Starting epoch 473\n",
      "[epoch 473] Completed in 0:00:00\n",
      "[epoch 473] [epoch 474] Starting epoch 474\n",
      "[epoch 474] Completed in 0:00:00\n",
      "[epoch 474] [epoch 475] Starting epoch 475\n",
      "[epoch 475] Completed in 0:00:00\n",
      "[epoch 475] [epoch 476] Starting epoch 476\n",
      "[epoch 476] Completed in 0:00:00\n",
      "[epoch 476] [epoch 477] Starting epoch 477\n",
      "[epoch 477] Completed in 0:00:00\n",
      "[epoch 477] [epoch 478] Starting epoch 478\n",
      "[epoch 478] Completed in 0:00:00\n",
      "[epoch 478] [epoch 479] Starting epoch 479\n",
      "[epoch 479] Completed in 0:00:00\n",
      "[epoch 479] [epoch 480] Starting epoch 480\n",
      "[epoch 480] Completed in 0:00:00\n",
      "[epoch 480] [epoch 481] Starting epoch 481\n",
      "[epoch 481] Completed in 0:00:00\n",
      "[epoch 481] [epoch 482] Starting epoch 482\n",
      "[epoch 482] Completed in 0:00:00\n",
      "[epoch 482] [epoch 483] Starting epoch 483\n",
      "[epoch 483] Completed in 0:00:00\n",
      "[epoch 483] [epoch 484] Starting epoch 484\n",
      "[epoch 484] Completed in 0:00:00\n",
      "[epoch 484] [epoch 485] Starting epoch 485\n",
      "[epoch 485] Completed in 0:00:00\n",
      "[epoch 485] [epoch 486] Starting epoch 486\n",
      "[epoch 486] Completed in 0:00:00\n",
      "[epoch 486] [epoch 487] Starting epoch 487\n",
      "[epoch 487] Completed in 0:00:00\n",
      "[epoch 487] [epoch 488] Starting epoch 488\n",
      "[epoch 488] Completed in 0:00:00\n",
      "[epoch 488] [epoch 489] Starting epoch 489\n",
      "[epoch 489] Completed in 0:00:00\n",
      "[epoch 489] [epoch 490] Starting epoch 490\n",
      "[epoch 490] Completed in 0:00:00\n",
      "[epoch 490] [epoch 491] Starting epoch 491\n",
      "[epoch 491] Completed in 0:00:00\n",
      "[epoch 491] [epoch 492] Starting epoch 492\n",
      "[epoch 492] Completed in 0:00:00\n",
      "[epoch 492] [epoch 493] Starting epoch 493\n",
      "[epoch 493] Completed in 0:00:00\n",
      "[epoch 493] [epoch 494] Starting epoch 494\n",
      "[epoch 494] Completed in 0:00:00\n",
      "[epoch 494] [epoch 495] Starting epoch 495\n",
      "[epoch 495] Completed in 0:00:00\n",
      "[epoch 495] [epoch 496] Starting epoch 496\n",
      "[epoch 496] Completed in 0:00:00\n",
      "[epoch 496] [epoch 497] Starting epoch 497\n",
      "[epoch 497] Completed in 0:00:00\n",
      "[epoch 497] [epoch 498] Starting epoch 498\n",
      "[epoch 498] Completed in 0:00:00\n",
      "[epoch 498] [epoch 499] Starting epoch 499\n",
      "[epoch 499] Completed in 0:00:00\n",
      "[epoch 499] [epoch 500] Starting epoch 500\n",
      "[epoch 500] Completed in 0:00:00\n",
      "[epoch 500] Predicting for Federalist Paper 20\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "james_madison: 0.35\n",
      "alexander_hamilton: 0.40\n",
      "john_jay: 0.25\n",
      "\n",
      "Predicting for Federalist Paper 58\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "james_madison: 0.45\n",
      "alexander_hamilton: 0.36\n",
      "john_jay: 0.19\n",
      "\n",
      "Predicting for Federalist Paper 49\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "james_madison: 0.33\n",
      "alexander_hamilton: 0.51\n",
      "john_jay: 0.16\n",
      "\n",
      "Predicting for Federalist Paper 55\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "james_madison: 0.46\n",
      "alexander_hamilton: 0.37\n",
      "john_jay: 0.17\n",
      "\n",
      "Predicting for Federalist Paper 54\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "james_madison: 0.51\n",
      "alexander_hamilton: 0.34\n",
      "john_jay: 0.15\n",
      "\n",
      "Predicting for Federalist Paper 57\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "james_madison: 0.39\n",
      "alexander_hamilton: 0.47\n",
      "john_jay: 0.15\n",
      "\n",
      "Predicting for Federalist Paper 56\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "james_madison: 0.40\n",
      "alexander_hamilton: 0.36\n",
      "john_jay: 0.24\n",
      "\n",
      "Predicting for Federalist Paper 51\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "james_madison: 0.54\n",
      "alexander_hamilton: 0.31\n",
      "john_jay: 0.15\n",
      "\n",
      "Predicting for Federalist Paper 50\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "james_madison: 0.46\n",
      "alexander_hamilton: 0.36\n",
      "john_jay: 0.18\n",
      "\n",
      "Predicting for Federalist Paper 53\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "james_madison: 0.45\n",
      "alexander_hamilton: 0.41\n",
      "john_jay: 0.14\n",
      "\n",
      "Predicting for Federalist Paper 52\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "james_madison: 0.33\n",
      "alexander_hamilton: 0.43\n",
      "john_jay: 0.24\n",
      "\n",
      "Predicting for Federalist Paper 19\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "james_madison: 0.41\n",
      "alexander_hamilton: 0.37\n",
      "john_jay: 0.22\n",
      "\n",
      "Predicting for Federalist Paper 62\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "james_madison: 0.43\n",
      "alexander_hamilton: 0.41\n",
      "john_jay: 0.16\n",
      "\n",
      "Predicting for Federalist Paper 63\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "james_madison: 0.40\n",
      "alexander_hamilton: 0.41\n",
      "john_jay: 0.19\n",
      "\n",
      "Predicting for Federalist Paper 72\n",
      "Truth: alexander_hamilton\n",
      "Prediction Summary:\n",
      "james_madison: 0.16\n",
      "alexander_hamilton: 0.70\n",
      "john_jay: 0.14\n",
      "\n",
      "Predicting for Federalist Paper 18\n",
      "Truth: james_madison\n",
      "Prediction Summary:\n",
      "james_madison: 0.35\n",
      "alexander_hamilton: 0.45\n",
      "john_jay: 0.20\n",
      "\n"
     ]
    }
   ],
>>>>>>> 651ae6c0d146adbeeaade7f56459ce625202a1c1
   "source": [
    "reload(rnnlm)\n",
    "\n",
    "# Will print status every this many seconds\n",
    "print_interval = 5\n",
    "\n",
    "# Clear old log directory\n",
    "shutil.rmtree(\"tf_summaries\", ignore_errors=True)\n",
    "\n",
    "lm = rnnlm.RNNLM(**model_params)\n",
    "lm.BuildCoreGraph()\n",
    "lm.BuildTrainGraph()\n",
    "lm.BuildClassifierGraph()\n",
    "\n",
    "# Explicitly add global initializer and variable saver to LM graph\n",
    "with lm.graph.as_default():\n",
    "    initializer = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "# Clear old log directory\n",
    "shutil.rmtree(TF_SAVEDIR, ignore_errors=True)\n",
    "if not os.path.isdir(TF_SAVEDIR):\n",
    "    os.makedirs(TF_SAVEDIR)\n",
    "\n",
    "with tf.Session(graph=lm.graph) as session:\n",
    "    # Seed RNG for repeatability\n",
    "    tf.set_random_seed(42)\n",
    "\n",
    "    session.run(initializer)\n",
    "\n",
    "    # List for saving the unkown paper predictions from each epoch\n",
    "    if save_predictions:\n",
    "        epoch_predictions = []\n",
    "    for epoch in xrange(1,num_epochs+1):\n",
    "        t0_epoch = time.time()\n",
    "        bi = batch_generator(X_train_shaped, y_train_shaped, batch_size)\n",
    "        print \"[epoch %d] Starting epoch %d\" % (epoch, epoch)\n",
    "        # Run a training epoch.\n",
    "\n",
    "        run_epoch(lm, session, bi, train=True, verbose=True, tick_s=100, learning_rate=learning_rate)\n",
    "    \n",
    "        print \"[epoch %d] Completed in %s\" % (epoch, pretty_timedelta(since=t0_epoch))\n",
    "    \n",
    "        # Save a checkpoint\n",
    "        saver.save(session, checkpoint_filename, global_step=epoch)\n",
    "    \n",
    "        ##\n",
    "        # score_dataset will run a forward pass over the entire dataset\n",
    "        # and report perplexity scores. This can be slow (around 1/2 to \n",
    "        # 1/4 as long as a full epoch), so you may want to comment it out\n",
    "        # to speed up training on a slow machine. Be sure to run it at the \n",
    "        # end to evaluate your score.\n",
    "        print (\"[epoch %d]\" % epoch),\n",
    "        #score_dataset(lm, session, eval_X['18'], eval_y['18'], max_time, name=\"Federalist Paper 18\")\n",
    "        #score_dataset(lm, session, test_ids, name=\"Test set\")\n",
    "\n",
    "        # test known set of papers.\n",
    "        test_predictions = test_papers(lm, session, X_test_shaped, y_test_shaped, author_to_id, batch_size, print_results=False)\n",
    "        if save_predictions:\n",
    "            # testing against all unkown federalist papers\n",
    "            unk_predictions = test_papers(lm, session, X_eval_shaped, y_eval_shaped, author_to_id, batch_size, print_results=False)\n",
    "            epoch_predictions.append(unk_predictions)\n",
    "\n",
    "        accuracy = get_accuracy(test_predictions, y_test_shaped)\n",
    "        print \"test accuracy:\", accuracy\n",
    "        if accuracy > .95:\n",
    "            break\n",
    "            \n",
    "    # Testing final model against all unkown federalist papers\n",
    "    final_test = test_papers(lm, session, X_eval_shaped, y_eval_shaped, author_to_id, batch_size, print_results=True)    \n",
    "    # Save final model\n",
    "    saver.save(session, trained_filename)\n",
    "    \n",
    "    if save_predictions:\n",
    "        df = create_predictions_dataframe(epoch_predictions)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAVING: Uncomment and run to save the current model results to disk\n",
    "By default, results will be placed in their own directory within `/nn_saved_results`, which is named with the current datetime stamp. This is to prevent overwrites when we are pushing to the directory."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 24,
>>>>>>> 651ae6c0d146adbeeaade7f56459ce625202a1c1
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# RESULTS_SAVE_DIR = './nn_saved_results/' + datetime.now().strftime('%Y-%m-%d_%H_%M_%S')\n",
    "# save_results(RESULTS_SAVE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
